<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte Final - Curso de Inteligencia Artificial</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        p {
            text-align: justify;
            line-height: 1.5;
            font-size: 12pt;
        }

        body {
            font-family: Arial, sans-serif;
            font-size: 12pt;
            line-height: 1.5;
            color: #333;
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
            overflow: hidden;
            padding: 2.5cm;
        }

        /* Header */
        .header {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.95;
        }

        .header-logo {
            margin-bottom: 20px;
            font-size: 3em;
        }

        /* Main Content */
        .content {
            padding: 0;
            text-align: justify;
        }

        .section {
            margin-bottom: 50px;
            page-break-inside: avoid;
            page-break-after: auto;
        }

        .section-title {
            font-size: 14pt;
            color: #000;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #C41E3A;
            font-weight: bold;
            page-break-after: avoid;
        }

        .section-subtitle {
            font-size: 12pt;
            color: #000;
            margin-top: 30px;
            margin-bottom: 15px;
            font-weight: bold;
            font-style: italic;
            padding-left: 20px;
            border-left: 4px solid #C41E3A;
        }

        .intro-text {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-left: 5px solid #C41E3A;
            margin-bottom: 30px;
            line-height: 1.5;
            font-size: 12pt;
            text-align: justify;
        }

        /* Specifications */
        .specifications {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .spec-card {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #C41E3A;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .spec-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(196, 30, 58, 0.2);
        }

        .spec-card strong {
            color: #000;
            display: block;
            margin-bottom: 8px;
        }

        /* Lists */
        ul,
        ol {
            margin-left: 30px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 12px;
            line-height: 1.5;
            text-align: justify;
        }

        li strong {
            color: #4A4A4A;
        }

        /* Structure sections */
        .structure-list {
            padding: 30px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .structure-item {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 1px solid #e0e0e0;
        }

        .structure-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .structure-item h4 {
            color: #000;
            font-size: 1.15em;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
        }

        .structure-item h4:before {
            content: "▸";
            margin-right: 10px;
            font-size: 1.3em;
            color: #4A4A4A;
        }

        .structure-description {
            margin-left: 20px;
            color: #666;
            line-height: 1.8;
        }

        /* Rubric */
        .rubric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .rubric-item {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 25px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(139, 21, 56, 0.2);
        }

        .rubric-percentage {
            font-size: 2.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .rubric-description {
            font-size: 0.95em;
            opacity: 0.95;
        }

        /* Deliverables */
        .deliverables {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 30px;
            border-radius: 8px;
            border: 2px solid #C41E3A;
        }

        .deliverable-item {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
            font-size: 1.05em;
        }

        .deliverable-item:last-child {
            margin-bottom: 0;
        }

        .deliverable-icon {
            width: 30px;
            height: 30px;
            background: #C41E3A;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 15px;
            font-weight: bold;
            flex-shrink: 0;
        }

        /* Format Table */
        .format-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            overflow: hidden;
        }

        .format-table th {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }

        .format-table td {
            padding: 15px;
            border-bottom: 1px solid #e0e0e0;
        }

        .format-table tr:hover {
            background: #f8f9fa;
        }

        .format-table tr:last-child td {
            border-bottom: none;
        }

        /* Footer */
        .footer {
            background: #f8f9fa;
            padding: 30px 40px;
            text-align: center;
            color: #666;
            border-top: 1px solid #e0e0e0;
        }

        .footer p {
            margin-bottom: 10px;
        }

        .footer-highlight {
            color: #4A4A4A;
            font-weight: bold;
        }

        /* Highlight boxes */
        .highlight-box {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            border-left: 4px solid #C41E3A;
            padding: 15px 20px;
            border-radius: 4px;
            margin: 20px 0;
            color: #000;
        }

        .highlight-box strong {
            color: #000;
        }

        /* Code blocks */
        .code-block {
            background-color: #f5f5f5;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            border-left: 4px solid #C41E3A;
            margin: 15px 0;
            font-size: 0.9em;
            line-height: 1.4;
        }

        /* Responsiveness */
        @media (max-width: 768px) {
            .header {
                padding: 40px 20px;
            }

            .header h1 {
                font-size: 1.8em;
            }

            .content {
                padding: 30px 20px;
                text-align: justify;
            }

            .section-title {
                font-size: 1.6em;
            }

            .specifications,
            .rubric-grid {
                grid-template-columns: 1fr;
            }

            .structure-item h4 {
                font-size: 1.05em;
            }

            .format-table {
                font-size: 0.9em;
            }

            .format-table th,
            .format-table td {
                padding: 10px;
            }

            p,
            li,
            td {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }
        }

        /* Animation */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .section {
            animation: fadeIn 0.6s ease-out;
        }

        .spec-card {
            animation: fadeIn 0.6s ease-out;
        }

        /* Print styles */
        @media print {
            body {
                background: white;
                padding: 2.5cm;
                margin: 0;
                font-size: 12pt;
                line-height: 1.5;
                counter-reset: page 1;
            }

            .container {
                box-shadow: none;
                border-radius: 0;
                padding: 0;
                max-width: 100%;
                margin: 0;
            }

            .header {
                page-break-after: avoid;
                padding: 30px 0;
            }

            .content {
                padding: 0;
                text-align: justify;
            }

            p,
            li,
            td,
            th {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }

            .section {
                page-break-inside: avoid;
            }

            @page {
                margin: 2.5cm;

                @bottom-center {
                    content: counter(page);
                    font-size: 12pt;
                    font-family: Arial, sans-serif;
                }
            }
        }

        /* Code styles */
        code {
            background: #f0f0f0;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d63384;
        }

        /* COVER PAGE STYLES */
        .cover-page {
            display: flex;
            align-items: flex-start;
            justify-content: center;
            min-height: 100vh;
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            color: #000;
            text-align: center;
            padding: 60px 60px 80px 60px;
            page-break-after: always;
            position: relative;
        }

        .cover-page::before {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #C41E3A, rgba(196, 30, 58, 0) 50%, rgba(196, 30, 58, 0));
        }

        .cover-page::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 2px;
            background: linear-gradient(90deg, rgba(196, 30, 58, 0), #C41E3A 50%, rgba(196, 30, 58, 0));
        }

        .cover-content {
            max-width: 600px;
            animation: fadeInCover 0.8s ease;
        }

        @keyframes fadeInCover {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .cover-logos {
            display: flex;
            justify-content: space-between;
            gap: 0;
            margin-bottom: 50px;
            align-items: center;
            width: 100%;
            max-width: none;
            margin-left: 0;
            margin-right: 0;
        }

        .cover-logo {
            flex: 0 0 auto;
            background: rgba(139, 21, 56, 0.05);
            padding: 15px;
            border-radius: 8px;
            border: 1px solid rgba(139, 21, 56, 0.2);
            backdrop-filter: blur(10px);
        }

        .cover-logo img {
            max-width: 100px;
            height: auto;
            filter: brightness(1);
            transition: transform 0.3s ease;
        }

        .cover-logo img:hover {
            transform: scale(1.05);
        }

        .cover-institution {
            margin-bottom: 60px;
            border-bottom: 2px solid #C41E3A;
            padding-bottom: 25px;
            letter-spacing: 0.5px;
        }

        .cover-institution h2 {
            font-size: 2em;
            margin-bottom: 8px;
            font-weight: 700;
            letter-spacing: 0.3px;
            line-height: 1.2;
            color: #000;
        }

        .cover-institution p {
            font-size: 1.15em;
            opacity: 1;
            font-weight: 500;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-course {
            margin-bottom: 90px;
            font-size: 1.25em;
            font-style: italic;
            opacity: 1;
            font-weight: 400;
            letter-spacing: 0.3px;
            color: #000;
        }

        .cover-main {
            margin-bottom: 100px;
        }

        .cover-main h1 {
            font-size: 3.5em;
            margin-bottom: 20px;
            font-weight: 800;
            text-shadow: none;
            line-height: 1.1;
            letter-spacing: -0.5px;
            color: #000;
        }

        .cover-subtitle {
            font-size: 1.4em;
            opacity: 1;
            font-style: italic;
            line-height: 1.5;
            font-weight: 300;
            color: #000;
        }

        .cover-author {
            margin-bottom: 70px;
            font-size: 1.1em;
        }

        .cover-author p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-author p:last-child {
            font-size: 1.4em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-date {
            font-size: 1.1em;
            margin-top: 80px;
            padding-top: 30px;
            border-top: 1px solid #C41E3A;
        }

        .cover-date p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-date p:last-child {
            font-size: 1.3em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        /* Print styles for cover */
        @media print {
            .cover-page {
                page-break-after: always;
                background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
                color: white;
            }
        }

        code-block {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            display: block;
            overflow-x: auto;
        }

        /* Footer con numeración de página */
        .page-number {
            text-align: center;
            padding: 20px 0;
            color: #999;
            font-size: 11pt;
            border-top: 1px solid #ddd;
            margin-top: 40px;
        }

        @media print {
            .page-number {
                display: none;
            }
        }

        /* Download Button */
        .download-container {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
        }

        .download-btn {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: bold;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(139, 21, 56, 0.3);
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .download-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(139, 21, 56, 0.4);
        }

        .download-btn:active {
            transform: translateY(0);
        }

        @media print {
            .download-container {
                display: none;
            }
        }

        /* Page Break Control */
        .page-section {
            page-break-after: always;
            page-break-inside: avoid;
            padding: 20px 0;
            margin-bottom: 1cm;
        }

        .page-section:last-child {
            page-break-after: avoid;
        }

        .section-page-break {
            page-break-after: always;
        }

        /* Evitar rupturas dentro de elementos */
        .page-section .section {
            page-break-inside: avoid;
        }

        .section-subtitle {
            page-break-after: avoid;
        }

        .section-title {
            page-break-after: avoid;
        }

        ul,
        ol {
            page-break-inside: avoid;
        }

        .format-table {
            page-break-inside: avoid;
        }

        .spec-card {
            page-break-inside: avoid;
        }

        .highlight-box {
            page-break-inside: avoid;
        }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script src="https://unpkg.com/docx@8.12.6/build/index.js"></script>
    <script>
        // Script para numeración de páginas
        window.addEventListener('load', function () {
            // En navegador, agregar numeración visible
            const pageNumbers = document.querySelectorAll('.page-number');
            if (pageNumbers.length > 0) {
                let pageCount = 1;
                pageNumbers.forEach((element, index) => {
                    element.textContent = 'Página ' + (index + 1);
                });
            }
        });

        // Función para descargar como Word
        function downloadAsWord() {
            try {
                const container = document.querySelector('.container');
                if (!container) {
                    alert('No se encontró el contenido para exportar');
                    return;
                }

                // Obtener el HTML completo
                const html = container.innerHTML;

                // Crear documento Word en formato OOXML
                const docContent = `<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<?mso-application progid="Word.Document"?>
<html xmlns:v="urn:schemas-microsoft-com:vml"
 xmlns:o="urn:schemas-microsoft-com:office:office"
 xmlns:w="urn:schemas-microsoft-com:office:word"
 xmlns:x="urn:schemas-microsoft-com:office:excel"
 xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
 xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 16">
<meta name=Originator content="Microsoft Word 16">
<link rel=File-List href="filelist.xml">
<title>Reporte Final - Análisis de sentimientos en versos</title>
<o:DocumentProperties>
 <o:Author>Erik I. Osornio Botello</o:Author>
 <o:LastAuthor>Erik I. Osornio Botello</o:LastAuthor>
 <o:Created>2025-10-16T00:00:00Z</o:Created>
 <o:LastSaved>2025-10-16T00:00:00Z</o:LastSaved>
 <o:Pages>1</o:Pages>
 <o:Words>1</o:Words>
 <o:Characters>1</o:Characters>
 <o:Lines>1</o:Lines>
 <o:Paragraphs>1</o:Paragraphs>
 <o:CharactersWithSpaces>1</o:CharactersWithSpaces>
 <o:Version>16.00</o:Version>
</o:DocumentProperties>
</head>
<body>
${html}
</body>
</html>`;

                // Crear Blob
                const blob = new Blob([docContent], { type: 'application/vnd.ms-word' });

                // Descargar
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;
                link.download = 'Reporte_Analisis_Sentimientos.doc';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);

                alert('✓ Descargado: Reporte_Analisis_Sentimientos.doc');
            } catch (error) {
                console.error('Error:', error);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }

        // Función alternativa: descargar como PDF
        function downloadAsPDF() {
            try {
                const element = document.querySelector('.container');
                const cloned = element.cloneNode(true);
                cloned.querySelectorAll('.download-container, .page-number, .header').forEach(el => el.remove());

                const opt = {
                    margin: 10,
                    filename: 'Reporte_Analisis_Sentimientos.pdf',
                    image: { type: 'jpeg', quality: 0.98 },
                    html2canvas: { scale: 2 },
                    jsPDF: { orientation: 'portrait', unit: 'mm', format: 'a4' }
                };

                html2pdf().set(opt).from(cloned).save();
                alert('Descargando como PDF...');
            } catch (err) {
                console.error('Error al descargar:', err);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }
    </script>
</head>

<body>
    <div class="container">
        <!-- COVER PAGE -->
        <div class="cover-page">
            <div class="cover-content">
                <div class="cover-logos">
                    <div class="cover-logo">
                        <img src="logo_cic.jpg" alt="Logo CIC - Centro de Investigación en Computación">
                    </div>
                    <div class="cover-logo">
                        <img src="logo_ipn.jpg" alt="Logo IPN - Instituto Politécnico Nacional">
                    </div>
                </div>
                <div class="cover-institution">
                    <h2>Centro de Investigación en Computación</h2>
                </div>

                <div class="cover-course">
                    <p>Diplomado en Inteligencia Artificial</p>
                </div>

                <div class="cover-main">
                    <h1>Análisis de sentimientos en versos</h1>
                    <p class="cover-subtitle">Implementación y Evaluación de Tres Enfoques de Clasificación</p>
                </div>

                <div class="cover-author">
                    <p><strong>Autor:</strong></p>
                    <p>Erik I. Osornio Botello</p>
                </div>

                <div class="cover-date">
                    <p><strong>Fecha de Entrega:</strong></p>
                    <p>16 de Octubre de 2025</p>
                </div>
            </div>
        </div>

        <!-- PAGE 2.1: Metodología -->
        <div class="page-section">
            <div class="section">
                <div class="section-title">🧭 Metodología</div>

                <div class="section-subtitle">Análisis de los datos y preprocesamiento</div>
                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                    El dataset <em>Poem Sentiment</em> presenta textos breves, con fuerte desbalance hacia la clase
                    <code>no_impact</code> y matices poéticos/arcaicos. Se implementaron dos estrategias de
                    preprocesamiento diferentes, de acuerdo con el tipo de modelo:
                </p>
                <ul style="line-height: 2;">
                    <li><strong>Baselines clásicos (MultinomialNB, Regresión Logística):</strong> preprocesamiento
                        optimizado para poesía inglesa antigua (expansión de contracciones arcaicas, normalización de
                        signos, limpieza suave). Tras tokenizar, se aplicó
                        <code>CountVectorizer(max_features=10000)</code>
                        y balanceo con <code>SMOTE</code> únicamente sobre el entrenamiento (excluyendo
                        <code>mixed</code>).
                        Esta decisión busca maximizar señal léxica útil para modelos basados en bolsa de palabras.
                    </li>
                    <li><strong>DeBERTa‑v3‑base (fine‑tuning):</strong> preprocesamiento <em>ligero y no
                            destructivo</em>
                        (normalizar comillas/guiones, eliminar duplicados, sin stemming ni stopwords), preservando los
                        matices poéticos para que el tokenizador subword capture semántica contextual. Se excluye la
                        clase
                        <code>mixed</code> en todos los splits.
                    </li>
                </ul>
                <div class="highlight-box">
                    <strong>Justificación de la elección:</strong> en enfoques clásicos conviene estandarizar la forma
                    superficial de las palabras para que la frecuencia sea informativa; en transformadores, el
                    tokenizador y el contexto atenúan la necesidad de limpiar agresivamente, y remover stopwords puede
                    incluso eliminar matices útiles en poesía.
                </div>

                <div class="section-subtitle">Modelos de IA empleados</div>
                <ul style="line-height: 2;">
                    <li><strong>Multinomial Naive Bayes:</strong> probabilístico, rápido y efectivo con conteos de
                        tokens; se ajustó y luego se <em>tuneó</em> el hiperparámetro <code>alpha</code> vía
                        <code>GridSearchCV</code>.
                    </li>
                    <li><strong>Regresión Logística:</strong> baseline lineal con <code>class_weight='balanced'</code>
                        para mitigar desbalance sin sobremuestreo.</li>
                    <li><strong>DeBERTa‑v3‑base:</strong> transformador preentrenado ajustado finamente con técnicas de
                        regularización (Focal Loss, label smoothing, early stopping) y optimizado por F1‑macro.</li>
                </ul>

                <div class="section-subtitle">Herramientas y tecnologías</div>
                <div class="specifications">
                    <div class="spec-card"><strong>Frameworks</strong> PyTorch, Hugging Face Transformers</div>
                    <div class="spec-card"><strong>ML clásico</strong> scikit‑learn, imbalanced‑learn</div>
                    <div class="spec-card"><strong>Gestión de datos</strong> pandas, numpy, datasets (HF)</div>
                    <div class="spec-card"><strong>Gráficos</strong> matplotlib, seaborn</div>
                    <div class="spec-card"><strong>NLP utilitario</strong> NLTK</div>
                    <div class="spec-card"><strong>I/O</strong> fastparquet/pyarrow (URIs hf://)</div>
                </div>
            </div>
        </div>

        <!-- TABLE OF CONTENTS -->
        <div style="page-break-after: always; padding: 40px 0;">
            <h2 style="font-size: 1.8em; color: #000; margin-bottom: 30px; text-align: center; font-weight: bold;">
                Índice</h2>
            <ol style="font-size: 12pt; line-height: 2; margin-left: 30px; color: #333;">
                <li>Introducción</li>
                <li>Metodología</li>
                <li>Datos</li>
                <li>Preprocesamiento</li>
                <li>Representación de texto</li>
                <li>Modelos implementados
                    <ol style="margin-top: 10px; margin-left: 20px;">
                        <li>Regresión Logística</li>
                        <li>Naive Bayes Multinomial</li>
                        <li>DeBERTa‑v3‑base (fine‑tuning)</li>
                    </ol>
                </li>
                <li>Entrenamiento y validación</li>
                <li>Métricas y evaluación</li>
                <li>Resultados</li>
                <li>Discusión</li>
                <li>Conclusiones y trabajo futuro</li>
                <li>Referencias</li>
            </ol>
        </div>

        <div class="download-container">
            <button class="download-btn" onclick="downloadAsWord()">📥 Descargar Word</button>
        </div>

        <!-- Main Content -->
        <div class="content">
            <!-- PAGE 1: Title and Author -->
            <div class="page-section">
                <div class="section" style="text-align: center; margin-bottom: 60px;">
                    <h2 style="font-size: 2.2em; color: #000; margin-bottom: 10px;">Análisis de sentimientos en versos
                    </h2>
                    <p style="font-size: 1.2em; color: #000; margin-bottom: 30px;"><strong>Autor:</strong> Erik I.
                        Osornio Botello</p>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; max-width: 800px; margin: 0 auto;">
                        <h3 style="color: #000; margin-bottom: 15px;">Resumen</h3>
                        <p style="text-align: justify; line-height: 1.8; color: #333;">
                            Este documento describe el desarrollo, implementación y evaluación de un sistema de análisis
                            de sentimientos sobre versos del dataset Poem Sentiment. Se comparan <strong>baselines
                                clásicos</strong>
                            (Regresión Logística y Naive Bayes Multinomial con CountVectorizer+SMOTE) frente a un
                            <strong>modelo preentrenado DeBERTa‑v3‑base</strong> ajustado finamente. Se detalla el flujo
                            completo: exploración y limpieza de datos, diferencias de preprocesamiento por enfoque,
                            entrenamiento, optimización de hiperparámetros, evaluación y discusión de resultados.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 2: Introduction Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📋 1. Introducción</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        El análisis de sentimientos busca asignar una polaridad (por ejemplo: positiva, negativa,
                        neutral) a textos.
                        En este proyecto se implementan tres enfoques que representan paradigmas distintos: modelos
                        lineales probabilísticos
                        (Regresión Logística), modelos de probabilidades condicionales con suposiciones de independencia
                        (Naive Bayes Multinomial)
                        y un transformador preentrenado (DeBERTa‑v3‑base). Se discute su preparación,
                        rendimiento y trade-offs.
                    </p>

                    <div class="section-subtitle">Objetivos</div>
                    <ul style="line-height: 2;">
                        <li>Construir y comparar tres modelos de análisis de sentimientos.</li>
                        <li>Evaluar rendimiento con métricas estándar (accuracy, precision, recall, F1, AUC cuando
                            aplique).</li>
                        <li>Documentar decisiones de diseño y parámetros.</li>
                    </ul>

                    <div class="section-subtitle">Marco de Referencia</div>
                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <p style="margin-bottom: 12px;">
                            <strong>📋 Indicaciones del Proyecto:</strong> Este proyecto se fundamenta en las
                            indicaciones
                            especificadas en el documento <em>Indicaciones Proyecto Poemas.pdf</em>, el cual establece
                            que:
                        </p>
                        <p
                            style="margin-bottom: 12px; padding-left: 15px; border-left: 3px solid #C41E3A; margin-left: 0;">
                            <strong>"Este proyecto es un ejercicio de aprendizaje supervisado. La idea general consiste
                                en
                                implementar tres clasificadores de texto para el problema de análisis de sentimientos en
                                versos de poemas."</strong>
                        </p>
                        <p>
                            <strong>Clases del Problema:</strong> El marco original define tres categorías de
                            sentimiento (positivo, negativo
                            o neutral), aunque en la práctica el dataset utilizado incluye cuatro clases: Positivo,
                            Negativo, Mixto y No impacto.
                            La estructura de tres clasificadores y el enfoque de aprendizaje supervisado se mantienen
                            como eje central de
                            la implementación.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 3: Data Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📊 2. Datos</div>

                    <div class="section-subtitle">Descripción del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        <strong>Fuente:</strong> Para este proyecto se utilizó el dataset <em>Poem Sentiment</em> del
                        repositorio de Google Research,
                        disponible en Hugging Face (hf://datasets/google-research-datasets/poem_sentiment). Este
                        conjunto de datos consiste en versos
                        de poemas extraídos de Project Gutenberg, etiquetados según el sentimiento que transmiten.
                    </p>

                    <div class="spec-card">
                        <strong>📈 Características principales:</strong>
                        <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                            <li><strong>Número total de ejemplos:</strong> 1,101 versos</li>
                            <li><strong>Idioma:</strong> Textos en inglés</li>
                            <li><strong>Tamaño:</strong> Dataset pequeño, puede dificultar la generalización al entrenar
                                modelos complejos desde cero. No obstante, con transformadores preentrenados y técnicas
                                de regularización (early stopping, class weights/Focal Loss, label smoothing) es posible
                                lograr buen desempeño.</li>
                            <li><strong>Balanceo de Clases:</strong> Se aplicaron técnicas de balanceo: SMOTE en modelos
                                clásicos (Naive Bayes, Logistic Regression) y Focal Loss con class weights en DeBERTa
                                para mitigar el desbalance inherente del dataset.</li>
                        </ul>
                    </div>

                    <div class="section-subtitle">Clases de Sentimiento</div>
                    <ul style="line-height: 2;">
                        <li><strong>Positivo:</strong> Versos con emociones positivas</li>
                        <li><strong>Negativo:</strong> Versos con emociones negativas</li>
                        <li><strong>Mixto:</strong> Versos que combinan emociones positivas y negativas</li>
                        <li><strong>No impacto:</strong> Versos que no presentan un sentimiento claro</li>
                    </ul>

                    <div class="section-subtitle">Columnas del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        Este conjunto de datos consta de versos de poemas extraídos de Project Gutenberg, etiquetados
                        según el sentimiento que transmiten.
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>verse_text:</strong> Contiene el texto del verso del poema</li>
                        <li><strong>label:</strong> Indica la categoría de sentimiento del verso</li>
                    </ul>

                    <div class="section-subtitle">Exploración Inicial</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        En la fase de exploración, no se encontraron valores nulos. El histograma de las longitudes por
                        clase se encuentra representado en la Ilustración 2.
                    </p>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="verse_lengths_distribution.png"
                            alt="Gráfico de Distribución de Longitudes de Versos por Clase"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Ilustración 1. Distribución de longitudes por clase</p>
                    </div>

                    <p style="text-align: justify; line-height: 1.5; margin-top: 20px;">
                        La figura muestra la distribución de la longitud de los versos según su sentimiento. Se observa
                        que la mayoría de los versos tienen entre 30 y 50 palabras,
                        con predominancia de la clase no impact. Las clases minoritarias (mixed, positivo, negativo)
                        están menos representadas, lo que refuerza el desbalance del dataset.
                        Esta distribución sugiere que los modelos podrían aprender primero la clase mayoritaria y que
                        los ejemplos muy largos son poco frecuentes y podrían considerarse outliers.
                    </p>

                    <div class="section-subtitle">División de Datos</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Conjunto</th>
                                <th>Número de Ejemplos</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Entrenamiento</strong></td>
                                <td>892 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Validación</strong></td>
                                <td>105 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Test</strong></td>
                                <td>104 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Total</strong></td>
                                <td>1,101 ejemplos</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="section-subtitle">Distribución de Clases (Entrenamiento Original)</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                                <th>Porcentaje</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>555</td>
                                <td>62.2%</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>155</td>
                                <td>17.4%</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>133</td>
                                <td>14.9%</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>49</td>
                                <td>5.5%</td>
                            </tr>
                        </tbody>
                    </table>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="sentiment_distribution.png"
                            alt="Gráfico de Distribución de Clases en Datos de Entrenamiento"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Figura 1: Distribución de Sentimientos en los Datos de Entrenamiento Original</p>
                    </div>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <strong>⚠️ Problema de Desbalance:</strong> La mayoría de los versos pertenecen a la clase "No
                        impacto",
                        mientras que la clase "Mixto" tiene muy pocos ejemplos. Este desbalance puede generar:
                        <ul style="margin-left: 20px; margin-top: 10px; margin-bottom: 10px; line-height: 1.8;">
                            <li><strong>Bias hacia la clase mayoritaria:</strong> Los modelos tienden a predecir con
                                mayor frecuencia la clase predominante (No impacto), lo que puede inflar el accuracy
                                aparente, pero reducir la capacidad de identificar correctamente las clases
                                minoritarias.</li>
                            <li><strong>Problemas de generalización en modelos complejos:</strong> Las redes
                                neuronales pueden sobreajustar fácilmente a la clase mayoritaria, especialmente cuando
                                el dataset es pequeño. En este caso, modelos complejos pueden aprender patrones sesgados
                                en lugar de representaciones robustas de todas las clases.</li>
                            <li><strong>Métricas poco confiables para clases minoritarias:</strong> Las métricas de
                                rendimiento pueden ser engañosas si se interpretan sin considerar el desbalance.</li>
                        </ul>
                        <p style="margin-top: 12px; text-align: justify; line-height: 1.6; font-size: 11pt;">
                            Dado el tamaño reducido y el desbalance, estos conjuntos pueden no ser representativos de la
                            distribución real de clases.
                            Esto significa que las métricas de evaluación (accuracy, F1, recall, precision) pueden ser
                            ruidosas y poco confiables,
                            especialmente para las clases minoritarias como Mixto y Positivo.
                        </p>
                    </div>

                    <div class="section-subtitle">Estrategias de Mitigación</div>
                    <ul style="line-height: 2;">
                        <li><strong>SMOTE (Modelos Clásicos):</strong> Aplicada en el entrenamiento de Naive Bayes y
                            Logistic Regression para sobremuestreo sintético y balanceo de clases minoritarias</li>
                        <li><strong>Focal Loss + Class weights (DeBERTa):</strong> Pesos por clase en el transformador
                            (DeBERTa) mediante Focal Loss (γ=1.5) + class weights para penalizar predicciones
                            incorrectas de clases minoritarias y mejorar generalización</li>
                    </ul>

                    <div class="section-subtitle">Distribución de Clases (Post Balanceo con SMOTE)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        <strong>Modelos Clásicos (Naive Bayes, Logistic Regression):</strong> Se aplicó SMOTE en el
                        conjunto de entrenamiento para generar muestras sintéticas de clases minoritarias y lograr
                        balanceo perfecto entre las tres clases.
                    </p>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Técnica</th>
                                <th>Negativo</th>
                                <th>Positivo</th>
                                <th>No impacto</th>
                                <th>Total</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr style="background: #fff3cd;">
                                <td><strong>SMOTE (Entrenamiento) </strong></td>
                                <td>555</td>
                                <td>555</td>
                                <td>555</td>
                                <td>1,665</td>
                            </tr>
                        </tbody>
                    </table>
                    <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                        SMOTE generó 1,665 muestras de entrenamiento perfectamente balanceadas (555 por clase) a partir
                        de 843 originales.</p>

                    <div style="height: 20px;"></div>

                    <div class="section-subtitle">Exclusión de la clase "Mixta" (Mixed) en Evaluación</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        La clase "mixed" (label=3) fue excluida de todos los modelos tanto en entrenamiento como en
                        evaluación.
                        Esta decisión se basa en tres razones fundamentales:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Distribución minoritaria:</strong> La clase "mixed" representa solo 5.5% del set de
                            entrenamiento,
                            lo que la hace altamente minoritaria y dificulta el entrenamiento robusto.</li>
                        <li><strong>Ambigüedad conceptual:</strong> Esta clase agrupa versos con sentimientos
                            contradictorios o ambiguos,
                            donde coexisten emociones positivas y negativas simultáneamente. Para una aplicación
                            práctica de análisis
                            de sentimientos en poesía, es más útil clasificar en tres categorías bien definidas
                            (negativo, positivo, sin impacto).</li>
                        <li><strong>Mejora de robustez del modelo:</strong> Excluir la clase "mixed" permite un problema
                            de clasificación
                            más claro y robusto, centrado en sentimientos claramente expresados, lo que mejora
                            significativamente las
                            métricas de desempeño y la interpretabilidad de los resultados.</li>
                    </ul>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Por lo tanto, todos los resultados reportados (F1-macro, exactitud, matrices de confusión, etc.)
                        se calculan
                        considerando únicamente las tres clases principales: negativo, positivo y sin impacto.
                    </p>
                </div>
            </div>

            <!-- PAGE 4: Preprocesamiento -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📝 3. Preprocesamiento</div>

                    <div class="section-subtitle">Preprocesamiento para Modelos Clásicos (NB y Regresión Logística)
                    </div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El preprocesamiento aplicado ha sido cuidadosamente diseñado para optimizar la clasificación de
                        sentimientos en poesía inglesa antigua (siglos XVII-XIX), equilibrando la limpieza textual con
                        la preservación de características semánticas relevantes. A diferencia de los enfoques estándar
                        que aplican normalización agresiva, nuestra estrategia reconoce que el lenguaje poético arcaico
                        contiene matices significativos para la detección de sentimientos.
                    </p>

                    <ul style="line-height: 2;">
                        <li><strong>Preservación del contexto poético:</strong> El enfoque mantiene palabras arcaicas y
                            poéticas (como "doth", "hath", "ne'er") que, aunque no sean comunes en el inglés moderno,
                            poseen un alto valor predictivo para la clasificación de sentimientos en textos históricos.
                            Estas palabras no se eliminan como stopwords, ya que a menudo aparecen en contextos emotivos
                            específicos que el modelo necesita capturar.</li>

                        <li><strong>Normalización de contracciones antiguas:</strong> Se expandieron contracciones
                            arcaicas ("'twas" → "it was", "o'er" → "over") a palabras completas para mejorar la
                            representación vectorial sin perder información léxica. Esta técnica aumenta la consistencia
                            del vocabulario sin introducir ambigüedad, permitiendo que el vectorizador de conteo
                            (CountVectorizer) capte patrones más robustos.</li>

                        <li><strong>Limpieza moderada de puntuación:</strong> Se normalizó la puntuación de manera
                            selectiva, removiendo caracteres especiales y de formato histórico, pero manteniendo la
                            estructura de oraciones. Esta aproximación evita la pérdida de información contextual que
                            podría ser relevante para modelos basados en bolsa de palabras, donde la proximidad léxica
                            importa.</li>

                        <li><strong>Vectorización con CountVectorizer y balanceo SMOTE:</strong> Después del
                            preprocesamiento, se utilizó CountVectorizer con un vocabulario máximo de 10,000 features
                            para capturar términos frecuentes relevantes. Aplicamos SMOTE solo en el conjunto de
                            entrenamiento para corregir el desbalance de clases de forma sintética, evitando sobreajuste
                            al no modificar conjuntos de validación y prueba.</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este diseño integrado maximiza la capacidad del modelo para distinguir entre sentimientos en
                        textos antiguos, priorizando la precisión sobre la simplicidad de preprocesamiento.
                    </p>

                    <div class="section-subtitle">Implementación: Función preprocess_poetry_text</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        La siguiente función implementa esta estrategia de preprocesamiento optimizada para poesía:
                    </p>

                    <div class="spec-card">
                        <strong>📝 Ejemplos de Preprocesamiento:</strong>
                        <div
                            style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                            <p><strong>Original (0):</strong> "with pale blue berries. in these peaceful shades--"</p>
                            <p><strong>Procesado:</strong> "with pale blue berries in these peaceful shades"</p>
                            <hr style="border: none; border-top: 1px solid #ddd; margin: 10px 0;">
                            <p><strong>Original (1):</strong> "it flows so long as falls the rain,"</p>
                            <p><strong>Procesado:</strong> "it flows so long as falls the rain"</p>
                            <hr style="border: none; border-top: 1px solid #ddd; margin: 10px 0;">
                            <p><strong>Original (2):</strong> "and that is why, the lonesome day,"</p>
                            <p><strong>Procesado:</strong> "and that is why the lonesome day"</p>
                        </div>
                    </div>

                    <div style="height: 20px; clear: both;"></div>



                    <div class="section-subtitle">Preprocesamiento en DeBERTa-v3-base</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El preprocesamiento aplicado en DeBERTa-v3-base es <strong>ligero y no destructivo</strong>,
                        diseñado específicamente para preservar las características estilísticas y semánticas de la
                        poesía:
                    </p>

                    <ul style="line-height: 2;">
                        <li><strong>Operaciones realizadas:</strong>
                            <ul style="margin-top: 8px; margin-left: 20px;">
                                <li>Normalización de comillas y guiones: convierte variantes Unicode (", —, –) a ASCII
                                    estándar para evitar tokens raros</li>
                                <li>Colapso de espacios múltiples y recorte de espacios al inicio/final</li>
                                <li>Eliminación de versos duplicados por coincidencia exacta</li>
                            </ul>
                        </li>
                        <li><strong>Decisiones importantes:</strong>
                            <ul style="margin-top: 8px; margin-left: 20px;">
                                <li><strong>Sin stemming ni stopwords:</strong> En poesía, la morfología completa y
                                    palabras aparentemente "vacías" portan matices de sentimiento. Removerlas degrada la
                                    señal</li>
                                <li><strong>Sin lowercasing forzado:</strong> El tokenizador subword (BPE) de DeBERTa
                                    maneja mayúsculas; además, en poesía las mayúsculas pueden tener valor estilístico
                                </li>
                            </ul>
                        </li>
                    </ul>

                    <div class="section-subtitle">Técnicas de Balanceo de Clases</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Dado el desbalance del dataset,
                        se aplicaron técnicas específicas de balanceo según el tipo de modelo:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Selección de clases minoritarias:</strong> Se identifican las clases que tienen
                            pocas muestras (por ejemplo: “negative”, “positive” y “mixed”).</li>
                        <li><strong>SMOTE (Synthetic Minority Over-sampling Technique):</strong> Para los modelos
                            clásicos (Multinomial Naive Bayes y Regresión Logística), se aplicó SMOTE exclusivamente en
                            el conjunto de entrenamiento para generar sintéticamente nuevas muestras de las clases
                            minoritarias. Esto corrige el desbalance sin perder información, permitiendo que los modelos
                            aprendan a distinguir mejor entre sentimientos.</li>
                        <li><strong>Focal Loss y Class Weights:</strong> Para DeBERTa-v3-base, se utilizó Focal Loss
                            combinada con pesos de clases para manejar el desbalance. Este enfoque es más eficaz en
                            redes neuronales profundas, ya que el Focal Loss penaliza más los ejemplos mal clasificados
                            de las clases minoritarias.</li>
                        <li><strong>Preservación de sets de validación y prueba:</strong> Tanto SMOTE como los pesos de
                            clase se aplicaron únicamente al conjunto de entrenamiento. Los conjuntos de validación y
                            prueba mantuvieron su distribución original para garantizar evaluación realista de la
                            capacidad de generalización del modelo.</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este enfoque diferenciado permite optimizar cada modelo de acuerdo a sus características,
                        mejorando el desempeño sin comprometer la evaluación independiente.
                    </p>

                </div>

                <!-- PAGE 5: Text Representation -->
                <div class="page-section">


                    <!-- PAGE 5.1: Implementación -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">🛠️ Implementación</div>

                            <div class="section-subtitle">Pipeline de desarrollo</div>
                            <div class="structure-list">
                                <div class="structure-item">
                                    <h4>Baselines clásicos (NB / Reg. Logística)</h4>
                                    <div class="structure-description">
                                        <ol>
                                            <li>Exploración y división de datos (train/val/test) desde Hugging Face</li>
                                            <li>Preprocesamiento optimizado para poesía (expansión de contracciones,
                                                limpieza suave)</li>
                                            <li>Vectorización con <code>CountVectorizer(max_features=10000)</code></li>
                                            <li>Exclusión de clase <code>mixed</code> y balanceo con <code>SMOTE</code>
                                                (solo train)</li>
                                            <li>Entrenamiento de <code>MultinomialNB</code> y
                                                <code>LogisticRegression</code>
                                            </li>
                                            <li>Ajuste de <code>alpha</code> (NB) con <code>GridSearchCV</code></li>
                                            <li>Evaluación macro‑F1 (sin clase <code>mixed</code>) y matrices de
                                                confusión</li>
                                        </ol>
                                    </div>
                                </div>
                                <div class="structure-item">
                                    <h4>DeBERTa‑v3‑base (fine‑tuning)</h4>
                                    <div class="structure-description">
                                        <ol>
                                            <li>Preprocesamiento ligero (normalizar comillas/guiones, deduplicar)</li>
                                            <li>Exclusión de clase <code>mixed</code> en todos los splits</li>
                                            <li>Tokenización subword (max_len=128) y creación de datasets de HF</li>
                                            <li>Hiperparámetros: lr=2e‑5, batch=16, epochs=6, warmup=0.05</li>
                                            <li>Regularización: Focal Loss (γ=1.5) + class weights, label smoothing=0.1
                                            </li>
                                            <li>Entrenamiento con Trainer optimizando F1‑macro + early stopping</li>
                                            <li>Evaluación en validación y test; análisis por clase y matriz de
                                                confusión</li>
                                        </ol>
                                    </div>
                                </div>
                            </div>

                            <div class="section-subtitle" style="margin-top: 25px;">Optimización y ajustes
                                (hiperparámetros)</div>
                            <div class="specifications">
                                <div class="spec-card">
                                    <strong>MultinomialNB</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li><code>GridSearchCV</code> sobre
                                            <code>alpha ∈ {0.01, 0.1, 0.5, 1.0, 5.0, 10.0}</code>
                                        </li>
                                        <li><em>Scoring</em>: F1‑macro, CV=5</li>
                                    </ul>
                                </div>
                                <div class="spec-card">
                                    <strong>Regresión Logística</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li><code>class_weight='balanced'</code>, <code>max_iter=2000</code>,
                                            <code>solver='liblinear'</code>
                                        </li>
                                    </ul>
                                </div>
                                <div class="spec-card">
                                    <strong>DeBERTa‑v3‑base</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li>Focal Loss (γ=1.5) + <em>class weights</em>, <em>label smoothing</em>=0.1
                                        </li>
                                        <li>lr=2e‑5, batch=16, epochs=6, warmup_ratio=0.05, early stopping (patience=3)
                                        </li>
                                        <li>Métrica objetivo: F1‑macro</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- PAGE 6: Models -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">🤖 5. Modelos Implementados</div>

                            <div class="section-subtitle">5.1 Regresión Logística</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                La regresión logística fue seleccionada por su capacidad para manejar eficazmente
                                representaciones vectorizadas
                                del texto. Este modelo aprende a estimar la probabilidad de pertenencia a cada clase
                                mediante una combinación
                                lineal de características, lo cual resulta apropiado en problemas de análisis de texto
                                donde la presencia
                                o frecuencia de ciertas palabras suele correlacionarse directamente con el sentimiento.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Permite incorporar pesos para clases minoritarias (class weights)</li>
                                    <li>Naturaleza probabilística facilita interpretar confianza</li>
                                    <li>Bajo costo computacional y estable</li>
                                    <li>Excelente baseline para comparar con modelos más complejos</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>

                            <pre class="code-block"><code>lr_model = LogisticRegression(
    random_state=SEED,
    max_iter=2000,
    class_weight='balanced',
    C=1.0,
    solver='liblinear'
)</code></pre>

                            <div class="section-subtitle">5.2 Naive Bayes Multinomial</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                El modelo Multinomial Naive Bayes se utiliza, en este caso, con ajuste de hiperparámetros mediante
                                búsqueda en cuadrícula (GridSearchCV) para optimizar el parámetro de suavizado alpha.
                                Este enfoque probabilístico calcula probabilidades condicionales de palabras para cada
                                clase, permitiendo una clasificación eficiente incluso con vocabularios grandes. La
                                búsqueda exhaustiva de alpha mediante validación cruzada de 5 folds maximiza el F1-score
                                macro, encontrando el balance óptimo entre sesgo y varianza del modelo.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li><strong>Eficiencia Computacional:</strong> Entrena extremadamente rápido con vocabularios grandes (10,000 features). GridSearchCV con validación cruzada de 5 folds completa en segundos, permitiendo iteración rápida sin costo computacional prohibitivo.</li>
                                    <li><strong>Optimización Automática de Hiperparámetros:</strong> GridSearchCV busca exhaustivamente el mejor alpha (suavizado) usando validación cruzada, garantizando máximo potencial sin necesidad de ajuste manual.</li>
                                    <li><strong>Interpretabilidad:</strong> Las probabilidades condicionales palabra-clase son directamente interpretables. Permite identificar qué palabras contribuyen más a cada sentimiento, facilitando validación de resultados.</li>
                                    <li><strong>Robustez con Datos Desbalanceados:</strong> Al entrenar sobre datos balanceados con SMOTE, mantiene rendimiento equilibrado en todas las clases. La métrica F1-macro asegura que ninguna clase sea penalizada, resultando en F1-scores altos (&gt;0.80).</li>
                                </ul>
                            </div>
                            
                            <pre class="code-block"><code>grid_search = GridSearchCV(
    estimator=MultinomialNB(),
    param_grid=param_grid,
    scoring='f1_macro',
    cv=5,
    n_jobs=-1,
    verbose=1
)</code></pre>
                            
                            <div class="section-subtitle">5.3 DeBERTa‑v3‑base (fine‑tuning)</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                Los transformadores preentrenados como <strong>DeBERTa‑v3‑base</strong> capturan
                                relaciones contextuales y semántica a nivel sub‑palabra mediante auto‑atención.
                                En este trabajo se realizó <em>fine‑tuning</em> completo para el dataset Poem
                                Sentiment (excluyendo la clase <code>mixed</code>), optimizando la métrica
                                <strong>F1‑macro</strong> y usando técnicas de regularización para manejar el
                                desbalance y evitar sobreajuste.
                            </p>
                            <div class="spec-card">
                                <strong>Técnicas aplicadas</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Tokenización subword (max_len=128)</li>
                                    <li>Focal Loss (γ = 1.5) + <em>class weights</em></li>
                                    <li><em>Label smoothing</em> = 0.1</li>
                                    <li><em>Early stopping</em> (patience = 3)</li>
                                    <li>Optimización con Hugging Face Trainer por F1‑macro</li>
                                </ul>
                            </div>

                            <div class="spec-card" style="margin-top: 15px;">
                                <strong>Ventajas</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Captura dependencias largas y matices poéticos</li>
                                    <li>Robusto ante variaciones léxicas y de estilo</li>
                                    <li>Rendimiento superior en dominios de texto fino</li>
                                </ul>
                            </div>

                            <p style="margin-top: 15px;"><strong>Framework:</strong> PyTorch + Hugging Face Transformers
                            </p>
                            <p style="margin-top: 10px;"><strong>Hiperparámetros clave:</strong> lr=2e‑5, batch_size=16,
                                epochs=6,
                                weight_decay=0.01, warmup_ratio=0.05, max_len=128</p>

                        </div>

                        <!-- PAGE 7: Metrics and Training -->
                        <div class="page-section">
                            <div class="section">
                                <div class="section-title">📊 6. Entrenamiento, Validación y Métricas</div>
                                <div class="section-subtitle">Carga del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    El dataset se obtuvo desde el repositorio de Hugging Face utilizando pandas. Los
                                    archivos están disponibles en formato Parquet
                                    y se pueden cargar directamente usando la siguiente configuración:
                                </p>

                                <div
                                    style="background: #f8f9fa; padding: 20px; border-radius: 4px; margin: 20px 0; overflow-x: auto;">
                                    <code
                                        style="background: #f0f0f0; padding: 15px; border-radius: 4px; font-family: 'Courier New', monospace; display: block;">
                                        import pandas as pd<br>
                                        <br>
                                        splits = {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'train': 'data/train-00000-of-00001.parquet',<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'validation': 'data/validation-00000-of-00001.parquet',<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'test': 'data/test-00000-of-00001.parquet'<br>
                                        }<br>
                                        <br>
                                        df = pd.read_parquet(<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;"hf://datasets/google-research-datasets/poem_sentiment/" + splits["train"]<br>
                                        )
                                    </code>
                                </div>

                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    <strong>URL del Dataset:</strong> <a
                                        href="https://huggingface.co/datasets/google-research-datasets/poem_sentiment/viewer"
                                        target="_blank"
                                        style="color: #C41E3A; text-decoration: none;">https://huggingface.co/datasets/google-research-datasets/poem_sentiment/viewer</a>
                                </p>

                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Este método permite cargar directamente los splits de entrenamiento, validación y
                                    prueba en DataFrames de pandas,
                                    facilitando el preprocesamiento y manipulación de los datos para el análisis
                                    posterior.
                                </p>
                                <div class="section-subtitle">División del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utilizó la división estándar del dataset proporcionada por Hugging Face para
                                    garantizar coherencia
                                    y reproducibilidad de los resultados.
                                </p>

                                <div class="section-subtitle">Métricas de Evaluación</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utilizaron las siguientes métricas para evaluar el desempeño de los modelos:
                                </p>
                                <ul style="line-height: 2;">
                                    <li><strong>Accuracy:</strong> Proporción de predicciones correctas</li>
                                    <li><strong>Precision (macro avg):</strong> Promedio de precisión por clase</li>
                                    <li><strong>Recall (macro avg):</strong> Promedio de recall por clase</li>
                                    <li><strong>F1 (macro avg):</strong> Media armónica de precision y recall</li>
                                </ul>
                                <p style="text-align: justify; line-height: 1.8; margin-top: 15px;">
                                    <strong>Librerías utilizadas:</strong> sklearn.metrics.classification_report,
                                    confusion_matrix
                                </p>
                                <code
                                    style="background: #f0f0f0; padding: 15px; border-radius: 4px; font-family: 'Courier New', monospace; display: block; margin-top: 10px;">
                                from sklearn.metrics import classification_report, confusion_matrix

                                y_pred = clf.predict(X_test_counts)
                                print(classification_report(y_test, y_pred))

                                cm = confusion_matrix(y_test, y_pred)
                                </code>

                            </div>

                            <!-- PAGE 8: Results -->
                            <div class="page-section">
                                <div class="section">
                                    <div class="section-title">📈 7. Resultados</div>

                                    <div class="section-subtitle">Resultados principales (DeBERTa‑v3‑base)</div>
                                    <table class="format-table">
                                        <thead>
                                            <tr>
                                                <th>Conjunto</th>
                                                <th>Accuracy</th>
                                                <th>F1‑Macro</th>
                                                <th>F1‑Weighted</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <td><strong>Validación</strong></td>
                                                <td>0.9143</td>
                                                <td><strong>0.8903</strong></td>
                                                <td>0.9132</td>
                                            </tr>
                                            <tr>
                                                <td><strong>Test</strong></td>
                                                <td>0.9135</td>
                                                <td><strong>0.8909</strong></td>
                                                <td>0.9136</td>
                                            </tr>
                                        </tbody>
                                    </table>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #e8f5e9 0%, #ffffff 100%); border-left-color: #2e7d32; margin-top: 30px;">
                                        <strong>✓ Objetivo cumplido:</strong> Se alcanzó <strong>F1‑macro ≥
                                            0.85</strong> en Validación y Test con
                                        DeBERTa‑v3‑base, cumpliendo el objetivo del proyecto con margen.
                                    </div>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; margin-top: 30px;">
                                        <strong>Comparativa con baselines clásicos:</strong> Los enfoques con
                                        CountVectorizer (MultinomialNB / Regresión Logística)
                                        se usaron como líneas base sólidas, pero <em>no alcanzaron</em> el desempeño del
                                        transformador en F1‑macro. La elección de
                                        DeBERTa se justifica por su capacidad para capturar matices semánticos y de
                                        estilo propios de la poesía.
                                    </div>
                                </div>

                                <!-- PAGE 9: Discussion -->
                                <div class="page-section">
                                    <div class="section">
                                        <div class="section-title">💡 8. Discusión</div>

                                        <div class="section-subtitle">¿Qué se observa en los resultados?</div>
                                        <ul style="line-height: 2;">
                                            <li><strong>DeBERTa‑v3‑base</strong> alcanza F1‑macro ≈ 0.891 en Test,
                                                superando ampliamente a los baselines clásicos.</li>
                                            <li>Por clase (Test): <em>negative</em> logra <strong>recall ≈ 1.00</strong>
                                                (marcadores afectivos más explícitos);
                                                <em>positive</em> es la más desafiante (<strong>precision/recall ≈
                                                    0.81</strong>), con confusiones hacia
                                                <code>no_impact</code> cuando el verso es más descriptivo que
                                                valorativo; <em>no_impact</em> mantiene
                                                precisión alta (≈ 0.95) y recall ≈ 0.91.
                                            </li>
                                            <li>La combinación de <em>class weights</em> + Focal Loss + label smoothing
                                                favorece el balance entre clases bajo desbalance.</li>
                                        </ul>

                                        <div class="section-subtitle">¿Fue exitoso el entrenamiento?</div>
                                        <p style="text-align: justify; line-height: 1.8;">
                                            Sí. La métrica objetivo (<strong>F1‑macro ≥ 0.85</strong>) se cumplió con
                                            margen. Las curvas por época
                                            (con early stopping) y el uso de regularización indican un proceso estable y
                                            reproducible.
                                        </p>

                                        <div class="section-subtitle">Escenarios de uso</div>
                                        <ul style="line-height: 2;">
                                            <li>Curaduría y analítica de colecciones poéticas (tendencias afectivas por
                                                autor/época).</li>
                                            <li>Herramientas de apoyo editorial, talleres de escritura y análisis
                                                literario asistido.</li>
                                            <li>Estudios de marcadores afectivos y estilísticos en humanidades
                                                digitales.</li>
                                        </ul>

                                        <div class="section-subtitle">Limitaciones y mejoras</div>
                                        <ul style="line-height: 2;">
                                            <li><strong>Clase positive:</strong> aún mejorable con
                                                <em>augmentations</em> suaves o calibración de umbrales.
                                            </li>
                                            <li><strong>Generalización:</strong> ampliar datos o realizar
                                                <em>fine‑tuning</em> por dominio/autor.
                                            </li>
                                            <li><strong>Mixta (<code>mixed</code>):</strong> reincorporarla demandará
                                                rediseñar pérdidas/umbral o recolectar más muestras.</li>
                                            <li><strong>Recursos:</strong> modelos mayores (DeBERTa‑large,
                                                RoBERTa‑large) y <em>ensembles</em> podrían subir el techo de desempeño
                                                con mayor costo computacional.</li>
                                        </ul>
                                    </div>

                                    <!-- PAGE 10: Conclusions -->
                                    <div class="page-section">
                                        <div class="section">
                                            <div class="section-title">🎯 9. Conclusiones y Trabajo Futuro</div>

                                            <div class="section-subtitle">Conclusiones</div>
                                            <ul style="line-height: 2;">
                                                <li><strong>Objetivo cumplido:</strong> se alcanzó F1‑macro ≥ 0.85 con
                                                    DeBERTa‑v3‑base (F1‑macro Test ≈ 0.8909).</li>
                                                <li>La <strong>elección de preprocesamiento</strong> diferenciado fue
                                                    clave: limpieza ligera para el transformador y normalización léxica
                                                    + CountVectorizer para baselines.</li>
                                                <li>Los <strong>baselines clásicos</strong> sirvieron como referencia y
                                                    análisis de sensibilidad, pero el transformador capturó mejor los
                                                    matices poéticos.</li>
                                                <li><strong>Impacto profesional:</strong> este proyecto consolida el
                                                    manejo de pipelines de NLP modernos (Transformers) y comparativos
                                                    clásicos, útil para prototipado rápido y despliegue en analítica
                                                    textual.</li>
                                            </ul>

                                            <div class="section-subtitle">Trabajo futuro</div>
                                            <ul style="line-height: 2;">
                                                <li>Explorar <em>ensembles</em> de checkpoints/seeds y modelos mayores
                                                    (DeBERTa‑large, RoBERTa).</li>
                                                <li>Mejorar la clase <em>positive</em> con <em>augmentations</em> suaves
                                                    y calibración de umbrales.</li>
                                                <li>Reincorporar la clase <code>mixed</code> con estrategias de pérdida
                                                    (p. ej., <em>asymmetric loss</em>) o más datos.</li>
                                                <li>Preparar un demo de inferencia (Gradio/FastAPI) y monitoreo en
                                                    producción.</li>
                                            </ul>
                                        </div>

                                        <!-- PAGE 11: References & Footer -->
                                        <div class="page-section">
                                            <div class="section">
                                                <div class="section-title">📚 10. Referencias Bibliográficas</div>

                                                <div
                                                    style="background: #f8f9fa; padding: 25px; border-radius: 8px; line-height: 2;">
                                                    <p>Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011).
                                                        <em>Scikit-learn: Machine Learning in Python</em>.
                                                        Journal of Machine Learning Research, 12, 2825-2830.
                                                    </p>



                                                    <p>Google Research. (s.f.). <em>Poem sentiment</em> [Conjunto de
                                                        datos]. Hugging Face.
                                                        Disponible en:
                                                        https://huggingface.co/datasets/google-research-datasets/poem_sentiment
                                                    </p>

                                                    <p>Goodfellow, I., Bengio, Y., & Courville, A. (2016). <em>Deep
                                                            Learning</em>.
                                                        MIT Press. [Referencia para arquitecturas de redes neuronales]
                                                    </p>

                                                    <p>Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT:
                                                        Pre-training of Deep Bidirectional Transformers
                                                        for Language Understanding. arXiv preprint arXiv:1810.04805.</p>
                                                </div>
                                            </div>

                                            <!-- Footer -->
                                            <div class="footer">
                                                <p>📊 <span class="footer-highlight">Reporte Final: Análisis de
                                                        sentimientos en versos - Diplomado en Inteligencia
                                                        Artificial</span></p>
                                                <p style="font-size: 0.9em; color: #999;">Autor: Erik I. Osornio Botello
                                                </p>
                                                <p style="margin-top: 15px; color: #999; font-size: 0.85em;">
                                                    Este reporte presenta el desarrollo, implementación y evaluación de
                                                    un sistema completo de análisis de sentimientos
                                                    utilizando tres enfoques distintos.
                                                </p>
                                            </div>

                                            <div class="page-number"></div>
                                        </div>
                                    </div>
                                </div>
</body>

</html>