<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte Final - Curso de Inteligencia Artificial</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        p {
            text-align: justify;
            line-height: 1.5;
            font-size: 12pt;
        }

        body {
            font-family: Arial, sans-serif;
            font-size: 12pt;
            line-height: 1.5;
            color: #333;
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
            overflow: hidden;
            padding: 2.5cm;
        }

        /* Header */
        .header {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.95;
        }

        .header-logo {
            margin-bottom: 20px;
            font-size: 3em;
        }

        /* Main Content */
        .content {
            padding: 0;
            text-align: justify;
        }

        .section {
            margin-bottom: 50px;
            page-break-inside: avoid;
            page-break-after: auto;
        }

        .section-title {
            font-size: 14pt;
            color: #000;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #C41E3A;
            font-weight: bold;
            page-break-after: avoid;
        }

        .section-subtitle {
            font-size: 12pt;
            color: #000;
            margin-top: 30px;
            margin-bottom: 15px;
            font-weight: bold;
            font-style: italic;
            padding-left: 20px;
            border-left: 4px solid #C41E3A;
        }

        .intro-text {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-left: 5px solid #C41E3A;
            margin-bottom: 30px;
            line-height: 1.5;
            font-size: 12pt;
            text-align: justify;
        }

        /* Specifications */
        .specifications {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .spec-card {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #C41E3A;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .spec-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(196, 30, 58, 0.2);
        }

        .spec-card strong {
            color: #000;
            display: block;
            margin-bottom: 8px;
        }

        /* Lists */
        ul,
        ol {
            margin-left: 30px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 12px;
            line-height: 1.5;
            text-align: justify;
        }

        li strong {
            color: #4A4A4A;
        }

        /* Structure sections */
        .structure-list {
            background: #f8f9fa;
            padding: 30px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .structure-item {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 1px solid #e0e0e0;
        }

        .structure-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .structure-item h4 {
            color: #000;
            font-size: 1.15em;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
        }

        .structure-item h4:before {
            content: "‚ñ∏";
            margin-right: 10px;
            font-size: 1.3em;
            color: #4A4A4A;
        }

        .structure-description {
            margin-left: 20px;
            color: #666;
            line-height: 1.8;
        }

        /* Rubric */
        .rubric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .rubric-item {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 25px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(139, 21, 56, 0.2);
        }

        .rubric-percentage {
            font-size: 2.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .rubric-description {
            font-size: 0.95em;
            opacity: 0.95;
        }

        /* Deliverables */
        .deliverables {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 30px;
            border-radius: 8px;
            border: 2px solid #C41E3A;
        }

        .deliverable-item {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
            font-size: 1.05em;
        }

        .deliverable-item:last-child {
            margin-bottom: 0;
        }

        .deliverable-icon {
            width: 30px;
            height: 30px;
            background: #C41E3A;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 15px;
            font-weight: bold;
            flex-shrink: 0;
        }

        /* Format Table */
        .format-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            overflow: hidden;
        }

        .format-table th {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }

        .format-table td {
            padding: 15px;
            border-bottom: 1px solid #e0e0e0;
        }

        .format-table tr:hover {
            background: #f8f9fa;
        }

        .format-table tr:last-child td {
            border-bottom: none;
        }

        /* Footer */
        .footer {
            background: #f8f9fa;
            padding: 30px 40px;
            text-align: center;
            color: #666;
            border-top: 1px solid #e0e0e0;
        }

        .footer p {
            margin-bottom: 10px;
        }

        .footer-highlight {
            color: #4A4A4A;
            font-weight: bold;
        }

        /* Highlight boxes */
        .highlight-box {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            border-left: 4px solid #C41E3A;
            padding: 15px 20px;
            border-radius: 4px;
            margin: 20px 0;
            color: #000;
        }

        .highlight-box strong {
            color: #000;
        }

        /* Responsiveness */
        @media (max-width: 768px) {
            .header {
                padding: 40px 20px;
            }

            .header h1 {
                font-size: 1.8em;
            }

            .content {
                padding: 30px 20px;
                text-align: justify;
            }

            .section-title {
                font-size: 1.6em;
            }

            .specifications,
            .rubric-grid {
                grid-template-columns: 1fr;
            }

            .structure-item h4 {
                font-size: 1.05em;
            }

            .format-table {
                font-size: 0.9em;
            }

            .format-table th,
            .format-table td {
                padding: 10px;
            }

            p,
            li,
            td {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }
        }

        /* Animation */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .section {
            animation: fadeIn 0.6s ease-out;
        }

        .spec-card {
            animation: fadeIn 0.6s ease-out;
        }

        /* Print styles */
        @media print {
            body {
                background: white;
                padding: 2.5cm;
                margin: 0;
                font-size: 12pt;
                line-height: 1.5;
                counter-reset: page 1;
            }

            .container {
                box-shadow: none;
                border-radius: 0;
                padding: 0;
                max-width: 100%;
                margin: 0;
            }

            .header {
                page-break-after: avoid;
                padding: 30px 0;
            }

            .content {
                padding: 0;
                text-align: justify;
            }

            p,
            li,
            td,
            th {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }

            .section {
                page-break-inside: avoid;
            }

            @page {
                margin: 2.5cm;

                @bottom-center {
                    content: counter(page);
                    font-size: 12pt;
                    font-family: Arial, sans-serif;
                }
            }
        }

        /* Code styles */
        code {
            background: #f0f0f0;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d63384;
        }

        /* COVER PAGE STYLES */
        .cover-page {
            display: flex;
            align-items: flex-start;
            justify-content: center;
            min-height: 100vh;
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            color: #000;
            text-align: center;
            padding: 60px 60px 80px 60px;
            page-break-after: always;
            position: relative;
        }

        .cover-page::before {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #C41E3A, rgba(196, 30, 58, 0) 50%, rgba(196, 30, 58, 0));
        }

        .cover-page::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 2px;
            background: linear-gradient(90deg, rgba(196, 30, 58, 0), #C41E3A 50%, rgba(196, 30, 58, 0));
        }

        .cover-content {
            max-width: 600px;
            animation: fadeInCover 0.8s ease;
        }

        @keyframes fadeInCover {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .cover-logos {
            display: flex;
            justify-content: space-between;
            gap: 0;
            margin-bottom: 50px;
            align-items: center;
            width: 100%;
            max-width: none;
            margin-left: 0;
            margin-right: 0;
        }

        .cover-logo {
            flex: 0 0 auto;
            background: rgba(139, 21, 56, 0.05);
            padding: 15px;
            border-radius: 8px;
            border: 1px solid rgba(139, 21, 56, 0.2);
            backdrop-filter: blur(10px);
        }

        .cover-logo img {
            max-width: 100px;
            height: auto;
            filter: brightness(1);
            transition: transform 0.3s ease;
        }

        .cover-logo img:hover {
            transform: scale(1.05);
        }

        .cover-institution {
            margin-bottom: 60px;
            border-bottom: 2px solid #C41E3A;
            padding-bottom: 25px;
            letter-spacing: 0.5px;
        }

        .cover-institution h2 {
            font-size: 2em;
            margin-bottom: 8px;
            font-weight: 700;
            letter-spacing: 0.3px;
            line-height: 1.2;
            color: #000;
        }

        .cover-institution p {
            font-size: 1.15em;
            opacity: 1;
            font-weight: 500;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-course {
            margin-bottom: 90px;
            font-size: 1.25em;
            font-style: italic;
            opacity: 1;
            font-weight: 400;
            letter-spacing: 0.3px;
            color: #000;
        }

        .cover-main {
            margin-bottom: 100px;
        }

        .cover-main h1 {
            font-size: 3.5em;
            margin-bottom: 20px;
            font-weight: 800;
            text-shadow: none;
            line-height: 1.1;
            letter-spacing: -0.5px;
            color: #000;
        }

        .cover-subtitle {
            font-size: 1.4em;
            opacity: 1;
            font-style: italic;
            line-height: 1.5;
            font-weight: 300;
            color: #000;
        }

        .cover-author {
            margin-bottom: 70px;
            font-size: 1.1em;
        }

        .cover-author p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-author p:last-child {
            font-size: 1.4em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-date {
            font-size: 1.1em;
            margin-top: 80px;
            padding-top: 30px;
            border-top: 1px solid #C41E3A;
        }

        .cover-date p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-date p:last-child {
            font-size: 1.3em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        /* Print styles for cover */
        @media print {
            .cover-page {
                page-break-after: always;
                background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
                color: white;
            }
        }

        code-block {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            display: block;
            overflow-x: auto;
        }

        /* Footer con numeraci√≥n de p√°gina */
        .page-number {
            text-align: center;
            padding: 20px 0;
            color: #999;
            font-size: 11pt;
            border-top: 1px solid #ddd;
            margin-top: 40px;
        }

        @media print {
            .page-number {
                display: none;
            }
        }

        /* Download Button */
        .download-container {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
        }

        .download-btn {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: bold;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(139, 21, 56, 0.3);
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .download-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(139, 21, 56, 0.4);
        }

        .download-btn:active {
            transform: translateY(0);
        }

        @media print {
            .download-container {
                display: none;
            }
        }

        /* Page Break Control */
        .page-section {
            page-break-after: always;
            page-break-inside: avoid;
            padding: 20px 0;
            margin-bottom: 1cm;
        }

        .page-section:last-child {
            page-break-after: avoid;
        }

        .section-page-break {
            page-break-after: always;
        }

        /* Evitar rupturas dentro de elementos */
        .page-section .section {
            page-break-inside: avoid;
        }

        .section-subtitle {
            page-break-after: avoid;
        }

        .section-title {
            page-break-after: avoid;
        }

        ul,
        ol {
            page-break-inside: avoid;
        }

        .format-table {
            page-break-inside: avoid;
        }

        .spec-card {
            page-break-inside: avoid;
        }

        .highlight-box {
            page-break-inside: avoid;
        }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script src="https://unpkg.com/docx@8.12.6/build/index.js"></script>
    <script>
        // Script para numeraci√≥n de p√°ginas
        window.addEventListener('load', function () {
            // En navegador, agregar numeraci√≥n visible
            const pageNumbers = document.querySelectorAll('.page-number');
            if (pageNumbers.length > 0) {
                let pageCount = 1;
                pageNumbers.forEach((element, index) => {
                    element.textContent = 'P√°gina ' + (index + 1);
                });
            }
        });

        // Funci√≥n para descargar como Word
        function downloadAsWord() {
            try {
                const container = document.querySelector('.container');
                if (!container) {
                    alert('No se encontr√≥ el contenido para exportar');
                    return;
                }

                // Obtener el HTML completo
                const html = container.innerHTML;

                // Crear documento Word en formato OOXML
                const docContent = `<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<?mso-application progid="Word.Document"?>
<html xmlns:v="urn:schemas-microsoft-com:vml"
 xmlns:o="urn:schemas-microsoft-com:office:office"
 xmlns:w="urn:schemas-microsoft-com:office:word"
 xmlns:x="urn:schemas-microsoft-com:office:excel"
 xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
 xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 16">
<meta name=Originator content="Microsoft Word 16">
<link rel=File-List href="filelist.xml">
<title>Reporte Final - An√°lisis de sentimientos en versos</title>
<o:DocumentProperties>
 <o:Author>Erik I. Osornio Botello</o:Author>
 <o:LastAuthor>Erik I. Osornio Botello</o:LastAuthor>
 <o:Created>2025-10-16T00:00:00Z</o:Created>
 <o:LastSaved>2025-10-16T00:00:00Z</o:LastSaved>
 <o:Pages>1</o:Pages>
 <o:Words>1</o:Words>
 <o:Characters>1</o:Characters>
 <o:Lines>1</o:Lines>
 <o:Paragraphs>1</o:Paragraphs>
 <o:CharactersWithSpaces>1</o:CharactersWithSpaces>
 <o:Version>16.00</o:Version>
</o:DocumentProperties>
</head>
<body>
${html}
</body>
</html>`;

                // Crear Blob
                const blob = new Blob([docContent], { type: 'application/vnd.ms-word' });

                // Descargar
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;
                link.download = 'Reporte_Analisis_Sentimientos.doc';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);

                alert('‚úì Descargado: Reporte_Analisis_Sentimientos.doc');
            } catch (error) {
                console.error('Error:', error);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }

        // Funci√≥n alternativa: descargar como PDF
        function downloadAsPDF() {
            try {
                const element = document.querySelector('.container');
                const cloned = element.cloneNode(true);
                cloned.querySelectorAll('.download-container, .page-number, .header').forEach(el => el.remove());

                const opt = {
                    margin: 10,
                    filename: 'Reporte_Analisis_Sentimientos.pdf',
                    image: { type: 'jpeg', quality: 0.98 },
                    html2canvas: { scale: 2 },
                    jsPDF: { orientation: 'portrait', unit: 'mm', format: 'a4' }
                };

                html2pdf().set(opt).from(cloned).save();
                alert('Descargando como PDF...');
            } catch (err) {
                console.error('Error al descargar:', err);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }
    </script>
</head>

<body>
    <div class="container">
        <!-- COVER PAGE -->
        <div class="cover-page">
            <div class="cover-content">
                <div class="cover-logos">
                    <div class="cover-logo">
                        <img src="logo_cic.jpg" alt="Logo CIC - Centro de Investigaci√≥n en Computaci√≥n">
                    </div>
                    <div class="cover-logo">
                        <img src="logo_ipn.jpg" alt="Logo IPN - Instituto Polit√©cnico Nacional">
                    </div>
                </div>
                <div class="cover-institution">
                    <h2>Centro de Investigaci√≥n en Computaci√≥n</h2>
                </div>

                <div class="cover-course">
                    <p>Diplomado en Inteligencia Artificial</p>
                </div>

                <div class="cover-main">
                    <h1>An√°lisis de sentimientos en versos</h1>
                    <p class="cover-subtitle">Implementaci√≥n y Evaluaci√≥n de Tres Enfoques de Clasificaci√≥n</p>
                </div>

                <div class="cover-author">
                    <p><strong>Autor:</strong></p>
                    <p>Erik I. Osornio Botello</p>
                </div>

                <div class="cover-date">
                    <p><strong>Fecha de Entrega:</strong></p>
                    <p>16 de Octubre de 2025</p>
                </div>
            </div>
        </div>

        <!-- PAGE 2.1: Metodolog√≠a -->
        <div class="page-section">
            <div class="section">
                <div class="section-title">üß≠ Metodolog√≠a</div>

                <div class="section-subtitle">An√°lisis de los datos y preprocesamiento</div>
                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                    El dataset <em>Poem Sentiment</em> presenta textos breves, con fuerte desbalance hacia la clase
                    <code>no_impact</code> y matices po√©ticos/arcaicos. Se implementaron dos estrategias de
                    preprocesamiento diferentes, de acuerdo con el tipo de modelo:
                </p>
                <ul style="line-height: 2;">
                    <li><strong>Baselines cl√°sicos (MultinomialNB, Regresi√≥n Log√≠stica):</strong> preprocesamiento
                        optimizado para poes√≠a inglesa antigua (expansi√≥n de contracciones arcaicas, normalizaci√≥n de
                        signos, limpieza suave). Tras tokenizar, se aplic√≥
                        <code>CountVectorizer(max_features=10000)</code>
                        y balanceo con <code>SMOTE</code> √∫nicamente sobre el entrenamiento (excluyendo
                        <code>mixed</code>).
                        Esta decisi√≥n busca maximizar se√±al l√©xica √∫til para modelos basados en bolsa de palabras.</li>
                    <li><strong>DeBERTa‚Äëv3‚Äëbase (fine‚Äëtuning):</strong> preprocesamiento <em>ligero y no
                            destructivo</em>
                        (normalizar comillas/guiones, eliminar duplicados, sin stemming ni stopwords), preservando los
                        matices po√©ticos para que el tokenizador subword capture sem√°ntica contextual. Se excluye la
                        clase
                        <code>mixed</code> en todos los splits.
                    </li>
                </ul>
                <div class="highlight-box">
                    <strong>Justificaci√≥n de la elecci√≥n:</strong> en enfoques cl√°sicos conviene estandarizar la forma
                    superficial de las palabras para que la frecuencia sea informativa; en transformadores, el
                    tokenizador y el contexto aten√∫an la necesidad de limpiar agresivamente, y remover stopwords puede
                    incluso eliminar matices √∫tiles en poes√≠a.
                </div>

                <div class="section-subtitle">Modelos de IA empleados</div>
                <ul style="line-height: 2;">
                    <li><strong>Multinomial Naive Bayes:</strong> probabil√≠stico, r√°pido y efectivo con conteos de
                        tokens; se ajust√≥ y luego se <em>tune√≥</em> el hiperpar√°metro <code>alpha</code> v√≠a
                        <code>GridSearchCV</code>.
                    </li>
                    <li><strong>Regresi√≥n Log√≠stica:</strong> baseline lineal con <code>class_weight='balanced'</code>
                        para mitigar desbalance sin sobremuestreo.</li>
                    <li><strong>DeBERTa‚Äëv3‚Äëbase:</strong> transformador preentrenado ajustado finamente con t√©cnicas de
                        regularizaci√≥n (Focal Loss, label smoothing, early stopping) y optimizado por F1‚Äëmacro.</li>
                </ul>

                <div class="section-subtitle">Herramientas y tecnolog√≠as</div>
                <div class="specifications">
                    <div class="spec-card"><strong>Frameworks</strong> PyTorch, Hugging Face Transformers</div>
                    <div class="spec-card"><strong>ML cl√°sico</strong> scikit‚Äëlearn, imbalanced‚Äëlearn</div>
                    <div class="spec-card"><strong>Gesti√≥n de datos</strong> pandas, numpy, datasets (HF)</div>
                    <div class="spec-card"><strong>Gr√°ficos</strong> matplotlib, seaborn</div>
                    <div class="spec-card"><strong>NLP utilitario</strong> NLTK</div>
                    <div class="spec-card"><strong>I/O</strong> fastparquet/pyarrow (URIs hf://)</div>
                </div>
            </div>
        </div>

        <!-- TABLE OF CONTENTS -->
        <div style="page-break-after: always; padding: 40px 0;">
            <h2 style="font-size: 1.8em; color: #000; margin-bottom: 30px; text-align: center; font-weight: bold;">
                √çndice</h2>
            <ol style="font-size: 12pt; line-height: 2; margin-left: 30px; color: #333;">
                <li>Introducci√≥n</li>
                <li>Metodolog√≠a</li>
                <li>Datos</li>
                <li>Preprocesamiento</li>
                <li>Representaci√≥n de texto</li>
                <li>Modelos implementados
                    <ol style="margin-top: 10px; margin-left: 20px;">
                        <li>Regresi√≥n Log√≠stica</li>
                        <li>Naive Bayes Multinomial</li>
                        <li>DeBERTa‚Äëv3‚Äëbase (fine‚Äëtuning)</li>
                    </ol>
                </li>
                <li>Entrenamiento y validaci√≥n</li>
                <li>M√©tricas y evaluaci√≥n</li>
                <li>Resultados</li>
                <li>Discusi√≥n</li>
                <li>Conclusiones y trabajo futuro</li>
                <li>Referencias</li>
            </ol>
        </div>

        <div class="download-container">
            <button class="download-btn" onclick="downloadAsWord()">üì• Descargar Word</button>
        </div>

        <!-- Main Content -->
        <div class="content">
            <!-- PAGE 1: Title and Author -->
            <div class="page-section">
                <div class="section" style="text-align: center; margin-bottom: 60px;">
                    <h2 style="font-size: 2.2em; color: #000; margin-bottom: 10px;">An√°lisis de sentimientos en versos
                    </h2>
                    <p style="font-size: 1.2em; color: #000; margin-bottom: 30px;"><strong>Autor:</strong> Erik I.
                        Osornio Botello</p>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; max-width: 800px; margin: 0 auto;">
                        <h3 style="color: #000; margin-bottom: 15px;">Resumen</h3>
                        <p style="text-align: justify; line-height: 1.8; color: #333;">
                            Este documento describe el desarrollo, implementaci√≥n y evaluaci√≥n de un sistema de an√°lisis
                            de sentimientos sobre versos del dataset Poem Sentiment. Se comparan <strong>baselines
                                cl√°sicos</strong>
                            (Regresi√≥n Log√≠stica y Naive Bayes Multinomial con CountVectorizer+SMOTE) frente a un
                            <strong>modelo preentrenado DeBERTa‚Äëv3‚Äëbase</strong> ajustado finamente. Se detalla el flujo
                            completo: exploraci√≥n y limpieza de datos, diferencias de preprocesamiento por enfoque,
                            entrenamiento, optimizaci√≥n de hiperpar√°metros, evaluaci√≥n y discusi√≥n de resultados.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 2: Introduction Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìã 1. Introducci√≥n</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        El an√°lisis de sentimientos busca asignar una polaridad (por ejemplo: positiva, negativa,
                        neutral) a textos.
                        En este proyecto se implementan tres enfoques que representan paradigmas distintos: modelos
                        lineales probabil√≠sticos
                        (Regresi√≥n Log√≠stica), modelos de probabilidades condicionales con suposiciones de independencia
                        (Naive Bayes Multinomial)
                        y un transformador preentrenado (DeBERTa‚Äëv3‚Äëbase). Se discute su preparaci√≥n,
                        rendimiento y trade-offs.
                    </p>

                    <div class="section-subtitle">Objetivos</div>
                    <ul style="line-height: 2;">
                        <li>Construir y comparar tres modelos de an√°lisis de sentimientos.</li>
                        <li>Evaluar rendimiento con m√©tricas est√°ndar (accuracy, precision, recall, F1, AUC cuando
                            aplique).</li>
                        <li>Documentar decisiones de dise√±o y par√°metros.</li>
                    </ul>

                    <div class="section-subtitle">Marco de Referencia</div>
                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <p style="margin-bottom: 12px;">
                            <strong>üìã Indicaciones del Proyecto:</strong> Este proyecto se fundamenta en las
                            indicaciones
                            especificadas en el documento <em>Indicaciones Proyecto Poemas.pdf</em>, el cual establece
                            que:
                        </p>
                        <p
                            style="margin-bottom: 12px; padding-left: 15px; border-left: 3px solid #C41E3A; margin-left: 0;">
                            <strong>"Este proyecto es un ejercicio de aprendizaje supervisado. La idea general consiste
                                en
                                implementar tres clasificadores de texto para el problema de an√°lisis de sentimientos en
                                versos de poemas."</strong>
                        </p>
                        <p>
                            <strong>Clases del Problema:</strong> El marco original define tres categor√≠as de
                            sentimiento (positivo, negativo
                            o neutral), aunque en la pr√°ctica el dataset utilizado incluye cuatro clases: Positivo,
                            Negativo, Mixto y No impacto.
                            La estructura de tres clasificadores y el enfoque de aprendizaje supervisado se mantienen
                            como eje central de
                            la implementaci√≥n.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 3: Data Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìä 2. Datos</div>

                    <div class="section-subtitle">Descripci√≥n del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        <strong>Fuente:</strong> Para este proyecto se utiliz√≥ el dataset <em>Poem Sentiment</em> del
                        repositorio de Google Research,
                        disponible en Hugging Face (hf://datasets/google-research-datasets/poem_sentiment). Este
                        conjunto de datos consiste en versos
                        de poemas extra√≠dos de Project Gutenberg, etiquetados seg√∫n el sentimiento que transmiten.
                    </p>

                    <div class="spec-card">
                        <strong>üìà Caracter√≠sticas principales:</strong>
                        <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                            <li><strong>N√∫mero total de ejemplos:</strong> 1,101 versos</li>
                            <li><strong>Idioma:</strong> Textos en ingl√©s</li>
                            <li><strong>Tama√±o:</strong> Dataset peque√±o, puede dificultar la generalizaci√≥n al entrenar
                                modelos complejos desde cero. No obstante, con transformadores preentrenados y t√©cnicas
                                de regularizaci√≥n (early stopping, class weights/Focal Loss, label smoothing) es posible
                                lograr buen desempe√±o.</li>
                            <li><strong>Data Augmentation:</strong> Debido al desbalance inicial de clases, se aplic√≥
                                data augmentation √∫nicamente en el conjunto de entrenamiento para equilibrar la
                                distribuci√≥n de clases.</li>
                        </ul>
                    </div>

                    <div class="section-subtitle">Clases de Sentimiento</div>
                    <ul style="line-height: 2;">
                        <li><strong>Positivo:</strong> Versos con emociones positivas</li>
                        <li><strong>Negativo:</strong> Versos con emociones negativas</li>
                        <li><strong>Mixto:</strong> Versos que combinan emociones positivas y negativas</li>
                        <li><strong>No impacto:</strong> Versos que no presentan un sentimiento claro</li>
                    </ul>

                    <div class="section-subtitle">Columnas del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        Este conjunto de datos consta de versos de poemas extra√≠dos de Project Gutenberg, etiquetados
                        seg√∫n el sentimiento que transmiten.
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>verse_text:</strong> Contiene el texto del verso del poema</li>
                        <li><strong>label:</strong> Indica la categor√≠a de sentimiento del verso</li>
                    </ul>

                    <div class="section-subtitle">Exploraci√≥n Inicial</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        En la fase de exploraci√≥n, no se encontraron valores nulos. El histograma de las longitudes por
                        clase se encuentra representado en la Ilustraci√≥n 2.
                    </p>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="verse_lengths_distribution.png"
                            alt="Gr√°fico de Distribuci√≥n de Longitudes de Versos por Clase"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Ilustraci√≥n 1. Distribuci√≥n de longitudes por clase</p>
                    </div>

                    <p style="text-align: justify; line-height: 1.5; margin-top: 20px;">
                        La figura muestra la distribuci√≥n de la longitud de los versos seg√∫n su sentimiento. Se observa
                        que la mayor√≠a de los versos tienen entre 30 y 50 palabras,
                        con predominancia de la clase no impact. Las clases minoritarias (mixed, positivo, negativo)
                        est√°n menos representadas, lo que refuerza el desbalance del dataset.
                        Esta distribuci√≥n sugiere que los modelos podr√≠an aprender primero la clase mayoritaria y que
                        los ejemplos muy largos son poco frecuentes y podr√≠an considerarse outliers.
                    </p>

                    <div class="section-subtitle">Divisi√≥n de Datos</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Conjunto</th>
                                <th>N√∫mero de Ejemplos</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Entrenamiento</strong></td>
                                <td>892 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Validaci√≥n</strong></td>
                                <td>105 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Test</strong></td>
                                <td>104 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Total</strong></td>
                                <td>1,101 ejemplos</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="section-subtitle">Distribuci√≥n de Clases (Entrenamiento Original)</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                                <th>Porcentaje</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>555</td>
                                <td>62.2%</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>155</td>
                                <td>17.4%</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>133</td>
                                <td>14.9%</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>49</td>
                                <td>5.5%</td>
                            </tr>
                        </tbody>
                    </table>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="sentiment_distribution.png"
                            alt="Gr√°fico de Distribuci√≥n de Clases en Datos de Entrenamiento"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Figura 1: Distribuci√≥n de Sentimientos en los Datos de Entrenamiento Original</p>
                    </div>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <strong>‚ö†Ô∏è Problema de Desbalance:</strong> La mayor√≠a de los versos pertenecen a la clase "No
                        impacto",
                        mientras que la clase "Mixto" tiene muy pocos ejemplos. Este desbalance puede generar:
                        <ul style="margin-left: 20px; margin-top: 10px; margin-bottom: 10px; line-height: 1.8;">
                            <li><strong>Bias hacia la clase mayoritaria:</strong> Los modelos tienden a predecir con
                                mayor frecuencia la clase predominante (No impacto), lo que puede inflar el accuracy
                                aparente, pero reducir la capacidad de identificar correctamente las clases
                                minoritarias.</li>
                            <li><strong>Problemas de generalizaci√≥n en modelos complejos:</strong> Las redes
                                neuronales pueden sobreajustar f√°cilmente a la clase mayoritaria, especialmente cuando
                                el dataset es peque√±o. En este caso, modelos complejos pueden aprender patrones sesgados
                                en lugar de representaciones robustas de todas las clases.</li>
                            <li><strong>M√©tricas poco confiables para clases minoritarias:</strong> Las m√©tricas de
                                rendimiento pueden ser enga√±osas si se interpretan sin considerar el desbalance.</li>
                        </ul>
                        <p style="margin-top: 12px; text-align: justify; line-height: 1.6; font-size: 11pt;">
                            Dado el tama√±o reducido y el desbalance, estos conjuntos pueden no ser representativos de la
                            distribuci√≥n real de clases.
                            Esto significa que las m√©tricas de evaluaci√≥n (accuracy, F1, recall, precision) pueden ser
                            ruidosas y poco confiables,
                            especialmente para las clases minoritarias como Mixto y Positivo.
                        </p>
                    </div>

                    <div class="section-subtitle">Estrategias de Mitigaci√≥n</div>
                    <ul style="line-height: 2;">
                        <li><strong>Data Augmentation:</strong> Aplicada solo en el entrenamiento para balancear las
                            clases</li>
                        <li><strong>Class weights:</strong> Pesos por clase en el transformador (DeBERTa) mediante Focal
                            Loss + class weights para penalizar predicciones
                            incorrectas de clases minoritarias</li>
                    </ul>

                    <div class="section-subtitle">Distribuci√≥n de Clases (Post Data Augmentation)</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>2,775</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>2,325</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>1,995</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>735</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <!-- PAGE 4: Preprocesamiento -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìù 3. Preprocesamiento</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        El texto se someti√≥ a un pipeline de preprocesamiento con dos funciones principales:
                        <code>clean_text</code> y <code>preprocess_text</code>.
                    </p>

                    <div class="section-subtitle">Limpieza de Texto (clean_text)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Esta funci√≥n realiza operaciones de limpieza b√°sica para normalizar los datos textuales:
                    </p>
                    <ul style="line-height: 2;">
                        <li>Conversi√≥n a min√∫sculas para uniformidad</li>
                        <li>Eliminaci√≥n de URLs y etiquetas HTML</li>
                        <li>Remoci√≥n de menciones de usuarios (@usuario) y s√≠mbolos de hashtags (#)</li>
                        <li>Eliminaci√≥n de puntuaci√≥n y n√∫meros</li>
                        <li>Reducci√≥n de espacios en blanco redundantes</li>
                    </ul>

                    <div class="section-subtitle">Preprocesamiento Completo (preprocess_text)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        A continuaci√≥n, el texto limpio se somete a un procesamiento adicional para preparar los datos
                        para modelos de NLP:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Tokenizaci√≥n:</strong> El texto se divide en palabras individuales</li>
                        <li><strong>Eliminaci√≥n de stopwords:</strong> Se eliminan palabras comunes sin contenido
                            sem√°ntico relevante (como ‚Äúthe‚Äù, ‚Äúand‚Äù, ‚Äúis‚Äù) utilizando la lista de NLTK</li>
                        <li><strong>Lematizaci√≥n:</strong> Cada palabra se reduce a su forma base (por ejemplo,
                            ‚Äúrunning‚Äù ‚Üí ‚Äúrun‚Äù, ‚Äúcars‚Äù ‚Üí ‚Äúcar‚Äù) usando WordNetLemmatizer.</li>
                        <li><strong>Reconstrucci√≥n del texto:</strong> Los tokens resultantes se unen nuevamente en un
                            string, listo para su an√°lisis o entrada a un modelo</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este pipeline permite obtener un texto limpio, normalizado y representativo, adecuado para
                        t√©cnicas de NLP como modelos cl√°sicos y transformadores,
                        Naive Bayes o TF-IDF, mejorando la calidad de las predicciones y reduciendo el ruido en los
                        datos.
                    </p>

                    <div class="spec-card">
                        <strong>üìù Ejemplos de Preprocesamiento:</strong>
                        <div
                            style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                            <p><strong>Original:</strong> "with pale blue berries. in these peaceful shades"</p>
                            <p><strong>Procesado:</strong> "pale blue berry peaceful shade"</p>
                            <hr style="border: none; border-top: 1px solid #ddd; margin: 10px 0;">
                            <p><strong>Original:</strong> "it flows so long as falls the rain,"</p>
                            <p><strong>Procesado:</strong> "flow long fall rain"</p>
                        </div>
                    </div>

                    <div style="height: 20px; clear: both;"></div>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Se puede observar que, tras aplicar procesamiento, se reduce la longitud de la oraci√≥n original,
                        se removi√≥ puntuaci√≥n y stopwords.
                    </p>

                    <div class="section-subtitle">Data Augmentation</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Se implement√≥ un pipeline de aumento de datos utilizando la librer√≠a <code>nlpaug</code> para
                        balancear
                        las clases minoritarias. El objetivo principal es balancear las clases minoritarias en el
                        dataset y mejorar la capacidad del modelo para generalizar.
                        El proceso incluye:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Selecci√≥n de clases minoritarias:</strong> Se identifican las clases que tienen
                            pocas muestras (por ejemplo: ‚Äúnegative‚Äù, ‚Äúpositive‚Äù y ‚Äúmixed‚Äù)
                            y se les aplica un mayor n√∫mero de "augmentations" para equilibrar la distribuci√≥n de
                            clases.</li>
                        <li><strong>Generaci√≥n de nuevas muestras:</strong> Para cada texto en el dataset se generan
                            varias versiones alternativas reemplazando palabras por sin√≥nimos usando WordNet.</li>
                        <li><strong>Proporci√≥n de aumentos:</strong> Las clases minoritarias reciben m√°s aumentos que
                            las clases mayoritarias, logrando un balance m√°s uniforme.</li>
                        <li><strong>Creaci√≥n de dataset final:</strong> Los textos originales y los aumentados se
                            combinan en un nuevo DataFrame.</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Esto produce un dataset m√°s grande y balanceado, que reduce el sesgo hacia clases mayoritarias y
                        ayuda a mejorar el entrenamiento de modelos de NLP.
                    </p>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este procedimiento es especialmente √∫til en problemas de clasificaci√≥n de texto donde algunas
                        categor√≠as tienen muy pocas muestras, ya que incrementa la diversidad de los datos
                        sin necesidad de recolectar m√°s ejemplos reales.

                    </p>

                    <div class="spec-card">
                        <strong>üìù Ejemplos de Data Augmentation:</strong>
                        <div
                            style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                            <p><strong>Original:</strong> "right wrong john"</p>
                            <p><strong>Aumento 1:</strong> "right unseasonable john"</p>
                            <p><strong>Aumento 2:</strong> "right ill timed john"</p>
                            <p><strong>Aumento 3:</strong> "right wrong king john"</p>
                            <p><strong>Aumento 4:</strong> "mightily wrong john"</p>
                        </div>
                    </div>

                    <p style="text-align: justify; line-height: 1.8; margin-top: 20px;">
                        Tras aplicar aumentos, se puede observar que en cada aumento se cambia la palabra <em>wrong</em>
                        (malo) por un sin√≥nimo diferente:
                        <em>unseasonable</em>, <em>ill timed</em>, <em>mightily wrong john</em>, haciendo el dataset m√°s
                        diverso. A la clase mayoritaria se le
                        aplicaron 5 aumentos y a las minoritarias 14 por cada muestra. De esta manera, se genera una
                        representaci√≥n m√°s rica de cada clase
                        sin necesidad de recolectar datos nuevos.
                    </p>

                    <p style="text-align: justify; line-height: 1.8; margin-top: 20px;">
                        La distribuci√≥n resultante se puede observar en la Tabla 2:
                    </p>

                    <table class="format-table" style="margin-top: 15px;">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                                <th>Porcentaje</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>2,775</td>
                                <td>35.45%</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>2,325</td>
                                <td>29.69%</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>1,995</td>
                                <td>25.48%</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>735</td>
                                <td>9.39%</td>
                            </tr>
                            <tr style="background: #f0f0f0; font-weight: bold;">
                                <td><strong>Total</strong></td>
                                <td>7,830</td>
                                <td>100%</td>
                            </tr>
                        </tbody>
                    </table>
                    <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                        Tabla 2. Distribuci√≥n de clases despu√©s de aplicar aumentos</p>

                </div>

                <!-- PAGE 5: Text Representation -->
                <div class="page-section">
                    <div class="section">
                        <div class="section-title">üî¢ 4. Representaci√≥n de Texto</div>

                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                            Se utiliz√≥ CountVectorizer para los modelos cl√°sicos y tokenizaci√≥n subword para DeBERTa.
                        </p>

                        <div class="section-subtitle">Count Vectorizer</div>
                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            El CountVectorizer se utiliza para convertir texto en una representaci√≥n num√©rica que pueda
                            ser procesada
                            por modelos de machine learning. Transforma un conjunto de documentos en una matriz de
                            conteo de palabras,
                            donde cada fila representa un documento, cada columna representa una palabra del
                            vocabulario, y el valor
                            indica cu√°ntas veces aparece esa palabra en el documento.
                        </p>

                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                            En <strong>scikit-learn</strong>, CountVectorizer se configura como un objeto que luego se
                            ajusta (fit) y transforma (transform) sobre los textos. La Ilustraci√≥n 4 muestra como
                            ajustar sus par√°metros.
                        </p>

                        <div style="text-align: center; margin: 30px 0;">
                            <img src="count_vectorizer.png" alt="Configuraci√≥n de CountVectorizer"
                                style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                            <p
                                style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                Ilustraci√≥n 4. Ejemplo de configuraci√≥n de CountVectorizer</p>
                        </div>

                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            <strong>Configuraci√≥n:</strong> max_features=10000, unigramas y bigramas
                        </p>
                        <p style="text-align: justify; line-height: 1.8;">
                            <strong>Matrices resultantes:</strong>
                        </p>
                        <ul style="line-height: 2;">
                            <li>X_train: (7830, 10000)</li>
                            <li>X_val: (105, 10000)</li>
                            <li>X_test: (104, 10000)</li>
                        </ul>

                        <div class="section-subtitle">Tokenizaci√≥n subword para Transformers (DeBERTa)</div>
                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            En <strong>DeBERTa‚Äëv3‚Äëbase</strong> se usa un tokenizador subword (SentencePiece/BPE) que
                            descompone palabras en unidades subl√©xicas y genera ids y m√°scaras de atenci√≥n:
                        </p>
                        <ul style="line-height: 2;">
                            <li><strong>Tokenizaci√≥n:</strong> <code>AutoTokenizer.from_pretrained(...)</code> produce
                                <code>input_ids</code> y <code>attention_mask</code>, con truncado/padding a
                                <strong>max_len=128</strong>.
                            </li>
                            <li><strong>Entrada al modelo:</strong> tensores con forma <code>(batch, seq_len)</code>.
                                El mecanismo de atenci√≥n capta dependencias largas y contexto.</li>
                            <li><strong>Optimizaci√≥n:</strong> el <em>fine‚Äëtuning</em> ajusta todas las capas del
                                modelo al dominio de poes√≠a, preservando matices estil√≠sticos.</li>
                        </ul>

                        <div class="spec-card">
                            <strong>üìù Ejemplo de Tokenizaci√≥n:</strong>
                            <div
                                style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                                <p><strong>Texto:</strong> "i love nlp"</p>
                                <p><strong>Tokenizado:</strong> [2, 3, 1]</p>
                                <p><strong>Con Padding (longitud=5):</strong> [2, 3, 1, 0, 0]</p>
                            </div>
                        </div>





                    </div>

                    <!-- PAGE 5.1: Implementaci√≥n -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">üõ†Ô∏è Implementaci√≥n</div>

                            <div class="section-subtitle">Pipeline de desarrollo</div>
                            <div class="structure-list">
                                <div class="structure-item">
                                    <h4>Baselines cl√°sicos (NB / Reg. Log√≠stica)</h4>
                                    <div class="structure-description">
                                        <ol>
                                            <li>Exploraci√≥n y divisi√≥n de datos (train/val/test) desde Hugging Face</li>
                                            <li>Preprocesamiento optimizado para poes√≠a (expansi√≥n de contracciones,
                                                limpieza suave)</li>
                                            <li>Vectorizaci√≥n con <code>CountVectorizer(max_features=10000)</code></li>
                                            <li>Exclusi√≥n de clase <code>mixed</code> y balanceo con <code>SMOTE</code>
                                                (solo train)</li>
                                            <li>Entrenamiento de <code>MultinomialNB</code> y
                                                <code>LogisticRegression</code></li>
                                            <li>Ajuste de <code>alpha</code> (NB) con <code>GridSearchCV</code></li>
                                            <li>Evaluaci√≥n macro‚ÄëF1 (sin clase <code>mixed</code>) y matrices de
                                                confusi√≥n</li>
                                        </ol>
                                    </div>
                                </div>
                                <div class="structure-item">
                                    <h4>DeBERTa‚Äëv3‚Äëbase (fine‚Äëtuning)</h4>
                                    <div class="structure-description">
                                        <ol>
                                            <li>Preprocesamiento ligero (normalizar comillas/guiones, deduplicar)</li>
                                            <li>Exclusi√≥n de clase <code>mixed</code> en todos los splits</li>
                                            <li>Tokenizaci√≥n subword (max_len=128) y creaci√≥n de datasets de HF</li>
                                            <li>Hiperpar√°metros: lr=2e‚Äë5, batch=16, epochs=6, warmup=0.05</li>
                                            <li>Regularizaci√≥n: Focal Loss (Œ≥=1.5) + class weights, label smoothing=0.1
                                            </li>
                                            <li>Entrenamiento con Trainer optimizando F1‚Äëmacro + early stopping</li>
                                            <li>Evaluaci√≥n en validaci√≥n y test; an√°lisis por clase y matriz de
                                                confusi√≥n</li>
                                        </ol>
                                    </div>
                                </div>
                            </div>

                            <div class="section-subtitle">Ejemplos de aplicaci√≥n</div>
                            <div class="spec-card">
                                <strong>Inferencia con DeBERTa‚Äëv3‚Äëbase (conceptual)</strong>
                                <div style="margin-top: 10px;
                                            font-family: 'Courier New', monospace;
                                            background: #f8f9fa; padding: 15px; border-radius: 4px;">
                                    <code>texto = "Sunshine fills my heart with joy."
# 1) tokenizar ‚Üí input_ids, attention_mask (max_len=128)
# 2) pasar por el modelo ‚Üí logits
# 3) pred = argmax(logits) ‚Üí {0: negative, 1: positive, 2: no_impact}</code>
                                </div>
                            </div>

                            <div class="spec-card" style="margin-top: 15px;">
                                <strong>Uso de pipeline cl√°sico</strong>
                                <div style="margin-top: 10px;
                                            font-family: 'Courier New', monospace;
                                            background: #f8f9fa; padding: 15px; border-radius: 4px;">
                                    <code># (resumen)
tokens = preprocess_poetry_text(verso)
vec = CountVectorizer(max_features=10000)
X = vec.transform([" ".join(tokens)])
pred = nb_model.predict(X)  # √≥ lr_model.predict(X)</code>
                                </div>
                            </div>

                            <div class="section-subtitle" style="margin-top: 25px;">Optimizaci√≥n y ajustes
                                (hiperpar√°metros)</div>
                            <div class="specifications">
                                <div class="spec-card">
                                    <strong>MultinomialNB</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li><code>GridSearchCV</code> sobre
                                            <code>alpha ‚àà {0.01, 0.1, 0.5, 1.0, 5.0, 10.0}</code></li>
                                        <li><em>Scoring</em>: F1‚Äëmacro, CV=5</li>
                                    </ul>
                                </div>
                                <div class="spec-card">
                                    <strong>Regresi√≥n Log√≠stica</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li><code>class_weight='balanced'</code>, <code>max_iter=2000</code>,
                                            <code>solver='liblinear'</code></li>
                                    </ul>
                                </div>
                                <div class="spec-card">
                                    <strong>DeBERTa‚Äëv3‚Äëbase</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li>Focal Loss (Œ≥=1.5) + <em>class weights</em>, <em>label smoothing</em>=0.1
                                        </li>
                                        <li>lr=2e‚Äë5, batch=16, epochs=6, warmup_ratio=0.05, early stopping (patience=3)
                                        </li>
                                        <li>M√©trica objetivo: F1‚Äëmacro</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- PAGE 6: Models -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">ü§ñ 5. Modelos Implementados</div>

                            <div class="section-subtitle">5.1 Regresi√≥n Log√≠stica</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                La regresi√≥n log√≠stica fue seleccionada por su capacidad para manejar eficazmente
                                representaciones vectorizadas
                                del texto. Este modelo aprende a estimar la probabilidad de pertenencia a cada clase
                                mediante una combinaci√≥n
                                lineal de caracter√≠sticas, lo cual resulta apropiado en problemas de an√°lisis de texto
                                donde la presencia
                                o frecuencia de ciertas palabras suele correlacionarse directamente con el sentimiento.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Permite incorporar pesos para clases minoritarias (class weights)</li>
                                    <li>Naturaleza probabil√≠stica facilita interpretar confianza</li>
                                    <li>Bajo costo computacional y estable</li>
                                    <li>Excelente baseline para comparar con modelos m√°s complejos</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>
                            <p style="margin-top: 15px;"><strong>Librer√≠a:</strong>
                                sklearn.linear_model.LogisticRegression</p>
                            <p style="margin-top: 15px;"><strong>Par√°metros:</strong> max_iter=1000</p>

                            <div style="text-align: center; margin: 30px 0;">
                                <img src="logistic_regression.png" alt="Par√°metros utilizados para regresi√≥n log√≠stica"
                                    style="max-width: 70%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                <p
                                    style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                    Ilustraci√≥n 6. Par√°metros utilizados para regresi√≥n log√≠stica</p>
                            </div>

                            <div class="section-subtitle">5.2 Naive Bayes Multinomial</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                El modelo Naive Bayes Multinomial est√° especialmente dise√±ado para trabajar con datos
                                representados como
                                frecuencias de palabras, como los obtenidos mediante t√©cnicas de Bag-of-Words o TF-IDF.
                                Asume independencia entre las caracter√≠sticas (palabras), lo
                                que simplifica el
                                c√°lculo de probabilidades y permite un entrenamiento muy r√°pido incluso con grandes
                                vol√∫menes de texto.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Rendimiento competitivo en clasificaci√≥n de textos</li>
                                    <li>Especialmente efectivo cuando hay palabras claramente asociadas a cada
                                        sentimiento</li>
                                    <li>Entrenamimiento r√°pido y eficiente</li>
                                    <li>Opci√≥n s√≥lida como modelo base</li>
                                </ul>
                            </div>
                            <p style="margin-top: 15px;"><strong>Implementaci√≥n:</strong> MultinomialNB de scikit-learn
                            </p>
                            <div style="text-align: center; margin: 30px 0;">
                                <img src="multinomial_nb.png" alt="Par√°metros utilizados para Naive Bayes Multinomial"
                                    style="max-width: 40%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                <p
                                    style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                    Ilustraci√≥n 7. Configuraci√≥n de par√°metros de Naive Bayes Multinomial</p>
                            </div>
                            <div class="section-subtitle">5.3 DeBERTa‚Äëv3‚Äëbase (fine‚Äëtuning)</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                Los transformadores preentrenados como <strong>DeBERTa‚Äëv3‚Äëbase</strong> capturan
                                relaciones contextuales y sem√°ntica a nivel sub‚Äëpalabra mediante auto‚Äëatenci√≥n.
                                En este trabajo se realiz√≥ <em>fine‚Äëtuning</em> completo para el dataset Poem
                                Sentiment (excluyendo la clase <code>mixed</code>), optimizando la m√©trica
                                <strong>F1‚Äëmacro</strong> y usando t√©cnicas de regularizaci√≥n para manejar el
                                desbalance y evitar sobreajuste.
                            </p>
                            <div class="spec-card">
                                <strong>T√©cnicas aplicadas</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Tokenizaci√≥n subword (max_len=128)</li>
                                    <li>Focal Loss (Œ≥ = 1.5) + <em>class weights</em></li>
                                    <li><em>Label smoothing</em> = 0.1</li>
                                    <li><em>Early stopping</em> (patience = 3)</li>
                                    <li>Optimizaci√≥n con Hugging Face Trainer por F1‚Äëmacro</li>
                                </ul>
                            </div>

                            <div class="spec-card" style="margin-top: 15px;">
                                <strong>Ventajas</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Captura dependencias largas y matices po√©ticos</li>
                                    <li>Robusto ante variaciones l√©xicas y de estilo</li>
                                    <li>Rendimiento superior en dominios de texto fino</li>
                                </ul>
                            </div>

                            <p style="margin-top: 15px;"><strong>Framework:</strong> PyTorch + Hugging Face Transformers
                            </p>
                            <p style="margin-top: 10px;"><strong>Hiperpar√°metros clave:</strong> lr=2e‚Äë5, batch_size=16,
                                epochs=6,
                                weight_decay=0.01, warmup_ratio=0.05, max_len=128</p>

                        </div>

                        <!-- PAGE 7: Metrics and Training -->
                        <div class="page-section">
                            <div class="section">
                                <div class="section-title">üìä 6. Entrenamiento, Validaci√≥n y M√©tricas</div>
                                <div class="section-subtitle">Carga del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    El dataset se obtuvo desde el repositorio de Hugging Face utilizando pandas. Los
                                    archivos est√°n disponibles en formato Parquet
                                    y se pueden cargar directamente usando la siguiente configuraci√≥n:
                                </p>

                                <div
                                    style="background: #f8f9fa; padding: 20px; border-radius: 4px; margin: 20px 0; overflow-x: auto;">
                                    <code
                                        style="background: #f0f0f0; padding: 15px; border-radius: 4px; font-family: 'Courier New', monospace; display: block;">
                                        import pandas as pd<br>
                                        <br>
                                        splits = {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'train': 'data/train-00000-of-00001.parquet',<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'validation': 'data/validation-00000-of-00001.parquet',<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'test': 'data/test-00000-of-00001.parquet'<br>
                                        }<br>
                                        <br>
                                        df = pd.read_parquet(<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;"hf://datasets/google-research-datasets/poem_sentiment/" + splits["train"]<br>
                                        )
                                    </code>
                                </div>

                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    <strong>URL del Dataset:</strong> <a
                                        href="https://huggingface.co/datasets/google-research-datasets/poem_sentiment/viewer"
                                        target="_blank"
                                        style="color: #C41E3A; text-decoration: none;">https://huggingface.co/datasets/google-research-datasets/poem_sentiment/viewer</a>
                                </p>

                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Este m√©todo permite cargar directamente los splits de entrenamiento, validaci√≥n y
                                    prueba en DataFrames de pandas,
                                    facilitando el preprocesamiento y manipulaci√≥n de los datos para el an√°lisis
                                    posterior.
                                </p>
                                <div class="section-subtitle">Divisi√≥n del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utiliz√≥ la divisi√≥n est√°ndar del dataset proporcionada por Hugging Face para
                                    garantizar coherencia
                                    y reproducibilidad de los resultados.
                                </p>

                                <div class="section-subtitle">M√©tricas de Evaluaci√≥n</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utilizaron las siguientes m√©tricas para evaluar el desempe√±o de los modelos:
                                </p>
                                <ul style="line-height: 2;">
                                    <li><strong>Accuracy:</strong> Proporci√≥n de predicciones correctas</li>
                                    <li><strong>Precision (macro avg):</strong> Promedio de precisi√≥n por clase</li>
                                    <li><strong>Recall (macro avg):</strong> Promedio de recall por clase</li>
                                    <li><strong>F1 (macro avg):</strong> Media arm√≥nica de precision y recall</li>
                                </ul>
                                <p style="text-align: justify; line-height: 1.8; margin-top: 15px;">
                                    <strong>Librer√≠as utilizadas:</strong> sklearn.metrics.classification_report,
                                    confusion_matrix
                                </p>
                                <code
                                    style="background: #f0f0f0; padding: 15px; border-radius: 4px; font-family: 'Courier New', monospace; display: block; margin-top: 10px;">
                                from sklearn.metrics import classification_report, confusion_matrix

                                y_pred = clf.predict(X_test_counts)
                                print(classification_report(y_test, y_pred))

                                cm = confusion_matrix(y_test, y_pred)
                                </code>

                            </div>

                            <!-- PAGE 8: Results -->
                            <div class="page-section">
                                <div class="section">
                                    <div class="section-title">üìà 7. Resultados</div>

                                    <div class="section-subtitle">Resultados principales (DeBERTa‚Äëv3‚Äëbase)</div>
                                    <table class="format-table">
                                        <thead>
                                            <tr>
                                                <th>Conjunto</th>
                                                <th>Accuracy</th>
                                                <th>F1‚ÄëMacro</th>
                                                <th>F1‚ÄëWeighted</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <td><strong>Validaci√≥n</strong></td>
                                                <td>0.9143</td>
                                                <td><strong>0.8903</strong></td>
                                                <td>0.9132</td>
                                            </tr>
                                            <tr>
                                                <td><strong>Test</strong></td>
                                                <td>0.9135</td>
                                                <td><strong>0.8909</strong></td>
                                                <td>0.9136</td>
                                            </tr>
                                        </tbody>
                                    </table>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #e8f5e9 0%, #ffffff 100%); border-left-color: #2e7d32; margin-top: 30px;">
                                        <strong>‚úì Objetivo cumplido:</strong> Se alcanz√≥ <strong>F1‚Äëmacro ‚â•
                                            0.85</strong> en Validaci√≥n y Test con
                                        DeBERTa‚Äëv3‚Äëbase, cumpliendo el objetivo del proyecto con margen.
                                    </div>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; margin-top: 30px;">
                                        <strong>Comparativa con baselines cl√°sicos:</strong> Los enfoques con
                                        CountVectorizer (MultinomialNB / Regresi√≥n Log√≠stica)
                                        se usaron como l√≠neas base s√≥lidas, pero <em>no alcanzaron</em> el desempe√±o del
                                        transformador en F1‚Äëmacro. La elecci√≥n de
                                        DeBERTa se justifica por su capacidad para capturar matices sem√°nticos y de
                                        estilo propios de la poes√≠a.
                                    </div>
                                </div>

                                <!-- PAGE 9: Discussion -->
                                <div class="page-section">
                                    <div class="section">
                                        <div class="section-title">üí° 8. Discusi√≥n</div>

                                        <div class="section-subtitle">¬øQu√© se observa en los resultados?</div>
                                        <ul style="line-height: 2;">
                                            <li><strong>DeBERTa‚Äëv3‚Äëbase</strong> alcanza F1‚Äëmacro ‚âà 0.891 en Test,
                                                superando ampliamente a los baselines cl√°sicos.</li>
                                            <li>Por clase (Test): <em>negative</em> logra <strong>recall ‚âà 1.00</strong>
                                                (marcadores afectivos m√°s expl√≠citos);
                                                <em>positive</em> es la m√°s desafiante (<strong>precision/recall ‚âà
                                                    0.81</strong>), con confusiones hacia
                                                <code>no_impact</code> cuando el verso es m√°s descriptivo que
                                                valorativo; <em>no_impact</em> mantiene
                                                precisi√≥n alta (‚âà 0.95) y recall ‚âà 0.91.
                                            </li>
                                            <li>La combinaci√≥n de <em>class weights</em> + Focal Loss + label smoothing
                                                favorece el balance entre clases bajo desbalance.</li>
                                        </ul>

                                        <div class="section-subtitle">¬øFue exitoso el entrenamiento?</div>
                                        <p style="text-align: justify; line-height: 1.8;">
                                            S√≠. La m√©trica objetivo (<strong>F1‚Äëmacro ‚â• 0.85</strong>) se cumpli√≥ con
                                            margen. Las curvas por √©poca
                                            (con early stopping) y el uso de regularizaci√≥n indican un proceso estable y
                                            reproducible.
                                        </p>

                                        <div class="section-subtitle">Escenarios de uso</div>
                                        <ul style="line-height: 2;">
                                            <li>Curadur√≠a y anal√≠tica de colecciones po√©ticas (tendencias afectivas por
                                                autor/√©poca).</li>
                                            <li>Herramientas de apoyo editorial, talleres de escritura y an√°lisis
                                                literario asistido.</li>
                                            <li>Estudios de marcadores afectivos y estil√≠sticos en humanidades
                                                digitales.</li>
                                        </ul>

                                        <div class="section-subtitle">Limitaciones y mejoras</div>
                                        <ul style="line-height: 2;">
                                            <li><strong>Clase positive:</strong> a√∫n mejorable con
                                                <em>augmentations</em> suaves o calibraci√≥n de umbrales.</li>
                                            <li><strong>Generalizaci√≥n:</strong> ampliar datos o realizar
                                                <em>fine‚Äëtuning</em> por dominio/autor.</li>
                                            <li><strong>Mixta (<code>mixed</code>):</strong> reincorporarla demandar√°
                                                redise√±ar p√©rdidas/umbral o recolectar m√°s muestras.</li>
                                            <li><strong>Recursos:</strong> modelos mayores (DeBERTa‚Äëlarge,
                                                RoBERTa‚Äëlarge) y <em>ensembles</em> podr√≠an subir el techo de desempe√±o
                                                con mayor costo computacional.</li>
                                        </ul>
                                    </div>

                                    <!-- PAGE 10: Conclusions -->
                                    <div class="page-section">
                                        <div class="section">
                                            <div class="section-title">üéØ 9. Conclusiones y Trabajo Futuro</div>

                                            <div class="section-subtitle">Conclusiones</div>
                                            <ul style="line-height: 2;">
                                                <li><strong>Objetivo cumplido:</strong> se alcanz√≥ F1‚Äëmacro ‚â• 0.85 con
                                                    DeBERTa‚Äëv3‚Äëbase (F1‚Äëmacro Test ‚âà 0.8909).</li>
                                                <li>La <strong>elecci√≥n de preprocesamiento</strong> diferenciado fue
                                                    clave: limpieza ligera para el transformador y normalizaci√≥n l√©xica
                                                    + CountVectorizer para baselines.</li>
                                                <li>Los <strong>baselines cl√°sicos</strong> sirvieron como referencia y
                                                    an√°lisis de sensibilidad, pero el transformador captur√≥ mejor los
                                                    matices po√©ticos.</li>
                                                <li><strong>Impacto profesional:</strong> este proyecto consolida el
                                                    manejo de pipelines de NLP modernos (Transformers) y comparativos
                                                    cl√°sicos, √∫til para prototipado r√°pido y despliegue en anal√≠tica
                                                    textual.</li>
                                            </ul>

                                            <div class="section-subtitle">Trabajo futuro</div>
                                            <ul style="line-height: 2;">
                                                <li>Explorar <em>ensembles</em> de checkpoints/seeds y modelos mayores
                                                    (DeBERTa‚Äëlarge, RoBERTa).</li>
                                                <li>Mejorar la clase <em>positive</em> con <em>augmentations</em> suaves
                                                    y calibraci√≥n de umbrales.</li>
                                                <li>Reincorporar la clase <code>mixed</code> con estrategias de p√©rdida
                                                    (p. ej., <em>asymmetric loss</em>) o m√°s datos.</li>
                                                <li>Preparar un demo de inferencia (Gradio/FastAPI) y monitoreo en
                                                    producci√≥n.</li>
                                            </ul>
                                        </div>

                                        <!-- PAGE 11: References & Footer -->
                                        <div class="page-section">
                                            <div class="section">
                                                <div class="section-title">üìö 10. Referencias Bibliogr√°ficas</div>

                                                <div
                                                    style="background: #f8f9fa; padding: 25px; border-radius: 8px; line-height: 2;">
                                                    <p>Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011).
                                                        <em>Scikit-learn: Machine Learning in Python</em>.
                                                        Journal of Machine Learning Research, 12, 2825-2830.
                                                    </p>



                                                    <p>Google Research. (s.f.). <em>Poem sentiment</em> [Conjunto de
                                                        datos]. Hugging Face.
                                                        Disponible en:
                                                        https://huggingface.co/datasets/google-research-datasets/poem_sentiment
                                                    </p>

                                                    <p>Goodfellow, I., Bengio, Y., & Courville, A. (2016). <em>Deep
                                                            Learning</em>.
                                                        MIT Press. [Referencia para arquitecturas de redes neuronales]
                                                    </p>

                                                    <p>Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT:
                                                        Pre-training of Deep Bidirectional Transformers
                                                        for Language Understanding. arXiv preprint arXiv:1810.04805.</p>
                                                </div>
                                            </div>

                                            <!-- Footer -->
                                            <div class="footer">
                                                <p>üìä <span class="footer-highlight">Reporte Final: An√°lisis de
                                                        sentimientos en versos - Diplomado en Inteligencia
                                                        Artificial</span></p>
                                                <p style="font-size: 0.9em; color: #999;">Autor: Erik I. Osornio Botello
                                                </p>
                                                <p style="margin-top: 15px; color: #999; font-size: 0.85em;">
                                                    Este reporte presenta el desarrollo, implementaci√≥n y evaluaci√≥n de
                                                    un sistema completo de an√°lisis de sentimientos
                                                    utilizando tres enfoques distintos.
                                                </p>
                                            </div>

                                            <div class="page-number"></div>
                                        </div>
                                    </div>
                                </div>
</body>

</html>