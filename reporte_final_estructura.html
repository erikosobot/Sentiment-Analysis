<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte Final - Curso de Inteligencia Artificial</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        p {
            text-align: justify;
            line-height: 1.5;
            font-size: 12pt;
        }

        body {
            font-family: Arial, sans-serif;
            font-size: 12pt;
            line-height: 1.5;
            color: #333;
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
            overflow: hidden;
            padding: 2.5cm;
        }

        /* Header */
        .header {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.95;
        }

        .header-logo {
            margin-bottom: 20px;
            font-size: 3em;
        }

        /* Main Content */
        .content {
            padding: 0;
            text-align: justify;
        }

        .section {
            margin-bottom: 50px;
            page-break-inside: avoid;
            page-break-after: auto;
        }

        .section-title {
            font-size: 14pt;
            color: #000;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #C41E3A;
            font-weight: bold;
            page-break-after: avoid;
        }

        .section-subtitle {
            font-size: 12pt;
            color: #000;
            margin-top: 30px;
            margin-bottom: 15px;
            font-weight: bold;
            font-style: italic;
            padding-left: 20px;
            border-left: 4px solid #C41E3A;
        }

        .intro-text {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-left: 5px solid #C41E3A;
            margin-bottom: 30px;
            line-height: 1.5;
            font-size: 12pt;
            text-align: justify;
        }

        /* Specifications */
        .specifications {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .spec-card {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #C41E3A;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .spec-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(196, 30, 58, 0.2);
        }

        .spec-card strong {
            color: #000;
            display: block;
            margin-bottom: 8px;
        }

        /* Lists */
        ul,
        ol {
            margin-left: 30px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 12px;
            line-height: 1.5;
            text-align: justify;
        }

        li strong {
            color: #4A4A4A;
        }

        /* Structure sections */
        .structure-list {
            padding: 30px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .structure-item {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 1px solid #e0e0e0;
        }

        .structure-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .structure-item h4 {
            color: #000;
            font-size: 1.15em;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
        }

        .structure-item h4:before {
            content: "‚ñ∏";
            margin-right: 10px;
            font-size: 1.3em;
            color: #4A4A4A;
        }

        .structure-description {
            margin-left: 20px;
            color: #666;
            line-height: 1.8;
        }

        /* Rubric */
        .rubric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .rubric-item {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 25px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(139, 21, 56, 0.2);
        }

        .rubric-percentage {
            font-size: 2.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .rubric-description {
            font-size: 0.95em;
            opacity: 0.95;
        }

        /* Deliverables */
        .deliverables {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 30px;
            border-radius: 8px;
            border: 2px solid #C41E3A;
        }

        .deliverable-item {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
            font-size: 1.05em;
        }

        .deliverable-item:last-child {
            margin-bottom: 0;
        }

        .deliverable-icon {
            width: 30px;
            height: 30px;
            background: #C41E3A;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 15px;
            font-weight: bold;
            flex-shrink: 0;
        }

        /* Format Table */
        .format-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            overflow: hidden;
        }

        .format-table th {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }

        .format-table td {
            padding: 15px;
            border-bottom: 1px solid #e0e0e0;
        }

        .format-table tr:hover {
            background: #f8f9fa;
        }

        .format-table tr:last-child td {
            border-bottom: none;
        }

        /* Footer */
        .footer {
            background: #f8f9fa;
            padding: 30px 40px;
            text-align: center;
            color: #666;
            border-top: 1px solid #e0e0e0;
        }

        .footer p {
            margin-bottom: 10px;
        }

        .footer-highlight {
            color: #4A4A4A;
            font-weight: bold;
        }

        /* Highlight boxes */
        .highlight-box {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            border-left: 4px solid #C41E3A;
            padding: 15px 20px;
            border-radius: 4px;
            margin: 20px 0;
            color: #000;
        }

        .highlight-box strong {
            color: #000;
        }

        /* Code blocks */
        .code-block {
            background-color: #f5f5f5;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            border-left: 4px solid #C41E3A;
            margin: 15px 0;
            font-size: 0.9em;
            line-height: 1.4;
        }

        /* Responsiveness */
        @media (max-width: 768px) {
            .header {
                padding: 40px 20px;
            }

            .header h1 {
                font-size: 1.8em;
            }

            .content {
                padding: 30px 20px;
                text-align: justify;
            }

            .section-title {
                font-size: 1.6em;
            }

            .specifications,
            .rubric-grid {
                grid-template-columns: 1fr;
            }

            .structure-item h4 {
                font-size: 1.05em;
            }

            .format-table {
                font-size: 0.9em;
            }

            .format-table th,
            .format-table td {
                padding: 10px;
            }

            p,
            li,
            td {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }
        }

        /* Animation */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .section {
            animation: fadeIn 0.6s ease-out;
        }

        .spec-card {
            animation: fadeIn 0.6s ease-out;
        }

        /* Print styles */
        @media print {
            body {
                background: white;
                padding: 2.5cm;
                margin: 0;
                font-size: 12pt;
                line-height: 1.5;
                counter-reset: page 1;
            }

            .container {
                box-shadow: none;
                border-radius: 0;
                padding: 0;
                max-width: 100%;
                margin: 0;
            }

            .header {
                page-break-after: avoid;
                padding: 30px 0;
            }

            .content {
                padding: 0;
                text-align: justify;
            }

            p,
            li,
            td,
            th {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }

            .section {
                page-break-inside: avoid;
            }

            @page {
                margin: 2.5cm;

                @bottom-center {
                    content: counter(page);
                    font-size: 12pt;
                    font-family: Arial, sans-serif;
                }
            }
        }

        /* Code styles */
        code {
            background: #f0f0f0;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d63384;
        }

        /* COVER PAGE STYLES */
        .cover-page {
            display: flex;
            align-items: flex-start;
            justify-content: center;
            min-height: 100vh;
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            color: #000;
            text-align: center;
            padding: 60px 60px 80px 60px;
            page-break-after: always;
            position: relative;
        }

        .cover-page::before {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #C41E3A, rgba(196, 30, 58, 0) 50%, rgba(196, 30, 58, 0));
        }

        .cover-page::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 2px;
            background: linear-gradient(90deg, rgba(196, 30, 58, 0), #C41E3A 50%, rgba(196, 30, 58, 0));
        }

        .cover-content {
            max-width: 600px;
            animation: fadeInCover 0.8s ease;
        }

        @keyframes fadeInCover {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .cover-logos {
            display: flex;
            justify-content: space-between;
            gap: 0;
            margin-bottom: 50px;
            align-items: center;
            width: 100%;
            max-width: none;
            margin-left: 0;
            margin-right: 0;
            min-height: 120px;
        }

        .cover-logo {
            flex: 0 0 auto;
            background: rgba(139, 21, 56, 0.05);
            padding: 15px;
            border-radius: 8px;
            border: 1px solid rgba(139, 21, 56, 0.2);
            backdrop-filter: blur(10px);
        }

        .cover-logo img {
            max-width: 100px;
            height: auto;
            filter: brightness(1);
            transition: transform 0.3s ease;
        }

        .cover-logo img:hover {
            transform: scale(1.05);
        }

        .cover-institution {
            margin-bottom: 60px;
            letter-spacing: 0.5px;
        }

        .cover-institution h2 {
            font-size: 2em;
            margin-bottom: 8px;
            font-weight: 700;
            letter-spacing: 0.3px;
            line-height: 1.2;
            color: #000;
        }

        .cover-institution p {
            font-size: 1.15em;
            opacity: 1;
            font-weight: 500;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-course {
            margin-bottom: 90px;
            font-size: 1.25em;
            font-style: italic;
            opacity: 1;
            font-weight: 400;
            letter-spacing: 0.3px;
            color: #000;
        }

        .cover-main {
            margin-bottom: 100px;
        }

        .cover-main h1 {
            font-size: 3.5em;
            margin-bottom: 20px;
            font-weight: 800;
            text-shadow: none;
            line-height: 1.1;
            letter-spacing: -0.5px;
            color: #000;
        }

        .cover-subtitle {
            font-size: 1.4em;
            opacity: 1;
            font-style: italic;
            line-height: 1.5;
            font-weight: 300;
            color: #000;
        }

        .cover-author {
            margin-bottom: 70px;
            font-size: 1.1em;
        }

        .cover-author p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-author p:last-child {
            font-size: 1.4em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-date {
            font-size: 1.1em;
            margin-top: 80px;
            padding-top: 30px;
            border-top: 1px solid #C41E3A;
        }

        .cover-date p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-date p:last-child {
            font-size: 1.3em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        /* Print styles for cover */
        @media print {
            .cover-page {
                page-break-after: always;
                background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
                color: white;
            }
        }

        code-block {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            display: block;
            overflow-x: auto;
        }

        /* Footer con numeraci√≥n de p√°gina */
        .page-number {
            text-align: center;
            padding: 20px 0;
            color: #999;
            font-size: 11pt;
            border-top: 1px solid #ddd;
            margin-top: 40px;
        }

        @media print {
            .page-number {
                display: none;
            }
        }

        /* Download Button */
        .download-container {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
        }

        .download-btn {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: bold;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(139, 21, 56, 0.3);
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .download-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(139, 21, 56, 0.4);
        }

        .download-btn:active {
            transform: translateY(0);
        }

        @media print {
            .download-container {
                display: none;
            }
        }

        /* Page Break Control */
        .page-section {
            page-break-after: always;
            page-break-inside: avoid;
            padding: 20px 0;
            margin-bottom: 1cm;
        }

        .page-section:last-child {
            page-break-after: avoid;
        }

        .section-page-break {
            page-break-after: always;
        }

        /* Evitar rupturas dentro de elementos */
        .page-section .section {
            page-break-inside: avoid;
        }

        .section-subtitle {
            page-break-after: avoid;
        }

        .section-title {
            page-break-after: avoid;
        }

        ul,
        ol {
            page-break-inside: avoid;
        }

        .format-table {
            page-break-inside: avoid;
        }

        .spec-card {
            page-break-inside: avoid;
        }

        .highlight-box {
            page-break-inside: avoid;
        }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script src="https://unpkg.com/docx@8.12.6/build/index.js"></script>
    <script>
        // Script para numeraci√≥n de p√°ginas
        window.addEventListener('load', function () {
            // En navegador, agregar numeraci√≥n visible
            const pageNumbers = document.querySelectorAll('.page-number');
            if (pageNumbers.length > 0) {
                let pageCount = 1;
                pageNumbers.forEach((element, index) => {
                    element.textContent = 'P√°gina ' + (index + 1);
                });
            }
        });

        // Funci√≥n para descargar como Word
        function downloadAsWord() {
            try {
                const container = document.querySelector('.container');
                if (!container) {
                    alert('No se encontr√≥ el contenido para exportar');
                    return;
                }

                // Obtener el HTML completo
                const html = container.innerHTML;

                // Crear documento Word en formato OOXML
                const docContent = `<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<?mso-application progid="Word.Document"?>
<html xmlns:v="urn:schemas-microsoft-com:vml"
 xmlns:o="urn:schemas-microsoft-com:office:office"
 xmlns:w="urn:schemas-microsoft-com:office:word"
 xmlns:x="urn:schemas-microsoft-com:office:excel"
 xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
 xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 16">
<meta name=Originator content="Microsoft Word 16">
<link rel=File-List href="filelist.xml">
<title>Reporte Final - An√°lisis de sentimientos en versos</title>
<o:DocumentProperties>
 <o:Author>Erik I. Osornio Botello</o:Author>
 <o:LastAuthor>Erik I. Osornio Botello</o:LastAuthor>
 <o:Created>2025-10-16T00:00:00Z</o:Created>
 <o:LastSaved>2025-10-16T00:00:00Z</o:LastSaved>
 <o:Pages>1</o:Pages>
 <o:Words>1</o:Words>
 <o:Characters>1</o:Characters>
 <o:Lines>1</o:Lines>
 <o:Paragraphs>1</o:Paragraphs>
 <o:CharactersWithSpaces>1</o:CharactersWithSpaces>
 <o:Version>16.00</o:Version>
</o:DocumentProperties>
</head>
<body>
${html}
</body>
</html>`;

                // Crear Blob
                const blob = new Blob([docContent], { type: 'application/vnd.ms-word' });

                // Descargar
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;
                link.download = 'Reporte_Analisis_Sentimientos.doc';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);

                alert('‚úì Descargado: Reporte_Analisis_Sentimientos.doc');
            } catch (error) {
                console.error('Error:', error);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }

        // Funci√≥n alternativa: descargar como PDF
        function downloadAsPDF() {
            try {
                const element = document.querySelector('.container');
                const cloned = element.cloneNode(true);
                cloned.querySelectorAll('.download-container, .page-number, .header').forEach(el => el.remove());

                const opt = {
                    margin: 10,
                    filename: 'Reporte_Analisis_Sentimientos.pdf',
                    image: { type: 'jpeg', quality: 0.98 },
                    html2canvas: { scale: 2 },
                    jsPDF: { orientation: 'portrait', unit: 'mm', format: 'a4' }
                };

                html2pdf().set(opt).from(cloned).save();
                alert('Descargando como PDF...');
            } catch (err) {
                console.error('Error al descargar:', err);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }
    </script>
</head>

<body>
    <div class="container">
        <!-- COVER PAGE -->
        <div class="cover-page">
            <div class="cover-content">
                <div class="cover-logos">
                    <div class="cover-logo">
                        <img src="logo_cic.jpg" alt="Logo CIC - Centro de Investigaci√≥n en Computaci√≥n">
                    </div>
                    <div class="cover-institution" style="text-align: center; flex: 1; display: flex; flex-direction: column; align-items: center; justify-content: center;">
                        <h2 style="margin: 0; padding: 0 20px; font-size: 1.3em;">Centro de Investigaci√≥n en Computaci√≥n</h2>
                        <p style="margin: 10px 0 0 0; font-size: 1em;">Diplomado en Inteligencia Artificial</p>
                    </div>
                    <div class="cover-logo">
                        <img src="logo_ipn.jpg" alt="Logo IPN - Instituto Polit√©cnico Nacional">
                    </div>
                </div>

                <div class="cover-course">
                    <p style="display: none;">Diplomado en Inteligencia Artificial</p>
                </div>

                <div class="cover-main">
                    <h1>An√°lisis de sentimientos en poemas</h1>
                    <p class="cover-subtitle">Implementaci√≥n y Evaluaci√≥n de Tres Enfoques de Clasificaci√≥n</p>
                </div>

                <div class="cover-author">
                    <p><strong>Autor:</strong></p>
                    <p>Erik I. Osornio Botello</p>
                </div>

                <div class="cover-date">
                    <p><strong>Fecha de Entrega:</strong></p>
                    <p>16 de Octubre de 2025</p>
                </div>
            </div>
        </div>

        <!-- TABLE OF CONTENTS -->
        <div style="page-break-after: always; padding: 40px 0;">
            <h2 style="font-size: 1.8em; color: #000; margin-bottom: 30px; text-align: center; font-weight: bold;">
                √çndice</h2>
            <ol style="font-size: 12pt; line-height: 2; margin-left: 30px; color: #333;">
                <li>Introducci√≥n</li>
                <li>Metodolog√≠a</li>
                <li>Datos</li>
                <li>Preprocesamiento</li>
                <li>Representaci√≥n de texto</li>
                <li>Modelos implementados
                    <ol style="margin-top: 10px; margin-left: 20px;">
                        <li>Regresi√≥n Log√≠stica</li>
                        <li>Naive Bayes Multinomial</li>
                        <li>DeBERTa‚Äëv3‚Äëbase (fine‚Äëtuning)</li>
                    </ol>
                </li>
                <li>Entrenamiento y validaci√≥n</li>
                <li>M√©tricas y evaluaci√≥n</li>
                <li>Resultados</li>
                <li>Discusi√≥n</li>
                <li>Conclusiones y trabajo futuro</li>
                <li>Referencias</li>
            </ol>
        </div>

        <!-- Main Content -->
        <div class="content">
            <!-- PAGE 1: Title and Author -->
            <div class="page-section">
                <div class="section" style="text-align: center; margin-bottom: 60px;">
                    <h2 style="font-size: 2.2em; color: #000; margin-bottom: 10px;">An√°lisis de sentimientos en versos
                    </h2>
                    <p style="font-size: 1.2em; color: #000; margin-bottom: 30px;"><strong>Autor:</strong> Erik I.
                        Osornio Botello</p>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; max-width: 800px; margin: 0 auto;">
                        <h3 style="color: #000; margin-bottom: 15px;">Resumen</h3>
                        <p style="text-align: justify; line-height: 1.8; color: #333;">
                            Este documento describe el desarrollo, implementaci√≥n y evaluaci√≥n de un sistema de an√°lisis
                            de sentimientos sobre versos del dataset Poem Sentiment. Se comparan <strong>baselines
                                cl√°sicos</strong>
                            (Regresi√≥n Log√≠stica y Naive Bayes Multinomial con CountVectorizer+SMOTE) frente a un
                            <strong>modelo preentrenado DeBERTa‚Äëv3‚Äëbase</strong> ajustado finamente. Se detalla el flujo
                            completo: exploraci√≥n y limpieza de datos, diferencias de preprocesamiento por enfoque,
                            entrenamiento, optimizaci√≥n de hiperpar√°metros, evaluaci√≥n y discusi√≥n de resultados.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 2: Introduction Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìã 1. Introducci√≥n</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        El an√°lisis de sentimientos busca asignar una polaridad (por ejemplo: positiva, negativa,
                        neutral) a textos.
                        En este proyecto se implementan tres enfoques que representan paradigmas distintos: modelos
                        lineales probabil√≠sticos
                        (Regresi√≥n Log√≠stica), modelos de probabilidades condicionales con suposiciones de independencia
                        (Naive Bayes Multinomial)
                        y un transformador preentrenado (DeBERTa‚Äëv3‚Äëbase). Se discute su preparaci√≥n,
                        rendimiento y trade-offs.
                    </p>

                    <div class="section-subtitle">Contexto del Problema</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El an√°lisis de sentimientos en textos po√©ticos presenta un desaf√≠o particular comparado con textos
                        cotidianos o t√©cnicos. La poes√≠a, especialmente la de √©pocas antiguas, emplea un lenguaje altamente
                        metaf√≥rico, ambiguo y cargado de subjetividad. Los poetas frecuentemente expresan emociones de manera
                        indirecta, mediante descripciones de la naturaleza, objetos abstractos o figuras literarias, lo que
                        dificulta la detecci√≥n autom√°tica del sentimiento. Este proyecto aborda la clasificaci√≥n de versos
                        de poemas ingleses antiguos en categor√≠as de sentimiento (positivo, negativo, sin impacto),
                        utilizando un dataset curado de 1,101 ejemplos disponible en Hugging Face.
                    </p>

                    <div class="section-subtitle">Importancia Acad√©mica e Industrial</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Este proyecto es relevante en m√∫ltiples contextos:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Acad√©mico:</strong> Consolida conocimientos de aprendizaje supervisado, procesamiento de
                            lenguaje natural (NLP), y comparaci√≥n de paradigmas cl√°sicos vs. modernos (Transformers). Proporciona
                            experiencia pr√°ctica en gesti√≥n de datos desbalanceados, regularizaci√≥n y evaluaci√≥n de modelos.</li>
                        <li><strong>Industrial/Aplicado:</strong> Las t√©cnicas son transferibles a an√°lisis de sentimientos en
                            rese√±as de libros, cr√≠ticas literarias, an√°lisis de opiniones en redes sociales, y herramientas de
                            asistencia editorial. La metodolog√≠a de comparaci√≥n entre baselines y transformadores es aplicable
                            a cualquier tarea de clasificaci√≥n de texto con recursos limitados.</li>
                    </ul>

                    <div class="section-subtitle">Alcance y Limitaciones</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        <strong>Alcance:</strong> Este proyecto implementa tres modelos completos (Regresi√≥n Log√≠stica, Naive Bayes
                        Multinomial, DeBERTa-v3-base), documenta el pipeline de preprocesamiento, reporta m√©tricas de desempe√±o
                        (F1-macro, accuracy, precision, recall) y analiza resultados con √©nfasis en la clase positiva.
                    </p>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        <strong>Limitaciones:</strong>
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Tama√±o del dataset:</strong> Con 1,101 ejemplos y desbalance hacia la clase "sin impacto",
                            los modelos pueden tener capacidad de generalizaci√≥n limitada fuera de poes√≠a antigua en ingl√©s.</li>
                        <li><strong>Clase "mixta" excluida:</strong> La clase "mixed" se excluy√≥ por baja frecuencia (5.5%) y
                            ambig√ºedad conceptual, limitando la completitud del an√°lisis.</li>
                        <li><strong>Dominio espec√≠fico:</strong> Los modelos se entrenan en poes√≠a inglesa de Project Gutenberg,
                            por lo que su desempe√±o en otros idiomas, √©pocas o g√©neros no se garantiza.</li>
                        <li><strong>Recursos computacionales:</strong> No se exploraron modelos m√°s grandes (DeBERTa-large,
                            RoBERTa-large) ni ensembles por limitaciones de tiempo/recursos, dejando margen para mejora.</li>
                    </ul>

                    <div class="section-subtitle">Objetivos</div>
                    <ul style="line-height: 2;">
                        <li><strong>Objetivo General:</strong> Implementar y comparar tres enfoques de clasificaci√≥n (dos cl√°sicos y uno moderno basado en Transformers) para an√°lisis de sentimientos en poes√≠a, demostrando la viabilidad de ambos paradigmas con √©nfasis en t√©cnicas de regularizaci√≥n para datasets peque√±os.</li>
                        <li><strong>Objetivos Espec√≠ficos:</strong>
                            <ul style="margin-top: 8px; margin-left: 20px; line-height: 1.8;">
                                <li>Alcanzar F1-macro ‚â• 0.85 en el conjunto de prueba mediante fine-tuning de DeBERTa-v3-base con Focal Loss y class weights.</li>
                                <li>Comparar baselines cl√°sicos (Regresi√≥n Log√≠stica, Naive Bayes Multinomial) con transformadores, evaluando trade-offs de complejidad vs. desempe√±o.</li>
                                <li>Documentar estrategias de preprocesamiento diferenciadas seg√∫n el tipo de modelo, preservando matices po√©ticos en transformadores.</li>
                                
                                <li>Proporcionar recomendaciones reproducibles para an√°lisis de sentimientos en dominios especializados (poes√≠a, literatura, textos arcaicos).</li>
                            </ul>
                        </li>
                    </ul>

                    <div class="section-subtitle">Marco de Referencia</div>
                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <p style="margin-bottom: 12px;">
                            <strong>üìã Indicaciones del Proyecto:</strong> Este proyecto se fundamenta en las
                            indicaciones
                            especificadas en el documento <em>Indicaciones Proyecto Poemas.pdf</em>, el cual establece
                            que:
                        </p>
                        <p
                            style="margin-bottom: 12px; padding-left: 15px; border-left: 3px solid #C41E3A; margin-left: 0;">
                            <strong>"Este proyecto es un ejercicio de aprendizaje supervisado. La idea general consiste
                                en
                                implementar tres clasificadores de texto para el problema de an√°lisis de sentimientos en
                                versos de poemas."</strong>
                        </p>
                        <p>
                            <strong>Clases del Problema:</strong> El marco original define tres categor√≠as de
                            sentimiento (positivo, negativo
                            o neutral), aunque en la pr√°ctica el dataset utilizado incluye cuatro clases: Positivo,
                            Negativo, Mixto y No impacto.
                            La estructura de tres clasificadores y el enfoque de aprendizaje supervisado se mantienen
                            como eje central de
                            la implementaci√≥n.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 1.5: Marco Te√≥rico -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìö 1.5 Marco Te√≥rico</div>

                    <div class="section-subtitle">An√°lisis de Sentimientos (Sentiment Analysis)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El an√°lisis de sentimientos es una tarea fundamental en el procesamiento de lenguaje natural (NLP) que busca 
                        determinar la orientaci√≥n emocional (positiva, negativa o neutra) de un texto. Formalmente, es un problema 
                        de clasificaci√≥n multiclase donde se asigna una etiqueta de sentimiento a cada documento bas√°ndose en su 
                        contenido ling√º√≠stico.
                    </p>

                    <div class="section-subtitle">Enfoques Cl√°sicos vs. Transformadores</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Existen dos paradigmas principales para esta tarea:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Enfoques Cl√°sicos (Bolsa de Palabras):</strong> Modelos como Naive Bayes y Regresi√≥n Log√≠stica 
                        trabajan con representaciones de frecuencia (TF-IDF, CountVectorizer). Son r√°pidos, interpretables y eficientes 
                        con datos peque√±os, pero no capturan relaciones contextuales o sem√°nticas complejas.</li>
                        <li><strong>Transformadores (Contextuales):</strong> Modelos como BERT, DeBERTa utilizan mecanismos de 
                        auto-atenci√≥n para capturar dependencias de largo alcance y contexto. Requieren m√°s datos y recursos, pero 
                        son superiores en capturar matices ling√º√≠sticos, especialmente en dominios especializados como la poes√≠a.</li>
                    </ul>

                    <div class="section-subtitle">Desaf√≠os en An√°lisis de Sentimientos de Poes√≠a</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El lenguaje po√©tico presenta caracter√≠sticas √∫nicas que lo hacen m√°s desafiante:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Ambig√ºedad Sem√°ntica:</strong> Los poemas emplean met√°foras, simbolismo y dobles sentidos que 
                        dificultan la extracci√≥n autom√°tica de sentimientos.</li>
                        <li><strong>Expresi√≥n Indirecta:</strong> Las emociones se comunican impl√≠citamente a trav√©s de descripciones 
                        de objetos, naturaleza o estados abstractos, no mediante palabras emocionales expl√≠citas.</li>
                        <li><strong>Escasez de Datos Etiquetados:</strong> Hay pocos datasets de sentimientos en poes√≠a comparado con 
                        rese√±as de productos o redes sociales, lo que requiere t√©cnicas de regularizaci√≥n robustas.</li>
                        <li><strong>Vocabulario Arcaico:</strong> La poes√≠a antigua contiene palabras y estructuras ling√º√≠sticas 
                        obsoletas que requieren preprocesamiento especializado.</li>
                    </ul>

                    <div class="section-subtitle">T√©cnicas de Regularizaci√≥n para Datasets Peque√±os</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Con 1,101 ejemplos (peque√±o para deep learning), se aplican t√©cnicas para mejorar generalizaci√≥n:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>SMOTE:</strong> Sobremuestreo sint√©tico de clases minoritarias para balanceo en modelos cl√°sicos.</li>
                        <li><strong>Focal Loss:</strong> Funci√≥n de p√©rdida que penaliza m√°s ejemplos mal clasificados de clases 
                        minoritarias, evitando que el modelo ignore clases raras.</li>
                        <li><strong>Class Weights:</strong> Asignaci√≥n de pesos inversamente proporcionales a la frecuencia de clase.</li>
                        <li><strong>Label Smoothing:</strong> T√©cnica que suaviza etiquetas one-hot (0.1 en clases incorrectas) para 
                        evitar sobrefitting.</li>
                        <li><strong>Early Stopping:</strong> Detenci√≥n del entrenamiento cuando la m√©trica de validaci√≥n no mejora, 
                        evitando sobreajuste.</li>
                    </ul>
                </div>
            </div>

            <!-- PAGE 2.1: Metodolog√≠a -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üß≠ 2. Metodolog√≠a</div>

                    <div class="section-subtitle">An√°lisis de los datos y preprocesamiento</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El dataset <em>Poem Sentiment</em> presenta textos breves, con fuerte desbalance hacia la clase
                        <code>no_impact</code> y matices po√©ticos/arcaicos. Se implementaron dos estrategias de
                        preprocesamiento diferentes, de acuerdo con el tipo de modelo:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Baselines cl√°sicos (MultinomialNB, Regresi√≥n Log√≠stica):</strong> preprocesamiento
                            optimizado para poes√≠a inglesa antigua (expansi√≥n de contracciones arcaicas, normalizaci√≥n de
                            signos, limpieza suave). Tras tokenizar, se aplic√≥
                            <code>CountVectorizer(max_features=10000)</code>
                            y balanceo con <code>SMOTE</code> √∫nicamente sobre el entrenamiento (excluyendo
                            <code>mixed</code>).
                            Esta decisi√≥n busca maximizar se√±al l√©xica √∫til para modelos basados en bolsa de palabras.
                        </li>
                        <li><strong>DeBERTa‚Äëv3‚Äëbase (fine‚Äëtuning):</strong> preprocesamiento <em>ligero y no
                                destructivo</em>
                            (normalizar comillas/guiones, eliminar duplicados, sin stemming ni stopwords), preservando los
                            matices po√©ticos para que el tokenizador subword capture sem√°ntica contextual. Se excluye la
                            clase
                            <code>mixed</code> en todos los splits.
                        </li>
                    </ul>
                    <div class="highlight-box">
                        <strong>Justificaci√≥n de la elecci√≥n:</strong> en enfoques cl√°sicos conviene estandarizar la forma
                        superficial de las palabras para que la frecuencia sea informativa; en transformadores, el
                        tokenizador y el contexto aten√∫an la necesidad de limpiar agresivamente, y remover stopwords puede
                        incluso eliminar matices √∫tiles en poes√≠a.
                    </div>

                    <div class="section-subtitle">Modelos de IA empleados</div>
                    <ul style="line-height: 2;">
                        <li><strong>Multinomial Naive Bayes:</strong> probabil√≠stico, r√°pido y efectivo con conteos de
                            tokens; se ajust√≥ y luego se <em>tune√≥</em> el hiperpar√°metro <code>alpha</code> v√≠a
                            <code>GridSearchCV</code>.
                        </li>
                        <li><strong>Regresi√≥n Log√≠stica:</strong> baseline lineal con <code>class_weight='balanced'</code>
                            para mitigar desbalance sin sobremuestreo.</li>
                        <li><strong>DeBERTa‚Äëv3‚Äëbase:</strong> transformador preentrenado ajustado finamente con t√©cnicas de
                            regularizaci√≥n (Focal Loss, label smoothing, early stopping) y optimizado por F1‚Äëmacro.</li>
                    </ul>

                    <div class="section-subtitle">Herramientas y tecnolog√≠as</div>
                    <div class="specifications">
                        <div class="spec-card"><strong>Frameworks</strong> PyTorch, Hugging Face Transformers</div>
                        <div class="spec-card"><strong>ML cl√°sico</strong> scikit‚Äëlearn, imbalanced‚Äëlearn</div>
                        <div class="spec-card"><strong>Gesti√≥n de datos</strong> pandas, numpy, datasets (HF)</div>
                        <div class="spec-card"><strong>Gr√°ficos</strong> matplotlib, seaborn</div>
                        <div class="spec-card"><strong>NLP utilitario</strong> NLTK</div>
                        <div class="spec-card"><strong>I/O</strong> fastparquet/pyarrow (URIs hf://)</div>
                    </div>
                </div>
            </div>

            <!-- PAGE 3: Data Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìä 3. Datos</div>

                    <div class="section-subtitle">Descripci√≥n del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        <strong>Fuente:</strong> Para este proyecto se utiliz√≥ el dataset <em>Poem Sentiment</em> del
                        repositorio de Google Research,
                        disponible en Hugging Face (hf://datasets/google-research-datasets/poem_sentiment). Este
                        conjunto de datos consiste en versos
                        de poemas extra√≠dos de Project Gutenberg, etiquetados seg√∫n el sentimiento que transmiten.
                    </p>

                    <div class="spec-card">
                        <strong>üìà Caracter√≠sticas principales:</strong>
                        <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                            <li><strong>N√∫mero total de ejemplos:</strong> 1,101 versos</li>
                            <li><strong>Idioma:</strong> Textos en ingl√©s</li>
                            <li><strong>Tama√±o:</strong> Dataset peque√±o, puede dificultar la generalizaci√≥n al entrenar
                                modelos complejos desde cero. No obstante, con transformadores preentrenados y t√©cnicas
                                de regularizaci√≥n (early stopping, class weights/Focal Loss, label smoothing) es posible
                                lograr buen desempe√±o.</li>
                            <li><strong>Balanceo de Clases:</strong> Se aplicaron t√©cnicas de balanceo: SMOTE en modelos
                                cl√°sicos (Naive Bayes, Logistic Regression) y Focal Loss con class weights en DeBERTa
                                para mitigar el desbalance inherente del dataset.</li>
                        </ul>
                    </div>

                    <div class="section-subtitle">Clases de Sentimiento</div>
                    <ul style="line-height: 2;">
                        <li><strong>Positivo:</strong> Versos con emociones positivas</li>
                        <li><strong>Negativo:</strong> Versos con emociones negativas</li>
                        <li><strong>Mixto:</strong> Versos que combinan emociones positivas y negativas</li>
                        <li><strong>No impacto:</strong> Versos que no presentan un sentimiento claro</li>
                    </ul>

                    <div class="section-subtitle">Columnas del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        Este conjunto de datos consta de versos de poemas extra√≠dos de Project Gutenberg, etiquetados
                        seg√∫n el sentimiento que transmiten.
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>verse_text:</strong> Contiene el texto del verso del poema</li>
                        <li><strong>label:</strong> Indica la categor√≠a de sentimiento del verso</li>
                    </ul>

                    <div class="section-subtitle">Exploraci√≥n Inicial</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        En la fase de exploraci√≥n, no se encontraron valores nulos. El histograma de las longitudes por
                        clase se encuentra representado en la Ilustraci√≥n 2.
                    </p>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="verse_lengths_distribution.png"
                            alt="Gr√°fico de Distribuci√≥n de Longitudes de Versos por Clase"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Ilustraci√≥n 1. Distribuci√≥n de longitudes por clase</p>
                    </div>

                    <p style="text-align: justify; line-height: 1.5; margin-top: 20px;">
                        La figura muestra la distribuci√≥n de la longitud de los versos seg√∫n su sentimiento. Se observa
                        que la mayor√≠a de los versos tienen entre 30 y 50 palabras,
                        con predominancia de la clase no impact. Las clases minoritarias (mixed, positivo, negativo)
                        est√°n menos representadas, lo que refuerza el desbalance del dataset.
                        Esta distribuci√≥n sugiere que los modelos podr√≠an aprender primero la clase mayoritaria y que
                        los ejemplos muy largos son poco frecuentes y podr√≠an considerarse outliers.
                    </p>

                    <div class="section-subtitle">Divisi√≥n de Datos</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Conjunto</th>
                                <th>N√∫mero de Ejemplos</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Entrenamiento</strong></td>
                                <td>892 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Validaci√≥n</strong></td>
                                <td>105 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Test</strong></td>
                                <td>104 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Total</strong></td>
                                <td>1,101 ejemplos</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="section-subtitle">Distribuci√≥n de Clases (Entrenamiento Original)</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                                <th>Porcentaje</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>555</td>
                                <td>62.2%</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>155</td>
                                <td>17.4%</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>133</td>
                                <td>14.9%</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>49</td>
                                <td>5.5%</td>
                            </tr>
                        </tbody>
                    </table>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="sentiment_distribution.png"
                            alt="Gr√°fico de Distribuci√≥n de Clases en Datos de Entrenamiento"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Figura 1: Distribuci√≥n de Sentimientos en los Datos de Entrenamiento Original</p>
                    </div>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <strong>‚ö†Ô∏è Problema de Desbalance:</strong> La mayor√≠a de los versos pertenecen a la clase "No
                        impacto",
                        mientras que la clase "Mixto" tiene muy pocos ejemplos. Este desbalance puede generar:
                        <ul style="margin-left: 20px; margin-top: 10px; margin-bottom: 10px; line-height: 1.8;">
                            <li><strong>Bias hacia la clase mayoritaria:</strong> Los modelos tienden a predecir con
                                mayor frecuencia la clase predominante (No impacto), lo que puede inflar el accuracy
                                aparente, pero reducir la capacidad de identificar correctamente las clases
                                minoritarias.</li>
                            <li><strong>Problemas de generalizaci√≥n en modelos complejos:</strong> Las redes
                                neuronales pueden sobreajustar f√°cilmente a la clase mayoritaria, especialmente cuando
                                el dataset es peque√±o. En este caso, modelos complejos pueden aprender patrones sesgados
                                en lugar de representaciones robustas de todas las clases.</li>
                            <li><strong>M√©tricas poco confiables para clases minoritarias:</strong> Las m√©tricas de
                                rendimiento pueden ser enga√±osas si se interpretan sin considerar el desbalance.</li>
                        </ul>
                        <p style="margin-top: 12px; text-align: justify; line-height: 1.6; font-size: 11pt;">
                            Dado el tama√±o reducido y el desbalance, estos conjuntos pueden no ser representativos de la
                            distribuci√≥n real de clases.
                            Esto significa que las m√©tricas de evaluaci√≥n (accuracy, F1, recall, precision) pueden ser
                            ruidosas y poco confiables,
                            especialmente para las clases minoritarias como Mixto y Positivo.
                        </p>
                    </div>

                    <div class="section-subtitle">Estrategias de Mitigaci√≥n</div>
                    <ul style="line-height: 2;">
                        <li><strong>SMOTE (Modelos Cl√°sicos):</strong> Aplicada en el entrenamiento de Naive Bayes y
                            Logistic Regression para sobremuestreo sint√©tico y balanceo de clases minoritarias</li>
                        <li><strong>Focal Loss + Class weights (DeBERTa):</strong> Pesos por clase en el transformador
                            (DeBERTa) mediante Focal Loss (Œ≥=1.5) + class weights para penalizar predicciones
                            incorrectas de clases minoritarias y mejorar generalizaci√≥n</li>
                    </ul>

                    <div class="section-subtitle">Distribuci√≥n de Clases (Post Balanceo con SMOTE)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        <strong>Modelos Cl√°sicos (Naive Bayes, Logistic Regression):</strong> Se aplic√≥ SMOTE en el
                        conjunto de entrenamiento para generar muestras sint√©ticas de clases minoritarias y lograr
                        balanceo perfecto entre las tres clases.
                    </p>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>T√©cnica</th>
                                <th>Negativo</th>
                                <th>Positivo</th>
                                <th>No impacto</th>
                                <th>Total</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr style="background: #fff3cd;">
                                <td><strong>SMOTE (Entrenamiento) </strong></td>
                                <td>555</td>
                                <td>555</td>
                                <td>555</td>
                                <td>1,665</td>
                            </tr>
                        </tbody>
                    </table>
                    <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                        SMOTE gener√≥ 1,665 muestras de entrenamiento perfectamente balanceadas (555 por clase) a partir
                        de 843 originales.</p>

                    <div style="height: 20px;"></div>

                    <div class="section-subtitle">Exclusi√≥n de la clase "Mixta" (Mixed) en Evaluaci√≥n</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        La clase "mixed" (label=3) fue excluida de todos los modelos tanto en entrenamiento como en
                        evaluaci√≥n.
                        Esta decisi√≥n se basa en tres razones fundamentales:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Distribuci√≥n minoritaria:</strong> La clase "mixed" representa solo 5.5% del set de
                            entrenamiento,
                            lo que la hace altamente minoritaria y dificulta el entrenamiento robusto.</li>
                        <li><strong>Ambig√ºedad conceptual:</strong> Esta clase agrupa versos con sentimientos
                            contradictorios o ambiguos,
                            donde coexisten emociones positivas y negativas simult√°neamente. Para una aplicaci√≥n
                            pr√°ctica de an√°lisis
                            de sentimientos en poes√≠a, es m√°s √∫til clasificar en tres categor√≠as bien definidas
                            (negativo, positivo, sin impacto).</li>
                        <li><strong>Mejora de robustez del modelo:</strong> Excluir la clase "mixed" permite un problema
                            de clasificaci√≥n
                            m√°s claro y robusto, centrado en sentimientos claramente expresados, lo que mejora
                            significativamente las
                            m√©tricas de desempe√±o y la interpretabilidad de los resultados.</li>
                    </ul>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Por lo tanto, todos los resultados reportados (F1-macro, exactitud, matrices de confusi√≥n, etc.)
                        se calculan
                        considerando √∫nicamente las tres clases principales: negativo, positivo y sin impacto.
                    </p>
                </div>
            </div>

            <!-- PAGE 4: Preprocesamiento -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìù 4. Preprocesamiento</div>

                    <div class="section-subtitle">Preprocesamiento para Modelos Cl√°sicos (NB y Regresi√≥n Log√≠stica)
                    </div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El preprocesamiento aplicado ha sido cuidadosamente dise√±ado para optimizar la clasificaci√≥n de
                        sentimientos en poes√≠a inglesa antigua, equilibrando la limpieza textual con
                        la preservaci√≥n de caracter√≠sticas sem√°nticas relevantes. A diferencia de los enfoques est√°ndar
                        que aplican normalizaci√≥n agresiva, nuestra estrategia reconoce que el lenguaje po√©tico arcaico
                        contiene matices significativos para la detecci√≥n de sentimientos.
                    </p>

                    <ul style="line-height: 2;">
                        <li><strong>Preservaci√≥n del contexto po√©tico:</strong> El enfoque mantiene palabras arcaicas y
                            po√©ticas (como "doth", "hath", "ne'er") que, aunque no sean comunes en el ingl√©s moderno,
                            poseen un alto valor predictivo para la clasificaci√≥n de sentimientos en textos hist√≥ricos.
                            Estas palabras no se eliminan como stopwords, ya que a menudo aparecen en contextos emotivos
                            espec√≠ficos que el modelo necesita capturar.</li>

                        <li><strong>Normalizaci√≥n de contracciones antiguas:</strong> Se expandieron contracciones
                            arcaicas ("'twas" ‚Üí "it was", "o'er" ‚Üí "over") a palabras completas para mejorar la
                            representaci√≥n vectorial sin perder informaci√≥n l√©xica. Esta t√©cnica aumenta la consistencia
                            del vocabulario sin introducir ambig√ºedad, permitiendo que el vectorizador de conteo
                            (CountVectorizer) capte patrones m√°s robustos.</li>

                        <li><strong>Limpieza moderada de puntuaci√≥n:</strong> Se normaliz√≥ la puntuaci√≥n de manera
                            selectiva, removiendo caracteres especiales y de formato hist√≥rico, pero manteniendo la
                            estructura de oraciones. Esta aproximaci√≥n evita la p√©rdida de informaci√≥n contextual que
                            podr√≠a ser relevante para modelos basados en bolsa de palabras, donde la proximidad l√©xica
                            importa.</li>

                        <li><strong>Vectorizaci√≥n con CountVectorizer y balanceo SMOTE:</strong> Despu√©s del
                            preprocesamiento, se utiliz√≥ CountVectorizer con un vocabulario m√°ximo de 10,000 features
                            para capturar t√©rminos frecuentes relevantes. Aplicamos SMOTE solo en el conjunto de
                            entrenamiento para corregir el desbalance de clases de forma sint√©tica, evitando sobreajuste
                            al no modificar conjuntos de validaci√≥n y prueba.</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este dise√±o integrado maximiza la capacidad del modelo para distinguir entre sentimientos en
                        textos antiguos, priorizando la precisi√≥n sobre la simplicidad de preprocesamiento.
                    </p>

                    <div class="section-subtitle">Implementaci√≥n: Funci√≥n preprocess_poetry_text</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        La siguiente funci√≥n implementa esta estrategia de preprocesamiento optimizada para poes√≠a:
                    </p>

                    <div class="spec-card">
                        <strong>üìù Ejemplos de Preprocesamiento:</strong>
                        <div
                            style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                            <p><strong>Original (0):</strong> "with pale blue berries. in these peaceful shades--"</p>
                            <p><strong>Procesado:</strong> "with pale blue berries in these peaceful shades"</p>
                            <hr style="border: none; border-top: 1px solid #ddd; margin: 10px 0;">
                            <p><strong>Original (1):</strong> "it flows so long as falls the rain,"</p>
                            <p><strong>Procesado:</strong> "it flows so long as falls the rain"</p>
                            <hr style="border: none; border-top: 1px solid #ddd; margin: 10px 0;">
                            <p><strong>Original (2):</strong> "and that is why, the lonesome day,"</p>
                            <p><strong>Procesado:</strong> "and that is why the lonesome day"</p>
                        </div>
                    </div>

                    <div style="height: 20px; clear: both;"></div>



                    <div class="section-subtitle">Preprocesamiento en DeBERTa-v3-base</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El preprocesamiento aplicado en DeBERTa-v3-base es <strong>ligero y no destructivo</strong>,
                        dise√±ado espec√≠ficamente para preservar las caracter√≠sticas estil√≠sticas y sem√°nticas de la
                        poes√≠a:
                    </p>

                    <ul style="line-height: 2;">
                        <li><strong>Operaciones realizadas:</strong>
                            <ul style="margin-top: 8px; margin-left: 20px;">
                                <li>Normalizaci√≥n de comillas y guiones: convierte variantes Unicode (", ‚Äî, ‚Äì) a ASCII
                                    est√°ndar para evitar tokens raros</li>
                                <li>Colapso de espacios m√∫ltiples y recorte de espacios al inicio/final</li>
                                <li>Eliminaci√≥n de versos duplicados por coincidencia exacta</li>
                            </ul>
                        </li>
                        <li><strong>Decisiones importantes:</strong>
                            <ul style="margin-top: 8px; margin-left: 20px;">
                                <li><strong>Sin stemming ni stopwords:</strong> En poes√≠a, la morfolog√≠a completa y
                                    palabras aparentemente "vac√≠as" portan matices de sentimiento. Removerlas degrada la
                                    se√±al</li>
                                <li><strong>Sin lowercasing forzado:</strong> El tokenizador subword (BPE) de DeBERTa
                                    maneja may√∫sculas; adem√°s, en poes√≠a las may√∫sculas pueden tener valor estil√≠stico
                                </li>
                            </ul>
                        </li>
                    </ul>

                    <div class="section-subtitle">T√©cnicas de Balanceo de Clases</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Dado el desbalance del dataset,
                        se aplicaron t√©cnicas espec√≠ficas de balanceo seg√∫n el tipo de modelo:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Selecci√≥n de clases minoritarias:</strong> Se identifican las clases que tienen
                            pocas muestras (por ejemplo: ‚Äúnegative‚Äù, ‚Äúpositive‚Äù y ‚Äúmixed‚Äù).</li>
                        <li><strong>SMOTE (Synthetic Minority Over-sampling Technique):</strong> Para los modelos
                            cl√°sicos (Multinomial Naive Bayes y Regresi√≥n Log√≠stica), se aplic√≥ SMOTE exclusivamente en
                            el conjunto de entrenamiento para generar sint√©ticamente nuevas muestras de las clases
                            minoritarias. Esto corrige el desbalance sin perder informaci√≥n, permitiendo que los modelos
                            aprendan a distinguir mejor entre sentimientos.</li>
                        <li><strong>Focal Loss y Class Weights:</strong> Para DeBERTa-v3-base, se utiliz√≥ Focal Loss
                            combinada con pesos de clases para manejar el desbalance. Este enfoque es m√°s eficaz en
                            redes neuronales profundas, ya que el Focal Loss penaliza m√°s los ejemplos mal clasificados
                            de las clases minoritarias.</li>
                        <li><strong>Preservaci√≥n de sets de validaci√≥n y prueba:</strong> Tanto SMOTE como los pesos de
                            clase se aplicaron √∫nicamente al conjunto de entrenamiento. Los conjuntos de validaci√≥n y
                            prueba mantuvieron su distribuci√≥n original para garantizar evaluaci√≥n realista de la
                            capacidad de generalizaci√≥n del modelo.</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este enfoque diferenciado permite optimizar cada modelo de acuerdo a sus caracter√≠sticas,
                        mejorando el desempe√±o sin comprometer la evaluaci√≥n independiente.
                    </p>

                </div>

                <!-- PAGE 5: Text Representation -->
                <div class="page-section">


                    <!-- PAGE 5.1: Implementaci√≥n -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">üõ†Ô∏è Implementaci√≥n</div>

                            <div class="section-subtitle">Pipeline de desarrollo</div>
                            <div class="structure-list">
                                <div class="structure-item">
                                    <h4>Baselines cl√°sicos (NB / Reg. Log√≠stica)</h4>
                                    <div class="structure-description">
                                        <ol>
                                            <li>Exploraci√≥n y divisi√≥n de datos (train/val/test) desde Hugging Face</li>
                                            <li>Preprocesamiento optimizado para poes√≠a (expansi√≥n de contracciones,
                                                limpieza suave)</li>
                                            <li>Vectorizaci√≥n con <code>CountVectorizer(max_features=10000)</code></li>
                                            <li>Exclusi√≥n de clase <code>mixed</code> y balanceo con <code>SMOTE</code>
                                                (solo train)</li>
                                            <li>Entrenamiento de <code>MultinomialNB</code> y
                                                <code>LogisticRegression</code>
                                            </li>
                                            <li>Ajuste de <code>alpha</code> (NB) con <code>GridSearchCV</code></li>
                                            <li>Evaluaci√≥n macro‚ÄëF1 (sin clase <code>mixed</code>) y matrices de
                                                confusi√≥n</li>
                                        </ol>
                                    </div>
                                </div>
                                <div class="structure-item">
                                    <h4>DeBERTa‚Äëv3‚Äëbase (fine‚Äëtuning)</h4>
                                    <div class="structure-description">
                                        <ol>
                                            <li>Preprocesamiento ligero (normalizar comillas/guiones, deduplicar)</li>
                                            <li>Exclusi√≥n de clase <code>mixed</code> en todos los splits</li>
                                            <li>Tokenizaci√≥n subword (max_len=128) y creaci√≥n de datasets de HF</li>
                                            <li>Hiperpar√°metros: lr=2e‚Äë5, batch=16, epochs=6, warmup=0.05</li>
                                            <li>Regularizaci√≥n: Focal Loss (Œ≥=1.5) + class weights, label smoothing=0.1
                                            </li>
                                            <li>Entrenamiento con Trainer optimizando F1‚Äëmacro + early stopping</li>
                                            <li>Evaluaci√≥n en validaci√≥n y test; an√°lisis por clase y matriz de
                                                confusi√≥n</li>
                                        </ol>
                                    </div>
                                </div>
                            </div>

                            <div class="section-subtitle" style="margin-top: 25px;">Optimizaci√≥n y ajustes
                                (hiperpar√°metros)</div>
                            <div class="specifications">
                                <div class="spec-card">
                                    <strong>MultinomialNB</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li><code>GridSearchCV</code> sobre
                                            <code>alpha ‚àà {0.01, 0.1, 0.5, 1.0, 5.0, 10.0}</code>
                                        </li>
                                        <li><em>Scoring</em>: F1‚Äëmacro, CV=5</li>
                                    </ul>
                                </div>
                                <div class="spec-card">
                                    <strong>Regresi√≥n Log√≠stica</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li><code>class_weight='balanced'</code>, <code>max_iter=2000</code>,
                                            <code>solver='liblinear'</code>
                                        </li>
                                    </ul>
                                </div>
                                <div class="spec-card">
                                    <strong>DeBERTa‚Äëv3‚Äëbase</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li>Focal Loss (Œ≥=1.5) + <em>class weights</em>, <em>label smoothing</em>=0.1
                                        </li>
                                        <li>lr=2e‚Äë5, batch=16, epochs=6, warmup_ratio=0.05, early stopping (patience=3)
                                        </li>
                                        <li>M√©trica objetivo: F1‚Äëmacro</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- PAGE 6: Models -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">ü§ñ 6. Modelos Implementados</div>

                            <div class="section-subtitle">5.1 Regresi√≥n Log√≠stica</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                La regresi√≥n log√≠stica fue seleccionada por su capacidad para manejar eficazmente
                                representaciones vectorizadas
                                del texto. Este modelo aprende a estimar la probabilidad de pertenencia a cada clase
                                mediante una combinaci√≥n
                                lineal de caracter√≠sticas, lo cual resulta apropiado en problemas de an√°lisis de texto
                                donde la presencia
                                o frecuencia de ciertas palabras suele correlacionarse directamente con el sentimiento.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Permite incorporar pesos para clases minoritarias (class weights)</li>
                                    <li>Naturaleza probabil√≠stica facilita interpretar confianza</li>
                                    <li>Bajo costo computacional y estable</li>
                                    <li>Excelente baseline para comparar con modelos m√°s complejos</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>
                            <div class="section-subtitle" style="border-left: none; padding-left: 0;">Configuraci√≥n:
                                LogisticRegression</div>
                            <pre class="code-block"><code>lr_model = LogisticRegression(
    random_state=SEED,
    max_iter=2000,
    class_weight='balanced',
    C=1.0,
    solver='liblinear'
)</code></pre>

                            <div class="section-subtitle">5.2 Naive Bayes Multinomial</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                El modelo Multinomial Naive Bayes se utiliza, en este caso, con ajuste de
                                hiperpar√°metros mediante
                                b√∫squeda en cuadr√≠cula (GridSearchCV) para optimizar el par√°metro de suavizado alpha.
                                Este enfoque probabil√≠stico calcula probabilidades condicionales de palabras para cada
                                clase, permitiendo una clasificaci√≥n eficiente incluso con vocabularios grandes. La
                                b√∫squeda exhaustiva de alpha mediante validaci√≥n cruzada de 5 folds maximiza el F1-score
                                macro, encontrando el balance √≥ptimo entre sesgo y varianza del modelo.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Entrenamiento r√°pido y eficiente incluso con vocabularios grandes</li>
                                    <li>Optimizaci√≥n autom√°tica de hiperpar√°metros mediante GridSearchCV</li>
                                    <li>Probabilidades interpretables a nivel palabra-clase</li>
                                    <li>Rendimiento equilibrado en todas las clases con datos balanceados</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>
                            <div class="section-subtitle" style="border-left: none; padding-left: 0;">Configuraci√≥n:
                                GridSearchCV</div>
                            <pre class="code-block"><code>grid_search = GridSearchCV(
    estimator=MultinomialNB(),
    param_grid=param_grid,
    scoring='f1_macro',
    cv=5,
    n_jobs=-1,
    verbose=1
)</code></pre>

                            <div class="section-subtitle">5.3 DeBERTa‚Äëv3‚Äëbase (fine‚Äëtuning)</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                Los transformadores preentrenados como <strong>DeBERTa‚Äëv3‚Äëbase</strong> capturan
                                relaciones contextuales y sem√°ntica a nivel sub‚Äëpalabra mediante auto‚Äëatenci√≥n.
                                En este trabajo se realiz√≥ <em>fine‚Äëtuning</em> para el dataset Poem
                                Sentiment (excluyendo la clase <code>mixed</code>), optimizando la m√©trica
                                <strong>F1‚Äëmacro</strong> y usando t√©cnicas de regularizaci√≥n para manejar el
                                desbalance y evitar sobreajuste.
                            </p>
                            <div class="spec-card">
                                <strong>T√©cnicas aplicadas</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Tokenizaci√≥n subword (max_len=128)</li>
                                    <li>Focal Loss (Œ≥ = 1.5) + <em>class weights</em></li>
                                    <li><em>Label smoothing</em> = 0.1</li>
                                    <li><em>Early stopping</em> (patience = 3)</li>
                                    <li>Optimizaci√≥n con Hugging Face Trainer por F1‚Äëmacro</li>
                                </ul>
                            </div>

                            <div class="spec-card" style="margin-top: 15px;">
                                <strong>Ventajas</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Captura dependencias largas y matices po√©ticos</li>
                                    <li>Robusto ante variaciones l√©xicas y de estilo</li>
                                    <li>Rendimiento superior en dominios de texto fino</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>
                            <div class="section-subtitle" style="border-left: none; padding-left: 0;">Configuraci√≥n: TrainingArguments</div>
                            <pre class="code-block"><code>
TrainingArguments(
    output_dir=f"{config.OUTPUT_DIR}/fold_{fold}",
    logging_dir=f"{config.LOGGING_DIR}/fold_{fold}",
    num_train_epochs=config.NUM_EPOCHS,
    per_device_train_batch_size=config.BATCH_SIZE,
    per_device_eval_batch_size=config.BATCH_SIZE * 2,
    learning_rate=config.LEARNING_RATE,
    weight_decay=config.WEIGHT_DECAY,
    warmup_ratio=config.WARMUP_RATIO,
    lr_scheduler_type="cosine",
    save_strategy="epoch",
    evaluation_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="f1_macro",
    greater_is_better=True,
    save_total_limit=2,
    logging_steps=50,
    report_to="none"
)</code></pre>
                            <p style="text-align: justify; line-height: 1.8; margin-top: 15px;">
                                Los argumentos de entrenamiento configuran el proceso de fine-tuning de DeBERTa. Se utiliza un scheduler coseno con warmup del 5%, early stopping basado en F1-macro, y se guardan solo los 2 mejores checkpoints para optimizar memoria.
                            </p>

                            

                        </div>

                        <!-- PAGE 7: Metrics and Training -->
                        <div class="page-section">
                            <div class="section">
                                <div class="section-title">üìä 7. Validaci√≥n y M√©tricas</div>
                                <div class="section-subtitle">Carga del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    El dataset se obtuvo desde el repositorio de Hugging Face utilizando pandas. Los
                                    archivos est√°n disponibles en formato Parquet
                                    y se pueden cargar directamente usando la siguiente configuraci√≥n:
                                </p>

                                <div
                                    style="background: #f8f9fa; padding: 20px; border-radius: 4px; margin: 20px 0; overflow-x: auto;">
                                    <code
                                        style="background: #f0f0f0; padding: 15px; border-radius: 4px; font-family: 'Courier New', monospace; display: block;">
                                        import pandas as pd<br>
                                        <br>
                                        splits = {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'train': 'data/train-00000-of-00001.parquet',<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'validation': 'data/validation-00000-of-00001.parquet',<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'test': 'data/test-00000-of-00001.parquet'<br>
                                        }<br>
                                        <br>
                                        df = pd.read_parquet(<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;"hf://datasets/google-research-datasets/poem_sentiment/" + splits["train"]<br>
                                        )
                                    </code>
                                </div>

                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    <strong>URL del Dataset:</strong> <a
                                        href="https://huggingface.co/datasets/google-research-datasets/poem_sentiment/viewer"
                                        target="_blank"
                                        style="color: #C41E3A; text-decoration: none;">https://huggingface.co/datasets/google-research-datasets/poem_sentiment/viewer</a>
                                </p>

                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Este m√©todo permite cargar directamente los splits de entrenamiento, validaci√≥n y
                                    prueba en DataFrames de pandas,
                                    facilitando el preprocesamiento y manipulaci√≥n de los datos para el an√°lisis
                                    posterior.
                                </p>
                                <div class="section-subtitle">Divisi√≥n del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utiliz√≥ la divisi√≥n est√°ndar del dataset proporcionada por Hugging Face para
                                    garantizar coherencia
                                    y reproducibilidad de los resultados.
                                </p>

                                <div class="section-subtitle">M√©tricas de Evaluaci√≥n</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utilizaron las siguientes m√©tricas para evaluar el desempe√±o de los modelos:
                                </p>
                                <ul style="line-height: 2;">
                                    <li><strong>Accuracy:</strong> Proporci√≥n de predicciones correctas</li>
                                    <li><strong>Precision (macro avg):</strong> Promedio de precisi√≥n por clase</li>
                                    <li><strong>Recall (macro avg):</strong> Promedio de recall por clase</li>
                                    <li><strong>F1 (macro avg):</strong> Media arm√≥nica de precision y recall</li>
                                </ul>
                               

                            </div>

                            <!-- PAGE 8: Results -->
                            <div class="page-section">
                                <div class="section">
                                    <div class="section-title">üìà 8. Resultados</div>

                                    <div class="section-subtitle">Resultados de Baselines Cl√°sicos</div>

                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt;">
                                        <strong>Regresi√≥n Log√≠stica</strong> con class_weight='balanced'
                                    </p>
                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt;">
                                        Validaci√≥n: F1‚Äëmacro = 0.4310
                                    </p>
                                    
                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="margin-bottom: 10px;"><strong>Validaci√≥n - Classification Report:</strong></div>
                                        <div style="white-space: pre; text-align: left;">              precision    recall  f1-score   support

    negativo       0.50      0.21      0.30        19
    positivo       0.50      0.12      0.19        17
 sin_impacto       0.69      0.93      0.79        69

    accuracy                           0.67       105
   macro avg       0.56      0.42      0.43       105
weighted avg       0.62      0.67      0.60       105</div>
                                        
                                        <div style="margin-top: 15px; margin-bottom: 10px;"><strong>Test - Classification Report:</strong></div>
                                        <div style="white-space: pre; text-align: left;">              precision    recall  f1-score   support

    negative       0.44      0.21      0.29        19
    positive       0.75      0.19      0.30        16
   no_impact       0.71      0.94      0.81        69

    accuracy                           0.69       104
   macro avg       0.64      0.45      0.47       104
weighted avg       0.67      0.69      0.64       104</div>
                                    </div>
                                    <div style="height: 20px; clear: both;"></div>
                                    <div style="text-align: center; margin: 30px 0;">
                                        <img src="mc_rl.png" alt="Matriz de Confusi√≥n - Regresi√≥n Log√≠stica"
                                            style="max-width: 55%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                        <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                            Ilustraci√≥n. Matriz de Confusi√≥n - Regresi√≥n Log√≠stica</p>
                                    </div>
                                    <div style="height: 20px; clear: both;"></div>

                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt; margin-top: 30px;">
                                        <strong>Multinomial Naive Bayes</strong> optimizado con GridSearchCV
                                    </p>
                                    
                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt;">
                                        Test: F1‚Äëmacro = 0.5625
                                    </p>
                                    
                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="margin-bottom: 10px;"><strong>Test - Classification Report (Ajustado):</strong></div>
                                        <div style="white-space: pre; text-align: left;">              precision    recall  f1-score   support

    negativo       0.46      0.58      0.51        19
    positivo       0.50      0.31      0.38        16
 sin_impacto       0.79      0.80      0.79        69

    accuracy                           0.68       104
   macro avg       0.58      0.56      0.56       104
weighted avg       0.68      0.68      0.68       104</div>
                                    </div>

                                    <div style="text-align: center; margin: 30px 0;">
                                        <img src="nb_m.png" alt="Matriz de Confusi√≥n - Multinomial Naive Bayes Optimizado"
                                            style="max-width: 55%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                        <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                            Ilustraci√≥n. Matriz de Confusi√≥n - Multinomial Naive Bayes Optimizado</p>
                                    </div>

                                    

                                    <div class="section-subtitle">Resultados principales (DeBERTa‚Äëv3‚Äëbase)</div>

                                    <table class="format-table">
                                        <thead>
                                            <tr>
                                                <th>Conjunto</th>
                                                <th>Accuracy</th>
                                                <th>F1‚ÄëMacro</th>
                                                <th>F1‚ÄëWeighted</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <td><strong>Validaci√≥n</strong></td>
                                                <td>0.9143</td>
                                                <td><strong>0.8903</strong></td>
                                                <td>0.9132</td>
                                            </tr>
                                            <tr>
                                                <td><strong>Test</strong></td>
                                                <td>0.9135</td>
                                                <td><strong>0.8909</strong></td>
                                                <td>0.9136</td>
                                            </tr>
                                        </tbody>
                                    </table>



                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px; font-size: 11pt; margin-top: 20px; color: #444;">
                                        <strong>ANALIZANDO DESBALANCE Y CALCULANDO CLASS WEIGHTS...</strong>
                                    </p>
                                    
                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">Class weights (for Trainer): [1.8129033 2.112782  0.5063063]
  ‚Ä¢ Negative (0): 1.813
  ‚Ä¢ Positive (1): 2.113
  ‚Ä¢ No_impact (2): 0.506</div>
                                    </div>

                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px; font-size: 11pt; margin-top: 25px; color: #444;">
                                        <strong>Progresi√≥n de entrenamiento (6 √©pocas):</strong>
                                    </p>

                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 9pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">[318/318 06:05, Epoch 6/6]

Epoch	Training Loss	Validation Loss	Accuracy	F1 Macro	F1 Weighted
1	0.687600	0.627334	0.219048	0.219373	0.112739
2	0.415900	0.277040	0.695238	0.677715	0.704948
3	0.168000	0.238712	0.904762	0.879654	0.905809
4	0.057400	0.295952	0.885714	0.855089	0.889655
5	0.033500	0.272913	0.904762	0.878603	0.903656
6	0.014500	0.268912	0.914286	0.890276	0.913175</div>
                                    </div>

                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 25px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">RESULTADOS FINALES EN VALIDATION SET:
  Accuracy:    0.9143
  F1-Macro:    0.8903
  F1-Weighted: 0.9132

RESULTADOS FINALES EN TEST SET:
  Accuracy:    0.9135
  F1-Macro:    0.8909
  F1-Weighted: 0.9136</div>
                                    </div>


                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt; margin-top: 25px; color: #444;">
                                        <strong>Reporte detallado de clasificaci√≥n (Test Set):</strong>
                                    </p>

                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">CLASSIFICATION REPORT (Test Set):
              precision    recall  f1-score   support

    negative       0.86      1.00      0.93        19
    positive       0.81      0.81      0.81        16
   no_impact       0.95      0.91      0.93        69

    accuracy                           0.91       104
   macro avg       0.88      0.91      0.89       104
weighted avg       0.92      0.91      0.91       104</div>
                                    </div>

                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 25px 0; font-size: 10pt; line-height: 1.8; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">FINE-TUNING DEBERTA-V3-BASE COMPLETADO:

 T√âCNICAS APLICADAS:
   ‚Ä¢ Modelo: DeBERTa-v3-base (Fine-tuned)
   ‚Ä¢ Preprocesamiento: Eliminaci√≥n duplicados, normalizaci√≥n comillas/guiones, 
     exclusi√≥n clase 'mixed'
   ‚Ä¢ Tokenizaci√≥n: max_len=128
   ‚Ä¢ P√©rdida: Focal Loss (Œ≥=1.5) con class weights
   ‚Ä¢ Regularizaci√≥n: Label smoothing 0.1
   ‚Ä¢ Entrenamiento: Hugging Face Trainer, optimizado por F1-macro
   ‚Ä¢ Validaci√≥n: Early stopping (patience=3)</div>
                                    </div>

                                    <div style="text-align: center; margin: 30px 0;">
                                        <img src="deberta.png" alt="Matriz de Confusi√≥n - DeBERTa-v3-base"
                                            style="max-width: 60%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                        <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                            Ilustraci√≥n. Matriz de Confusi√≥n - DeBERTa-v3-base (Conjunto de Test)</p>
                                    </div>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #e8f5e9 0%, #ffffff 100%); border-left-color: #2e7d32; margin-top: 30px;">
                                        <strong>Objetivo cumplido (ALCANZADO):</strong> Se alcanz√≥ <strong>F1‚Äëmacro = 0.8909</strong> en el conjunto de Test, 
                                        superando la meta de <strong>F1‚Äëmacro ‚â• 0.85</strong>. DeBERTa‚Äëv3‚Äëbase demostr√≥ ser significativamente superior 
                                        a los baselines cl√°sicos (Regresi√≥n Log√≠stica: 0.4661 | Multinomial NB optimizado: 0.5625), justificando 
                                        el uso de transformadores para la tarea de an√°lisis de sentimiento en poes√≠a.
                                    </div>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; margin-top: 30px;">
                                        <strong>Comparativa con baselines cl√°sicos:</strong> Los enfoques con
                                        CountVectorizer (MultinomialNB / Regresi√≥n Log√≠stica)
                                        se usaron como l√≠neas base s√≥lidas, pero <em>no alcanzaron</em> el desempe√±o del
                                        transformador en F1‚Äëmacro. La elecci√≥n de
                                        DeBERTa se justifica por su capacidad para capturar matices sem√°nticos y de
                                        estilo propios de la poes√≠a.
                                    </div>
                                </div>

                                <!-- PAGE 9: Discussion -->
                                <div class="page-section">
                                    <div class="section">
                                        <div class="section-title">üí° 9. Discusi√≥n</div>

                                        <div class="section-subtitle">¬øQu√© se observa en los resultados?</div>
                                        <ul style="line-height: 2;">
                                            <li><strong>DeBERTa‚Äëv3‚Äëbase</strong> alcanza F1‚Äëmacro ‚âà 0.891 en Test,
                                                superando ampliamente a los baselines cl√°sicos.</li>
                                            <li>Por clase (Test): <em>negative</em> logra <strong>recall ‚âà 1.00</strong>
                                                (marcadores expl√≠citos); <em>positive</em> es desafiante (F1 ‚âà 0.81) porque el 
                                                sentimiento positivo en poes√≠a es sutil y metaf√≥rico, frecuentemente confundido con 
                                                <code>no_impact</code> cuando el poeta describe la belleza sin expresar expl√≠citamente 
                                                alegr√≠a. Ejemplo: un verso como <em>"The golden light upon the hills"</em> expresa belleza 
                                                (sentimiento positivo), pero el modelo puede clasificarlo como neutro por la ausencia de 
                                                palabras emocionales directas; <em>no_impact</em> es f√°cil de detectar (precisi√≥n ‚âà 0.95, recall ‚âà 0.91).
                                            </li>
                                            <li>La combinaci√≥n de <em>class weights</em> + Focal Loss + label smoothing
                                                favorece el balance entre clases bajo desbalance.</li>
                                        </ul>

                                        <div class="section-subtitle">¬øFue exitoso el entrenamiento?</div>
                                        <p style="text-align: justify; line-height: 1.8;">
                                            S√≠. La m√©trica objetivo (<strong>F1‚Äëmacro ‚â• 0.85</strong>) se cumpli√≥ con
                                            margen. Las curvas por √©poca
                                            (con early stopping) y el uso de regularizaci√≥n indican un proceso estable y
                                            reproducible.
                                        </p>

                                        <div class="section-subtitle">Escenarios de uso</div>
                                        <ul style="line-height: 2;">
                                            <li>Anal√≠tica de colecciones po√©ticas (tendencias afectivas por
                                                autor/√©poca).</li>
                                            <li>Herramientas de apoyo editorial, talleres de escritura y an√°lisis
                                                literario asistido.</li>
                                            
                                        </ul>

                                        <div class="section-subtitle">Limitaciones y mejoras</div>
                                        <ul style="line-height: 2;">
                                            <li><strong>Clase positive:</strong> a√∫n mejorable con
                                                <em>augmentations</em> suaves o calibraci√≥n de umbrales.
                                            </li>
                                            <li><strong>Generalizaci√≥n:</strong> ampliar datos o realizar
                                                <em>fine‚Äëtuning</em> por dominio/autor:
                                                <ul style="margin-top: 10px; margin-left: 20px; line-height: 1.8;">
                                                    <li><strong>Por dominio:</strong> Poes√≠a medieval vs. moderna vs. rom√°ntica (cada estilo tiene caracter√≠sticas diferentes). Un modelo entrenado espec√≠ficamente en poes√≠a rom√°ntica (con √©nfasis en descripciones l√≠ricas de la naturaleza y emociones) podr√≠a capturar mejor los matices del sentimiento positivo en ese contexto, comparado con un modelo general entrenado en m√∫ltiples √©pocas simult√°neamente.</li>
                                                    <li><strong>Por autor:</strong> Ajustar el modelo espec√≠ficamente para William Shakespeare, Emily Dickinson, etc. (cada poeta tiene su propio estilo y forma de expresar sentimientos). Shakespeare tiende a usar lenguaje elaborado y formal; Dickinson emplea puntuaci√≥n experimental y abstracciones. Un modelo fine-tuned por autor ser√≠a m√°s preciso en detectar sentimientos bajo el estilo espec√≠fico de ese poeta.</li>
                                                </ul>
                                            </li>
                                            <li><strong>Clase mixta (<code>mixed</code>):</strong> reincorporarla demandar√°
                                                redise√±ar p√©rdidas/umbral o recolectar m√°s muestras.</li>
                                            <li><strong>Recursos:</strong> modelos mayores (DeBERTa‚Äëlarge,
                                                RoBERTa‚Äëlarge) y <em>ensembles</em> podr√≠an subir el techo de desempe√±o
                                                con mayor costo computacional.</li>
                                        </ul>
                                    </div>

                                    <!-- PAGE 10: Conclusions -->
                                    <div class="page-section">
                                        <div class="section">
                                            <div class="section-title">üéØ 10. Conclusiones y Trabajo Futuro</div>

                                            <div class="section-subtitle">Conclusiones</div>
                                            <ul style="line-height: 2;">
                                                <li><strong>Objetivo cumplido:</strong> se alcanz√≥ F1‚Äëmacro ‚â• 0.85 con
                                                    DeBERTa‚Äëv3‚Äëbase (F1‚Äëmacro Test ‚âà 0.8909).</li>
                                                <li>La <strong>elecci√≥n de preprocesamiento</strong> diferenciado fue
                                                    clave: limpieza ligera para el transformador y normalizaci√≥n l√©xica
                                                    + CountVectorizer para baselines.</li>
                                                <li>Los <strong>baselines cl√°sicos</strong> sirvieron como referencia y
                                                    an√°lisis de sensibilidad, pero el transformador entendi√≥ mejor los
                                                    detalles y sutilezas del lenguaje po√©tico.</li>
                                                <li><strong>Impacto profesional:</strong> este proyecto consolida el
                                                    manejo de pipelines de NLP modernos (Transformers) y comparativos
                                                    cl√°sicos, √∫til para prototipado r√°pido y despliegue en anal√≠tica
                                                    textual.</li>
                                            </ul>

                                            <div class="section-subtitle">Trabajo futuro</div>
                                            <ul style="line-height: 2;">
                                                <li>Explorar modelos mayores
                                                    (DeBERTa‚Äëlarge, RoBERTa).</li>
                                                <li>Mejorar la clase <em>positive</em> con <em>augmentations</em> suaves
                                                    y calibraci√≥n de umbrales.</li>
                                                <li>Reincorporar la clase <code>mixed</code> con estrategias de p√©rdida
                                                    (p. ej., <em>asymmetric loss</em>) o m√°s datos.</li>
                                                <li>Preparar un demo de inferencia (FastAPI) en
                                                    producci√≥n.</li>
                                            </ul>
                                        </div>

                                        <!-- PAGE 11: References & Footer -->
                                        <div class="page-section">
                                            <div class="section">
                                                <div class="section-title">üìö 11. Referencias Bibliogr√°ficas</div>

                                                <div
                                                    style="background: #f8f9fa; padding: 25px; border-radius: 8px; line-height: 2;">
                                                    <p>Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011).
                                                        <em>Scikit-learn: Machine Learning in Python</em>.
                                                        Journal of Machine Learning Research, 12, 2825-2830.
                                                    </p>



                                                    <p>Google Research. (s.f.). <em>Poem sentiment</em> [Conjunto de
                                                        datos]. Hugging Face.
                                                        Disponible en:
                                                        https://huggingface.co/datasets/google-research-datasets/poem_sentiment
                                                    </p>

                                                    <p>Goodfellow, I., Bengio, Y., & Courville, A. (2016). <em>Deep
                                                            Learning</em>.
                                                        MIT Press. [Referencia para arquitecturas de redes neuronales]
                                                    </p>

                                                    <p>Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT:
                                                        Pre-training of Deep Bidirectional Transformers
                                                        for Language Understanding. arXiv preprint arXiv:1810.04805.</p>
                                                </div>
                                            </div>

                                            

                                            <div class="page-number"></div>
                                        </div>
                                    </div>
                                </div>
</body>

</html>