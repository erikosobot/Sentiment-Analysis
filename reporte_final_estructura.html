<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte Final - Curso de Inteligencia Artificial</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        p {
            text-align: justify;
            line-height: 1.5;
            font-size: 12pt;
        }

        body {
            font-family: Arial, sans-serif;
            font-size: 12pt;
            line-height: 1.5;
            color: #333;
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
            overflow: hidden;
            padding: 2.5cm;
        }

        /* Header */
        .header {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.95;
        }

        .header-logo {
            margin-bottom: 20px;
            font-size: 3em;
        }

        /* Main Content */
        .content {
            padding: 0;
            text-align: justify;
        }

        .section {
            margin-bottom: 50px;
            page-break-inside: avoid;
            page-break-after: auto;
        }

        .section-title {
            font-size: 14pt;
            color: #000;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #C41E3A;
            font-weight: bold;
            page-break-after: avoid;
        }

        .section-subtitle {
            font-size: 12pt;
            color: #000;
            margin-top: 30px;
            margin-bottom: 15px;
            font-weight: bold;
            font-style: italic;
            padding-left: 20px;
            border-left: 4px solid #C41E3A;
        }

        .intro-text {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-left: 5px solid #C41E3A;
            margin-bottom: 30px;
            line-height: 1.5;
            font-size: 12pt;
            text-align: justify;
        }

        /* Specifications */
        .specifications {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .spec-card {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #C41E3A;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .spec-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(196, 30, 58, 0.2);
        }

        .spec-card strong {
            color: #000;
            display: block;
            margin-bottom: 8px;
        }

        /* Lists */
        ul,
        ol {
            margin-left: 30px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 12px;
            line-height: 1.5;
            text-align: justify;
        }

        li strong {
            color: #4A4A4A;
        }

        /* Structure sections */
        .structure-list {
            background: #f8f9fa;
            padding: 30px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .structure-item {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 1px solid #e0e0e0;
        }

        .structure-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .structure-item h4 {
            color: #000;
            font-size: 1.15em;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
        }

        .structure-item h4:before {
            content: "‚ñ∏";
            margin-right: 10px;
            font-size: 1.3em;
            color: #4A4A4A;
        }

        .structure-description {
            margin-left: 20px;
            color: #666;
            line-height: 1.8;
        }

        /* Rubric */
        .rubric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .rubric-item {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 25px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(139, 21, 56, 0.2);
        }

        .rubric-percentage {
            font-size: 2.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .rubric-description {
            font-size: 0.95em;
            opacity: 0.95;
        }

        /* Deliverables */
        .deliverables {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 30px;
            border-radius: 8px;
            border: 2px solid #C41E3A;
        }

        .deliverable-item {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
            font-size: 1.05em;
        }

        .deliverable-item:last-child {
            margin-bottom: 0;
        }

        .deliverable-icon {
            width: 30px;
            height: 30px;
            background: #C41E3A;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 15px;
            font-weight: bold;
            flex-shrink: 0;
        }

        /* Format Table */
        .format-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            overflow: hidden;
        }

        .format-table th {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }

        .format-table td {
            padding: 15px;
            border-bottom: 1px solid #e0e0e0;
        }

        .format-table tr:hover {
            background: #f8f9fa;
        }

        .format-table tr:last-child td {
            border-bottom: none;
        }

        /* Footer */
        .footer {
            background: #f8f9fa;
            padding: 30px 40px;
            text-align: center;
            color: #666;
            border-top: 1px solid #e0e0e0;
        }

        .footer p {
            margin-bottom: 10px;
        }

        .footer-highlight {
            color: #4A4A4A;
            font-weight: bold;
        }

        /* Highlight boxes */
        .highlight-box {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            border-left: 4px solid #C41E3A;
            padding: 15px 20px;
            border-radius: 4px;
            margin: 20px 0;
            color: #000;
        }

        .highlight-box strong {
            color: #000;
        }

        /* Responsiveness */
        @media (max-width: 768px) {
            .header {
                padding: 40px 20px;
            }

            .header h1 {
                font-size: 1.8em;
            }

            .content {
                padding: 30px 20px;
                text-align: justify;
            }

            .section-title {
                font-size: 1.6em;
            }

            .specifications,
            .rubric-grid {
                grid-template-columns: 1fr;
            }

            .structure-item h4 {
                font-size: 1.05em;
            }

            .format-table {
                font-size: 0.9em;
            }

            .format-table th,
            .format-table td {
                padding: 10px;
            }

            p,
            li,
            td {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }
        }

        /* Animation */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .section {
            animation: fadeIn 0.6s ease-out;
        }

        .spec-card {
            animation: fadeIn 0.6s ease-out;
        }

        /* Print styles */
        @media print {
            body {
                background: white;
                padding: 2.5cm;
                margin: 0;
                font-size: 12pt;
                line-height: 1.5;
                counter-reset: page 1;
            }

            .container {
                box-shadow: none;
                border-radius: 0;
                padding: 0;
                max-width: 100%;
                margin: 0;
            }

            .header {
                page-break-after: avoid;
                padding: 30px 0;
            }

            .content {
                padding: 0;
                text-align: justify;
            }

            p,
            li,
            td,
            th {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }

            .section {
                page-break-inside: avoid;
            }

            @page {
                margin: 2.5cm;

                @bottom-center {
                    content: counter(page);
                    font-size: 12pt;
                    font-family: Arial, sans-serif;
                }
            }
        }

        /* Code styles */
        code {
            background: #f0f0f0;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d63384;
        }

        /* COVER PAGE STYLES */
        .cover-page {
            display: flex;
            align-items: flex-start;
            justify-content: center;
            min-height: 100vh;
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            color: #000;
            text-align: center;
            padding: 60px 60px 80px 60px;
            page-break-after: always;
            position: relative;
        }

        .cover-page::before {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #C41E3A, rgba(196, 30, 58, 0) 50%, rgba(196, 30, 58, 0));
        }

        .cover-page::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 2px;
            background: linear-gradient(90deg, rgba(196, 30, 58, 0), #C41E3A 50%, rgba(196, 30, 58, 0));
        }

        .cover-content {
            max-width: 600px;
            animation: fadeInCover 0.8s ease;
        }

        @keyframes fadeInCover {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .cover-logos {
            display: flex;
            justify-content: space-between;
            gap: 0;
            margin-bottom: 50px;
            align-items: center;
            width: 100%;
            max-width: none;
            margin-left: 0;
            margin-right: 0;
        }

        .cover-logo {
            flex: 0 0 auto;
            background: rgba(139, 21, 56, 0.05);
            padding: 15px;
            border-radius: 8px;
            border: 1px solid rgba(139, 21, 56, 0.2);
            backdrop-filter: blur(10px);
        }

        .cover-logo img {
            max-width: 100px;
            height: auto;
            filter: brightness(1);
            transition: transform 0.3s ease;
        }

        .cover-logo img:hover {
            transform: scale(1.05);
        }

        .cover-institution {
            margin-bottom: 60px;
            border-bottom: 2px solid #C41E3A;
            padding-bottom: 25px;
            letter-spacing: 0.5px;
        }

        .cover-institution h2 {
            font-size: 2em;
            margin-bottom: 8px;
            font-weight: 700;
            letter-spacing: 0.3px;
            line-height: 1.2;
            color: #000;
        }

        .cover-institution p {
            font-size: 1.15em;
            opacity: 1;
            font-weight: 500;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-course {
            margin-bottom: 90px;
            font-size: 1.25em;
            font-style: italic;
            opacity: 1;
            font-weight: 400;
            letter-spacing: 0.3px;
            color: #000;
        }

        .cover-main {
            margin-bottom: 100px;
        }

        .cover-main h1 {
            font-size: 3.5em;
            margin-bottom: 20px;
            font-weight: 800;
            text-shadow: none;
            line-height: 1.1;
            letter-spacing: -0.5px;
            color: #000;
        }

        .cover-subtitle {
            font-size: 1.4em;
            opacity: 1;
            font-style: italic;
            line-height: 1.5;
            font-weight: 300;
            color: #000;
        }

        .cover-author {
            margin-bottom: 70px;
            font-size: 1.1em;
        }

        .cover-author p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-author p:last-child {
            font-size: 1.4em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-date {
            font-size: 1.1em;
            margin-top: 80px;
            padding-top: 30px;
            border-top: 1px solid #C41E3A;
        }

        .cover-date p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-date p:last-child {
            font-size: 1.3em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        /* Print styles for cover */
        @media print {
            .cover-page {
                page-break-after: always;
                background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
                color: white;
            }
        }

        code-block {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            display: block;
            overflow-x: auto;
        }

        /* Footer con numeraci√≥n de p√°gina */
        .page-number {
            text-align: center;
            padding: 20px 0;
            color: #999;
            font-size: 11pt;
            border-top: 1px solid #ddd;
            margin-top: 40px;
        }

        @media print {
            .page-number {
                display: none;
            }
        }

        /* Download Button */
        .download-container {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
        }

        .download-btn {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: bold;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(139, 21, 56, 0.3);
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .download-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(139, 21, 56, 0.4);
        }

        .download-btn:active {
            transform: translateY(0);
        }

        @media print {
            .download-container {
                display: none;
            }
        }

        /* Page Break Control */
        .page-section {
            page-break-after: always;
            page-break-inside: avoid;
            padding: 20px 0;
            margin-bottom: 1cm;
        }

        .page-section:last-child {
            page-break-after: avoid;
        }

        .section-page-break {
            page-break-after: always;
        }

        /* Evitar rupturas dentro de elementos */
        .page-section .section {
            page-break-inside: avoid;
        }

        .section-subtitle {
            page-break-after: avoid;
        }

        .section-title {
            page-break-after: avoid;
        }

        ul,
        ol {
            page-break-inside: avoid;
        }

        .format-table {
            page-break-inside: avoid;
        }

        .spec-card {
            page-break-inside: avoid;
        }

        .highlight-box {
            page-break-inside: avoid;
        }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script src="https://unpkg.com/docx@8.12.6/build/index.js"></script>
    <script>
        // Script para numeraci√≥n de p√°ginas
        window.addEventListener('load', function () {
            // En navegador, agregar numeraci√≥n visible
            const pageNumbers = document.querySelectorAll('.page-number');
            if (pageNumbers.length > 0) {
                let pageCount = 1;
                pageNumbers.forEach((element, index) => {
                    element.textContent = 'P√°gina ' + (index + 1);
                });
            }
        });

        // Funci√≥n para descargar como Word
        function downloadAsWord() {
            try {
                const container = document.querySelector('.container');
                if (!container) {
                    alert('No se encontr√≥ el contenido para exportar');
                    return;
                }

                // Obtener el HTML completo
                const html = container.innerHTML;

                // Crear documento Word en formato OOXML
                const docContent = `<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<?mso-application progid="Word.Document"?>
<html xmlns:v="urn:schemas-microsoft-com:vml"
 xmlns:o="urn:schemas-microsoft-com:office:office"
 xmlns:w="urn:schemas-microsoft-com:office:word"
 xmlns:x="urn:schemas-microsoft-com:office:excel"
 xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
 xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 16">
<meta name=Originator content="Microsoft Word 16">
<link rel=File-List href="filelist.xml">
<title>Reporte Final - An√°lisis de sentimientos en versos</title>
<o:DocumentProperties>
 <o:Author>Erik I. Osornio Botello</o:Author>
 <o:LastAuthor>Erik I. Osornio Botello</o:LastAuthor>
 <o:Created>2025-10-16T00:00:00Z</o:Created>
 <o:LastSaved>2025-10-16T00:00:00Z</o:LastSaved>
 <o:Pages>1</o:Pages>
 <o:Words>1</o:Words>
 <o:Characters>1</o:Characters>
 <o:Lines>1</o:Lines>
 <o:Paragraphs>1</o:Paragraphs>
 <o:CharactersWithSpaces>1</o:CharactersWithSpaces>
 <o:Version>16.00</o:Version>
</o:DocumentProperties>
</head>
<body>
${html}
</body>
</html>`;

                // Crear Blob
                const blob = new Blob([docContent], { type: 'application/vnd.ms-word' });

                // Descargar
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;
                link.download = 'Reporte_Analisis_Sentimientos.doc';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);

                alert('‚úì Descargado: Reporte_Analisis_Sentimientos.doc');
            } catch (error) {
                console.error('Error:', error);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }

        // Funci√≥n alternativa: descargar como PDF
        function downloadAsPDF() {
            try {
                const element = document.querySelector('.container');
                const cloned = element.cloneNode(true);
                cloned.querySelectorAll('.download-container, .page-number, .header').forEach(el => el.remove());

                const opt = {
                    margin: 10,
                    filename: 'Reporte_Analisis_Sentimientos.pdf',
                    image: { type: 'jpeg', quality: 0.98 },
                    html2canvas: { scale: 2 },
                    jsPDF: { orientation: 'portrait', unit: 'mm', format: 'a4' }
                };

                html2pdf().set(opt).from(cloned).save();
                alert('Descargando como PDF...');
            } catch (err) {
                console.error('Error al descargar:', err);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }
    </script>
</head>

<body>
    <div class="container">
        <!-- COVER PAGE -->
        <div class="cover-page">
            <div class="cover-content">
                <div class="cover-logos">
                    <div class="cover-logo">
                        <img src="logo_cic.jpg" alt="Logo CIC - Centro de Investigaci√≥n en Computaci√≥n">
                    </div>
                    <div class="cover-logo">
                        <img src="logo_ipn.jpg" alt="Logo IPN - Instituto Polit√©cnico Nacional">
                    </div>
                </div>
                <div class="cover-institution">
                    <h2>Centro de Investigaci√≥n en Computaci√≥n</h2>
                </div>

                <div class="cover-course">
                    <p>Diplomado en Inteligencia Artificial</p>
                </div>

                <div class="cover-main">
                    <h1>An√°lisis de sentimientos en versos</h1>
                    <p class="cover-subtitle">Implementaci√≥n y Evaluaci√≥n de Tres Enfoques de Clasificaci√≥n</p>
                </div>

                <div class="cover-author">
                    <p><strong>Autor:</strong></p>
                    <p>Erik I. Osornio Botello</p>
                </div>

                <div class="cover-date">
                    <p><strong>Fecha de Entrega:</strong></p>
                    <p>16 de Octubre de 2025</p>
                </div>
            </div>
        </div>

        <!-- TABLE OF CONTENTS -->
        <div style="page-break-after: always; padding: 40px 0;">
            <h2 style="font-size: 1.8em; color: #000; margin-bottom: 30px; text-align: center; font-weight: bold;">
                √çndice</h2>
            <ol style="font-size: 12pt; line-height: 2; margin-left: 30px; color: #333;">
                <li>Introducci√≥n</li>
                <li>Datos</li>
                <li>Preprocesamiento</li>
                <li>Representaci√≥n de texto</li>
                <li>Modelos implementados
                    <ol style="margin-top: 10px; margin-left: 20px;">
                        <li>Regresi√≥n Log√≠stica</li>
                        <li>Naive Bayes Multinomial</li>
                        <li>LSTM</li>
                    </ol>
                </li>
                <li>Entrenamiento y validaci√≥n</li>
                <li>M√©tricas y evaluaci√≥n</li>
                <li>Resultados</li>
                <li>Discusi√≥n</li>
                <li>Conclusiones y trabajo futuro</li>
                <li>Referencias</li>
            </ol>
        </div>

        <div class="download-container">
            <button class="download-btn" onclick="downloadAsWord()">üì• Descargar Word</button>
        </div>

        <!-- Main Content -->
        <div class="content">
            <!-- PAGE 1: Title and Author -->
            <div class="page-section">
                <div class="section" style="text-align: center; margin-bottom: 60px;">
                    <h2 style="font-size: 2.2em; color: #000; margin-bottom: 10px;">An√°lisis de sentimientos en versos
                    </h2>
                    <p style="font-size: 1.2em; color: #000; margin-bottom: 30px;"><strong>Autor:</strong> Erik I.
                        Osornio Botello</p>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; max-width: 800px; margin: 0 auto;">
                        <h3 style="color: #000; margin-bottom: 15px;">Resumen</h3>
                        <p style="text-align: justify; line-height: 1.8; color: #333;">
                            Este documento describe el desarrollo, implementaci√≥n y evaluaci√≥n de un sistema de an√°lisis
                            de sentimientos
                            sobre un corpus en espa√±ol. Se comparan tres enfoques principales: <strong>Regresi√≥n
                                Log√≠stica</strong> (con CountVectorizer),
                            <strong>Naive Bayes Multinomial</strong> (con CountVectorizer) y una red neuronal
                            <strong>LSTM</strong> (trabajando sobre secuencias tokenizadas).
                            El objetivo es describir el flujo completo: exploraci√≥n y limpieza de datos, extracci√≥n de
                            caracter√≠sticas, entrenamiento,
                            validaci√≥n, evaluaci√≥n cuantitativa y an√°lisis cr√≠tico de resultados.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 2: Introduction Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìã 1. Introducci√≥n</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        El an√°lisis de sentimientos busca asignar una polaridad (por ejemplo: positiva, negativa,
                        neutral) a textos.
                        En este proyecto se implementan tres enfoques que representan paradigmas distintos: modelos
                        lineales probabil√≠sticos
                        (Regresi√≥n Log√≠stica), modelos de probabilidades condicionales con suposiciones de independencia
                        (Naive Bayes Multinomial)
                        y modelos secuenciales basados en redes neuronales (LSTM). Se discute su preparaci√≥n,
                        rendimiento y trade-offs.
                    </p>

                    <div class="section-subtitle">Objetivos</div>
                    <ul style="line-height: 2;">
                        <li>Construir y comparar tres modelos de an√°lisis de sentimientos.</li>
                        <li>Evaluar rendimiento con m√©tricas est√°ndar (accuracy, precision, recall, F1, AUC cuando
                            aplique).</li>
                        <li>Documentar decisiones de dise√±o y par√°metros.</li>
                    </ul>

                    <div class="section-subtitle">Marco de Referencia</div>
                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <p style="margin-bottom: 12px;">
                            <strong>üìã Indicaciones del Proyecto:</strong> Este proyecto se fundamenta en las
                            indicaciones
                            especificadas en el documento <em>Indicaciones Proyecto Poemas.pdf</em>, el cual establece
                            que:
                        </p>
                        <p
                            style="margin-bottom: 12px; padding-left: 15px; border-left: 3px solid #C41E3A; margin-left: 0;">
                            <strong>"Este proyecto es un ejercicio de aprendizaje supervisado. La idea general consiste
                                en
                                implementar tres clasificadores de texto para el problema de an√°lisis de sentimientos en
                                versos de poemas."</strong>
                        </p>
                        <p>
                            <strong>Clases del Problema:</strong> El marco original define tres categor√≠as de
                            sentimiento (positivo, negativo
                            o neutral), aunque en la pr√°ctica el dataset utilizado incluye cuatro clases: Positivo,
                            Negativo, Mixto y No impacto.
                            La estructura de tres clasificadores y el enfoque de aprendizaje supervisado se mantienen
                            como eje central de
                            la implementaci√≥n.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 3: Data Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìä 2. Datos</div>

                    <div class="section-subtitle">Descripci√≥n del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        <strong>Fuente:</strong> Para este proyecto se utiliz√≥ el dataset <em>Poem Sentiment</em> del
                        repositorio de Google Research,
                        disponible en Hugging Face (hf://datasets/google-research-datasets/poem_sentiment). Este
                        conjunto de datos consiste en versos
                        de poemas extra√≠dos de Project Gutenberg, etiquetados seg√∫n el sentimiento que transmiten.
                    </p>

                    <div class="spec-card">
                        <strong>üìà Caracter√≠sticas principales:</strong>
                        <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                            <li><strong>N√∫mero total de ejemplos:</strong> 1,101 versos</li>
                            <li><strong>Idioma:</strong> Textos en ingl√©s</li>
                            <li><strong>Tama√±o:</strong> Dataset peque√±o, lo que puede afectar la generalizaci√≥n de
                                modelos complejos como LSTM</li>
                            <li><strong>Data Augmentation:</strong> Debido al desbalance inicial de clases, se aplic√≥
                                data augmentation √∫nicamente en el conjunto de entrenamiento para equilibrar la
                                distribuci√≥n de clases.</li>
                        </ul>
                    </div>

                    <div class="section-subtitle">Clases de Sentimiento</div>
                    <ul style="line-height: 2;">
                        <li><strong>Positivo:</strong> Versos con emociones positivas</li>
                        <li><strong>Negativo:</strong> Versos con emociones negativas</li>
                        <li><strong>Mixto:</strong> Versos que combinan emociones positivas y negativas</li>
                        <li><strong>No impacto:</strong> Versos que no presentan un sentimiento claro</li>
                    </ul>

                    <div class="section-subtitle">Columnas del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        Este conjunto de datos consta de versos de poemas extra√≠dos de Project Gutenberg, etiquetados
                        seg√∫n el sentimiento que transmiten.
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>verse_text:</strong> Contiene el texto del verso del poema</li>
                        <li><strong>label:</strong> Indica la categor√≠a de sentimiento del verso</li>
                    </ul>

                    <div class="section-subtitle">Exploraci√≥n Inicial</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        En la fase de exploraci√≥n, no se encontraron valores nulos. El histograma de las longitudes por
                        clase se encuentra representado en la Ilustraci√≥n 2.
                    </p>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="verse_lengths_distribution.png"
                            alt="Gr√°fico de Distribuci√≥n de Longitudes de Versos por Clase"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Ilustraci√≥n 1. Distribuci√≥n de longitudes por clase</p>
                    </div>

                    <p style="text-align: justify; line-height: 1.5; margin-top: 20px;">
                        La figura muestra la distribuci√≥n de la longitud de los versos seg√∫n su sentimiento. Se observa
                        que la mayor√≠a de los versos tienen entre 30 y 50 palabras,
                        con predominancia de la clase no impact. Las clases minoritarias (mixed, positivo, negativo)
                        est√°n menos representadas, lo que refuerza el desbalance del dataset.
                        Esta distribuci√≥n sugiere que los modelos podr√≠an aprender primero la clase mayoritaria y que
                        los ejemplos muy largos son poco frecuentes y podr√≠an considerarse outliers.
                    </p>

                    <div class="section-subtitle">Divisi√≥n de Datos</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Conjunto</th>
                                <th>N√∫mero de Ejemplos</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Entrenamiento</strong></td>
                                <td>892 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Validaci√≥n</strong></td>
                                <td>105 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Test</strong></td>
                                <td>104 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Total</strong></td>
                                <td>1,101 ejemplos</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="section-subtitle">Distribuci√≥n de Clases (Entrenamiento Original)</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                                <th>Porcentaje</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>555</td>
                                <td>62.2%</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>155</td>
                                <td>17.4%</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>133</td>
                                <td>14.9%</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>49</td>
                                <td>5.5%</td>
                            </tr>
                        </tbody>
                    </table>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="sentiment_distribution.png"
                            alt="Gr√°fico de Distribuci√≥n de Clases en Datos de Entrenamiento"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Figura 1: Distribuci√≥n de Sentimientos en los Datos de Entrenamiento Original</p>
                    </div>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <strong>‚ö†Ô∏è Problema de Desbalance:</strong> La mayor√≠a de los versos pertenecen a la clase "No
                        impacto",
                        mientras que la clase "Mixto" tiene muy pocos ejemplos. Este desbalance puede generar:
                        <ul style="margin-left: 20px; margin-top: 10px; margin-bottom: 10px; line-height: 1.8;">
                            <li><strong>Bias hacia la clase mayoritaria:</strong> Los modelos tienden a predecir con
                                mayor frecuencia la clase predominante (No impacto), lo que puede inflar el accuracy
                                aparente, pero reducir la capacidad de identificar correctamente las clases
                                minoritarias.</li>
                            <li><strong>Problemas de generalizaci√≥n en LSTM y modelos complejos:</strong> Las redes
                                neuronales pueden sobreajustar f√°cilmente a la clase mayoritaria, especialmente cuando
                                el dataset es peque√±o. En este caso, modelos como LSTM pueden aprender patrones sesgados
                                en lugar de representaciones robustas de todas las clases.</li>
                            <li><strong>M√©tricas poco confiables para clases minoritarias:</strong> Las m√©tricas de
                                rendimiento pueden ser enga√±osas si se interpretan sin considerar el desbalance.</li>
                        </ul>
                        <p style="margin-top: 12px; text-align: justify; line-height: 1.6; font-size: 11pt;">
                            Dado el tama√±o reducido y el desbalance, estos conjuntos pueden no ser representativos de la
                            distribuci√≥n real de clases.
                            Esto significa que las m√©tricas de evaluaci√≥n (accuracy, F1, recall, precision) pueden ser
                            ruidosas y poco confiables,
                            especialmente para las clases minoritarias como Mixto y Positivo.
                        </p>
                    </div>

                    <div class="section-subtitle">Estrategias de Mitigaci√≥n</div>
                    <ul style="line-height: 2;">
                        <li><strong>Data Augmentation:</strong> Aplicada solo en el entrenamiento para balancear las
                            clases</li>
                        <li><strong>Class weights:</strong> Pesos por clase en LSTM para penalizar predicciones
                            incorrectas de clases minoritarias</li>
                    </ul>

                    <div class="section-subtitle">Distribuci√≥n de Clases (Post Data Augmentation)</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>2,775</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>2,325</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>1,995</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>735</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <!-- PAGE 4: Preprocesamiento -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">üìù 3. Preprocesamiento</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        El texto se someti√≥ a un pipeline de preprocesamiento con dos funciones principales:
                        <code>clean_text</code> y <code>preprocess_text</code>.
                    </p>

                    <div class="section-subtitle">Limpieza de Texto (clean_text)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Esta funci√≥n realiza operaciones de limpieza b√°sica para normalizar los datos textuales:
                    </p>
                    <ul style="line-height: 2;">
                        <li>Conversi√≥n a min√∫sculas para uniformidad</li>
                        <li>Eliminaci√≥n de URLs y etiquetas HTML</li>
                        <li>Remoci√≥n de menciones de usuarios (@usuario) y s√≠mbolos de hashtags (#)</li>
                        <li>Eliminaci√≥n de puntuaci√≥n y n√∫meros</li>
                        <li>Reducci√≥n de espacios en blanco redundantes</li>
                    </ul>

                    <div class="section-subtitle">Preprocesamiento Completo (preprocess_text)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        A continuaci√≥n, el texto limpio se somete a un procesamiento adicional para preparar los datos
                        para modelos de NLP:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Tokenizaci√≥n:</strong> El texto se divide en palabras individuales</li>
                        <li><strong>Eliminaci√≥n de stopwords:</strong> Se eliminan palabras comunes sin contenido
                            sem√°ntico relevante (como ‚Äúthe‚Äù, ‚Äúand‚Äù, ‚Äúis‚Äù) utilizando la lista de NLTK</li>
                        <li><strong>Lematizaci√≥n:</strong> Cada palabra se reduce a su forma base (por ejemplo,
                            ‚Äúrunning‚Äù ‚Üí ‚Äúrun‚Äù, ‚Äúcars‚Äù ‚Üí ‚Äúcar‚Äù) usando WordNetLemmatizer.</li>
                        <li><strong>Reconstrucci√≥n del texto:</strong> Los tokens resultantes se unen nuevamente en un
                            string, listo para su an√°lisis o entrada a un modelo</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este pipeline permite obtener un texto limpio, normalizado y representativo, adecuado para
                        t√©cnicas de NLP como modelos de LSTM,
                        Naive Bayes o TF-IDF, mejorando la calidad de las predicciones y reduciendo el ruido en los
                        datos.
                    </p>

                    <div class="spec-card">
                        <strong>üìù Ejemplos de Preprocesamiento:</strong>
                        <div
                            style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                            <p><strong>Original:</strong> "with pale blue berries. in these peaceful shades"</p>
                            <p><strong>Procesado:</strong> "pale blue berry peaceful shade"</p>
                            <hr style="border: none; border-top: 1px solid #ddd; margin: 10px 0;">
                            <p><strong>Original:</strong> "it flows so long as falls the rain,"</p>
                            <p><strong>Procesado:</strong> "flow long fall rain"</p>
                        </div>
                    </div>

                    <div style="height: 20px; clear: both;"></div>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Se puede observar que, tras aplicar procesamiento, se reduce la longitud de la oraci√≥n original,
                        se removi√≥ puntuaci√≥n y stopwords.
                    </p>

                    <div class="section-subtitle">Data Augmentation</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Se implement√≥ un pipeline de aumento de datos utilizando la librer√≠a <code>nlpaug</code> para
                        balancear
                        las clases minoritarias. El objetivo principal es balancear las clases minoritarias en el
                        dataset y mejorar la capacidad del modelo para generalizar.
                        El proceso incluye:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Selecci√≥n de clases minoritarias:</strong> Se identifican las clases que tienen
                            pocas muestras (por ejemplo: ‚Äúnegative‚Äù, ‚Äúpositive‚Äù y ‚Äúmixed‚Äù)
                            y se les aplica un mayor n√∫mero de "augmentations" para equilibrar la distribuci√≥n de
                            clases.</li>
                        <li><strong>Generaci√≥n de nuevas muestras:</strong> Para cada texto en el dataset se generan
                            varias versiones alternativas reemplazando palabras por sin√≥nimos usando WordNet.</li>
                        <li><strong>Proporci√≥n de aumentos:</strong> Las clases minoritarias reciben m√°s aumentos que
                            las clases mayoritarias, logrando un balance m√°s uniforme.</li>
                        <li><strong>Creaci√≥n de dataset final:</strong> Los textos originales y los aumentados se
                            combinan en un nuevo DataFrame.</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Esto produce un dataset m√°s grande y balanceado, que reduce el sesgo hacia clases mayoritarias y
                        ayuda a mejorar el entrenamiento de modelos de NLP.
                    </p>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este procedimiento es especialmente √∫til en problemas de clasificaci√≥n de texto donde algunas
                        categor√≠as tienen muy pocas muestras, ya que incrementa la diversidad de los datos
                        sin necesidad de recolectar m√°s ejemplos reales.

                    </p>

                    <div class="spec-card">
                        <strong>üìù Ejemplos de Data Augmentation:</strong>
                        <div
                            style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                            <p><strong>Original:</strong> "right wrong john"</p>
                            <p><strong>Aumento 1:</strong> "right unseasonable john"</p>
                            <p><strong>Aumento 2:</strong> "right ill timed john"</p>
                            <p><strong>Aumento 3:</strong> "right wrong king john"</p>
                            <p><strong>Aumento 4:</strong> "mightily wrong john"</p>
                        </div>
                    </div>

                    <p style="text-align: justify; line-height: 1.8; margin-top: 20px;">
                        Tras aplicar aumentos, se puede observar que en cada aumento se cambia la palabra <em>wrong</em>
                        (malo) por un sin√≥nimo diferente:
                        <em>unseasonable</em>, <em>ill timed</em>, <em>mightily wrong john</em>, haciendo el dataset m√°s
                        diverso. A la clase mayoritaria se le
                        aplicaron 5 aumentos y a las minoritarias 14 por cada muestra. De esta manera, se genera una
                        representaci√≥n m√°s rica de cada clase
                        sin necesidad de recolectar datos nuevos.
                    </p>

                    <p style="text-align: justify; line-height: 1.8; margin-top: 20px;">
                        La distribuci√≥n resultante se puede observar en la Tabla 2:
                    </p>

                    <table class="format-table" style="margin-top: 15px;">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                                <th>Porcentaje</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>2,775</td>
                                <td>35.45%</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>2,325</td>
                                <td>29.69%</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>1,995</td>
                                <td>25.48%</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>735</td>
                                <td>9.39%</td>
                            </tr>
                            <tr style="background: #f0f0f0; font-weight: bold;">
                                <td><strong>Total</strong></td>
                                <td>7,830</td>
                                <td>100%</td>
                            </tr>
                        </tbody>
                    </table>
                    <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                        Tabla 2. Distribuci√≥n de clases despu√©s de aplicar aumentos</p>

                </div>

                <!-- PAGE 5: Text Representation -->
                <div class="page-section">
                    <div class="section">
                        <div class="section-title">üî¢ 4. Representaci√≥n de Texto</div>

                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                            Se utiliz√≥ CountVectorizer para los modelos cl√°sicos y embeddings + secuencias para la LSTM.
                        </p>

                        <div class="section-subtitle">Count Vectorizer</div>
                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            El CountVectorizer se utiliza para convertir texto en una representaci√≥n num√©rica que pueda
                            ser procesada
                            por modelos de machine learning. Transforma un conjunto de documentos en una matriz de
                            conteo de palabras,
                            donde cada fila representa un documento, cada columna representa una palabra del
                            vocabulario, y el valor
                            indica cu√°ntas veces aparece esa palabra en el documento.
                        </p>

                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                            En <strong>scikit-learn</strong>, CountVectorizer se configura como un objeto que luego se
                            ajusta (fit) y transforma (transform) sobre los textos. La Ilustraci√≥n 4 muestra como
                            ajustar sus par√°metros.
                        </p>

                        <div style="text-align: center; margin: 30px 0;">
                            <img src="count_vectorizer.png" alt="Configuraci√≥n de CountVectorizer"
                                style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                            <p
                                style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                Ilustraci√≥n 4. Ejemplo de configuraci√≥n de CountVectorizer</p>
                        </div>

                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            <strong>Configuraci√≥n:</strong> max_features=10000, unigramas y bigramas
                        </p>
                        <p style="text-align: justify; line-height: 1.8;">
                            <strong>Matrices resultantes:</strong>
                        </p>
                        <ul style="line-height: 2;">
                            <li>X_train: (7830, 10000)</li>
                            <li>X_val: (105, 10000)</li>
                            <li>X_test: (104, 10000)</li>
                        </ul>

                        <div class="section-subtitle">Tokenizaci√≥n para LSTM</div>
                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            Para entrenar una LSTM, cada documento se convirti√≥ en una secuencia num√©rica de longitud
                            fija mediante
                            la librer√≠a Keras Tokenizer:
                        </p>
                        <ul style="line-height: 2;">
                            <li><strong>Tokenizaci√≥n:</strong> Asignaci√≥n de identificador √∫nico a cada palabra del
                                vocabulario</li>
                            <li><strong>Padding:</strong> Relleno con ceros para garantizar longitud fija</li>
                            <li><strong>Entrada al modelo:</strong> El conjunto completo se representa como una matriz
                                de dimensi√≥n <code>(n_samples, max_sequence_length)</code>, donde <code>n_samples</code>
                                es el n√∫mero de documentos y <code>max_sequence_length</code> es la longitud m√°xima de
                                las secuencias despu√©s del padding</li>
                            <li><strong>Embedding:</strong> Transformaci√≥n de enteros en vectores densos de tama√±o fijo
                                (embedding_dim), resultando en una entrada final con forma: <code>(batch_size,
                                sequence_length, embedding_dim)</code></li>

                        </ul>
                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            <strong>Configuraci√≥n de ejemplo:</strong> num_words=10000, oov_token="&lt;OOV&gt;"
                        </p>

                        <div class="spec-card">
                            <strong>üìù Ejemplo de Tokenizaci√≥n:</strong>
                            <div
                                style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                                <p><strong>Texto:</strong> "i love nlp"</p>
                                <p><strong>Tokenizado:</strong> [2, 3, 1]</p>
                                <p><strong>Con Padding (longitud=5):</strong> [2, 3, 1, 0, 0]</p>
                            </div>
                        </div>

                        <div style="text-align: center; margin: 30px 0;">
                            <img src="tokenizacion_keras.png" alt="Tokenizaci√≥n en Keras"
                                style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                            <p
                                style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                Ilustraci√≥n 5. Tokenizaci√≥n en Keras</p>
                        </div>



                    </div>

                    <!-- PAGE 6: Models -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">ü§ñ 5. Modelos Implementados</div>

                            <div class="section-subtitle">5.1 Regresi√≥n Log√≠stica</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                La regresi√≥n log√≠stica fue seleccionada por su capacidad para manejar eficazmente
                                representaciones vectorizadas
                                del texto. Este modelo aprende a estimar la probabilidad de pertenencia a cada clase
                                mediante una combinaci√≥n
                                lineal de caracter√≠sticas, lo cual resulta apropiado en problemas de an√°lisis de texto
                                donde la presencia
                                o frecuencia de ciertas palabras suele correlacionarse directamente con el sentimiento.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Permite incorporar pesos para clases minoritarias (class weights)</li>
                                    <li>Naturaleza probabil√≠stica facilita interpretar confianza</li>
                                    <li>Bajo costo computacional y estable</li>
                                    <li>Excelente baseline para comparar con modelos m√°s complejos</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>
                            <p style="margin-top: 15px;"><strong>Librer√≠a:</strong>
                                sklearn.linear_model.LogisticRegression</p>
                            <p style="margin-top: 15px;"><strong>Par√°metros:</strong> max_iter=1000</p>

                            <div style="text-align: center; margin: 30px 0;">
                                <img src="logistic_regression.png" alt="Par√°metros utilizados para regresi√≥n log√≠stica"
                                    style="max-width: 70%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                <p
                                    style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                    Ilustraci√≥n 6. Par√°metros utilizados para regresi√≥n log√≠stica</p>
                            </div>

                            <div class="section-subtitle">5.2 Naive Bayes Multinomial</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                El modelo Naive Bayes Multinomial est√° especialmente dise√±ado para trabajar con datos
                                representados como
                                frecuencias de palabras, como los obtenidos mediante t√©cnicas de Bag-of-Words o TF-IDF.
                                Asume independencia entre las caracter√≠sticas (palabras), lo
                                que simplifica el
                                c√°lculo de probabilidades y permite un entrenamiento muy r√°pido incluso con grandes
                                vol√∫menes de texto.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Rendimiento competitivo en clasificaci√≥n de textos</li>
                                    <li>Especialmente efectivo cuando hay palabras claramente asociadas a cada
                                        sentimiento</li>
                                    <li>Entrenamimiento r√°pido y eficiente</li>
                                    <li>Opci√≥n s√≥lida como modelo base</li>
                                </ul>
                            </div>
                            <p style="margin-top: 15px;"><strong>Implementaci√≥n:</strong> MultinomialNB de scikit-learn
                            </p>
                            <div style="text-align: center; margin: 30px 0;">
                                <img src="multinomial_nb.png" alt="Par√°metros utilizados para Naive Bayes Multinomial"
                                    style="max-width: 40%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                <p
                                    style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                    Ilustraci√≥n 7. Configuraci√≥n de par√°metros de Naive Bayes Multinomial</p>
                            </div>
                            <div class="section-subtitle">5.3 LSTM (Long Short-Term Memory)</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                Las redes LSTM (Long Short-Term Memory) se utilizan en la clasificaci√≥n de sentimientos
                                porque est√°n dise√±adas para procesar secuencias de texto teniendo en cuenta el contexto
                                y el orden de las palabras, algo que los modelos tradicionales como Bag-of-Words no
                                pueden capturar. A diferencia de los modelos basados en frecuencias, que tratan cada
                                palabra de forma independiente, una LSTM puede recordar informaci√≥n relevante de
                                palabras anteriores y utilizarla para interpretar correctamente el sentimiento de una
                                frase completa. Esto es especialmente √∫til en casos donde el significado depende de la
                                estructura, como en negaciones (‚Äúno fue tan bueno‚Äù) o expresiones compuestas. Gracias a
                                esta capacidad para modelar dependencias a largo plazo, las LSTM logran una
                                representaci√≥n m√°s sem√°ntica del texto, mejorando el desempe√±o en tareas de an√°lisis de
                                sentimientos. Para su implementaci√≥n se utiliz√≥ la librer√≠a de keras y los par√°metros se
                                definen de acuerdo a la Ilustraci√≥n 8 donde: input_dim es el tama√±o de vocabulario;
                                output_dim, la dimensi√≥n del vector de embedding; input_length, la longitud m√°xima de
                                las secuencias; LSTM (), el n√∫mero de unidades de memoria en una LSTM; Dense es el
                                n√∫mero de clases de salida y activation es la funci√≥n de activaci√≥n para clasificaci√≥n
                                multiclase.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Modela dependencias a largo plazo</li>
                                    <li>√ötil para negaciones y expresiones compuestas</li>
                                    <li>Representaci√≥n m√°s sem√°ntica del texto</li>
                                    <li>Mejor desempe√±o en tareas complejas de an√°lisis de sentimientos</li>
                                </ul>
                            </div>
                            <p style="margin-top: 15px;"><strong>Framework:</strong> TensorFlow / Keras</p>
                            <p style="margin-top: 10px;"><strong>Arquitectura:</strong> Embedding (10000) ‚Üí LSTM (168) ‚Üí
                                Dropout (0.5) ‚Üí Dense (168) ‚Üí Dropout (0.5) ‚Üí Dense(4) ‚Üí Softmax</p>
                            <p style="margin-top: 10px;"><strong>Regularizaci√≥n:</strong> Dropout, recurrent_dropout, L2
                            </p>
                            <p style="margin-top: 10px;"><strong>Optimizer:</strong> Adam</p>
                        </div>

                        <!-- PAGE 7: Metrics and Training -->
                        <div class="page-section">
                            <div class="section">
                                <div class="section-title">üìä 6. Entrenamiento, Validaci√≥n y M√©tricas</div>

                                <div class="section-subtitle">Divisi√≥n del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utiliz√≥ la divisi√≥n est√°ndar del dataset proporcionada por Hugging Face para
                                    garantizar coherencia
                                    y reproducibilidad de los resultados.
                                </p>

                                <div class="section-subtitle">M√©tricas de Evaluaci√≥n</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utilizaron las siguientes m√©tricas para evaluar el desempe√±o de los modelos:
                                </p>
                                <ul style="line-height: 2;">
                                    <li><strong>Accuracy:</strong> Proporci√≥n de predicciones correctas</li>
                                    <li><strong>Precision (macro avg):</strong> Promedio de precisi√≥n por clase</li>
                                    <li><strong>Recall (macro avg):</strong> Promedio de recall por clase</li>
                                    <li><strong>F1 (macro avg):</strong> Media arm√≥nica de precision y recall</li>
                                </ul>
                                <p style="text-align: justify; line-height: 1.8; margin-top: 15px;">
                                    <strong>Librer√≠as utilizadas:</strong> sklearn.metrics.classification_report,
                                    confusion_matrix
                                </p>
                            </div>

                            <!-- PAGE 8: Results -->
                            <div class="page-section">
                                <div class="section">
                                    <div class="section-title">üìà 7. Resultados</div>

                                    <div class="section-subtitle">Resumen de M√©tricas</div>
                                    <table class="format-table">
                                        <thead>
                                            <tr>
                                                <th>Modelo</th>
                                                <th>Accuracy (train/test)</th>
                                                <th>Precision (macro)</th>
                                                <th>Recall (macro)</th>
                                                <th>F1 (macro)</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <td><strong>Logistic Regression</strong></td>
                                                <td>0.99 / 0.70</td>
                                                <td>0.48</td>
                                                <td>0.36</td>
                                                <td>0.38</td>
                                            </tr>
                                            <tr>
                                                <td><strong>Multinomial NB</strong></td>
                                                <td>0.99 / 0.69</td>
                                                <td>0.48</td>
                                                <td>0.48</td>
                                                <td>0.48</td>
                                            </tr>
                                            <tr>
                                                <td><strong>LSTM</strong></td>
                                                <td>0.95 / 0.51</td>
                                                <td>0.44</td>
                                                <td>0.42</td>
                                                <td>0.41</td>
                                            </tr>
                                        </tbody>
                                    </table>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; margin-top: 30px;">
                                        <strong>‚ö†Ô∏è Observaci√≥n Clave:</strong> Se observa un patr√≥n consistente de
                                        sobreajuste en todos los modelos,
                                        con desempe√±o significativamente mejor durante el entrenamiento que en el
                                        conjunto de prueba.
                                    </div>
                                </div>

                                <!-- PAGE 9: Discussion -->
                                <div class="page-section">
                                    <div class="section">
                                        <div class="section-title">üí° 8. Discusi√≥n</div>

                                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                                            A pesar de la aplicaci√≥n de t√©cnicas de aumento de datos en el conjunto de
                                            entrenamiento, los modelos
                                            evaluados presentan indicios claros de sobreajuste. Esto se evidencia en las
                                            altas precisiones obtenidas
                                            durante el entrenamiento (‚âà0.95‚Äì0.99) y la notable disminuci√≥n del
                                            rendimiento en el conjunto de prueba.
                                        </p>

                                        <div class="spec-card">
                                            <strong>An√°lisis del Sobreajuste:</strong>
                                            <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                                <li>Las estrategias de aumento incrementaron la cantidad de ejemplos
                                                    pero no aportaron suficiente variabilidad sem√°ntica</li>
                                                <li>El modelo LSTM evidencia el mayor grado de sobreajuste, posiblemente
                                                    debido a su alta capacidad de representaci√≥n</li>
                                                <li>Naive Bayes Multinomial muestra mejor generalizaci√≥n con valores m√°s
                                                    equilibrados entre entrenamiento y prueba</li>
                                            </ul>
                                        </div>

                                        <div class="highlight-box"
                                            style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                                            <strong>‚úì Conclusi√≥n Parcial:</strong> El modelo Multinomial Naive Bayes
                                            demuestra la mejor capacidad de
                                            generalizaci√≥n, manteniendo un F1-score consistente de 0.48 tanto en
                                            m√©tricas generales como en recall,
                                            indicando un equilibrio adecuado entre precisi√≥n y cobertura.
                                        </div>
                                    </div>

                                    <!-- PAGE 10: Conclusions -->
                                    <div class="page-section">
                                        <div class="section">
                                            <div class="section-title">üéØ 9. Conclusiones y Trabajo Futuro</div>

                                            <div class="section-subtitle">Conclusiones Principales</div>
                                            <ul style="line-height: 2;">
                                                <li>Se implementaron exitosamente tres modelos de an√°lisis de
                                                    sentimientos con diferentes paradigmas</li>
                                                <li>La t√©cnica de data augmentation mejor√≥ el balance de clases pero no
                                                    resolvi√≥ completamente el sobreajuste</li>
                                                <li>Naive Bayes Multinomial mostr√≥ la mejor generalizaci√≥n relativa bajo
                                                    las condiciones actuales</li>
                                                <li>El dataset peque√±o y desbalanceado limita el desempe√±o,
                                                    especialmente de modelos complejos como LSTM</li>
                                            </ul>

                                            <div class="section-subtitle">Recomendaciones para Trabajo Futuro</div>
                                            <ul style="line-height: 2;">
                                                <li>Optimizar la regularizaci√≥n de los modelos neuronales</li>
                                                <li>Explorar el uso de embeddings preentrenados (Word2Vec, GloVe,
                                                    FastText)</li>
                                                <li>Emplear t√©cnicas avanzadas de balanceo de clases (SMOTE,
                                                    estratificaci√≥n)</li>
                                                <li>Aumentar el volumen de datos o utilizar transfer learning</li>
                                                <li>Implementar validaci√≥n cruzada estratificada para evaluaciones m√°s
                                                    robustas</li>
                                            </ul>
                                        </div>

                                        <!-- PAGE 11: References & Footer -->
                                        <div class="page-section">
                                            <div class="section">
                                                <div class="section-title">üìö 10. Referencias Bibliogr√°ficas</div>

                                                <div
                                                    style="background: #f8f9fa; padding: 25px; border-radius: 8px; line-height: 2;">
                                                    <p>Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011).
                                                        <em>Scikit-learn: Machine Learning in Python</em>.
                                                        Journal of Machine Learning Research, 12, 2825-2830.
                                                    </p>

                                                    <p>Chollet, F. (2021). <em>Deep Learning with Python</em> (2nd ed.).
                                                        Manning Publications. [Keras framework documentation]</p>

                                                    <p>Google Research. (s.f.). <em>Poem sentiment</em> [Conjunto de
                                                        datos]. Hugging Face.
                                                        Disponible en:
                                                        https://huggingface.co/datasets/google-research-datasets/poem_sentiment
                                                    </p>

                                                    <p>Goodfellow, I., Bengio, Y., & Courville, A. (2016). <em>Deep
                                                            Learning</em>.
                                                        MIT Press. [Referencia para arquitecturas de redes neuronales]
                                                    </p>

                                                    <p>Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT:
                                                        Pre-training of Deep Bidirectional Transformers
                                                        for Language Understanding. arXiv preprint arXiv:1810.04805.</p>
                                                </div>
                                            </div>

                                            <!-- Footer -->
                                            <div class="footer">
                                                <p>üìä <span class="footer-highlight">Reporte Final: An√°lisis de
                                                        sentimientos en versos - Diplomado en Inteligencia
                                                        Artificial</span></p>
                                                <p style="font-size: 0.9em; color: #999;">Autor: Erik I. Osornio Botello
                                                </p>
                                                <p style="margin-top: 15px; color: #999; font-size: 0.85em;">
                                                    Este reporte presenta el desarrollo, implementaci√≥n y evaluaci√≥n de
                                                    un sistema completo de an√°lisis de sentimientos
                                                    utilizando tres enfoques distintos.
                                                </p>
                                            </div>

                                            <div class="page-number"></div>
                                        </div>
                                    </div>
                                </div>
</body>

</html>