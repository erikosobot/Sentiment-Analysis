<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte Final - Curso de Inteligencia Artificial</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        p {
            text-align: justify;
            line-height: 1.5;
            font-size: 12pt;
        }

        body {
            font-family: Arial, sans-serif;
            font-size: 12pt;
            line-height: 1.5;
            color: #333;
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
            overflow: hidden;
            padding: 2.5cm;
        }

        /* Header */
        .header {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.95;
        }

        .header-logo {
            margin-bottom: 20px;
            font-size: 3em;
        }

        /* Main Content */
        .content {
            padding: 0;
            text-align: justify;
        }

        .section {
            margin-bottom: 50px;
            page-break-inside: avoid;
            page-break-after: auto;
        }

        .section-title {
            font-size: 14pt;
            color: #000;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #C41E3A;
            font-weight: bold;
            page-break-after: avoid;
        }

        .section-subtitle {
            font-size: 12pt;
            color: #000;
            margin-top: 30px;
            margin-bottom: 15px;
            font-weight: bold;
            font-style: italic;
            padding-left: 20px;
            border-left: 4px solid #C41E3A;
        }

        .intro-text {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-left: 5px solid #C41E3A;
            margin-bottom: 30px;
            line-height: 1.5;
            font-size: 12pt;
            text-align: justify;
        }

        /* Specifications */
        .specifications {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .spec-card {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #C41E3A;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .spec-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(196, 30, 58, 0.2);
        }

        .spec-card strong {
            color: #000;
            display: block;
            margin-bottom: 8px;
        }

        /* Lists */
        ul,
        ol {
            margin-left: 30px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 12px;
            line-height: 1.5;
            text-align: justify;
        }

        li strong {
            color: #4A4A4A;
        }

        /* Structure sections */
        .structure-list {
            padding: 30px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .structure-item {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 1px solid #e0e0e0;
        }

        .structure-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .structure-item h4 {
            color: #000;
            font-size: 1.15em;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
        }

        .structure-item h4:before {
            content: "▸";
            margin-right: 10px;
            font-size: 1.3em;
            color: #4A4A4A;
        }

        .structure-description {
            margin-left: 20px;
            color: #666;
            line-height: 1.8;
        }

        /* Rubric */
        .rubric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .rubric-item {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 25px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(139, 21, 56, 0.2);
        }

        .rubric-percentage {
            font-size: 2.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .rubric-description {
            font-size: 0.95em;
            opacity: 0.95;
        }

        /* Deliverables */
        .deliverables {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 30px;
            border-radius: 8px;
            border: 2px solid #C41E3A;
        }

        .deliverable-item {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
            font-size: 1.05em;
        }

        .deliverable-item:last-child {
            margin-bottom: 0;
        }

        .deliverable-icon {
            width: 30px;
            height: 30px;
            background: #C41E3A;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 15px;
            font-weight: bold;
            flex-shrink: 0;
        }

        /* Format Table */
        .format-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            overflow: hidden;
        }

        .format-table th {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }

        .format-table td {
            padding: 15px;
            border-bottom: 1px solid #e0e0e0;
        }

        .format-table tr:hover {
            background: #f8f9fa;
        }

        .format-table tr:last-child td {
            border-bottom: none;
        }

        /* Footer */
        .footer {
            background: #f8f9fa;
            padding: 30px 40px;
            text-align: center;
            color: #666;
            border-top: 1px solid #e0e0e0;
        }

        .footer p {
            margin-bottom: 10px;
        }

        .footer-highlight {
            color: #4A4A4A;
            font-weight: bold;
        }

        /* Highlight boxes */
        .highlight-box {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            border-left: 4px solid #C41E3A;
            padding: 15px 20px;
            border-radius: 4px;
            margin: 20px 0;
            color: #000;
        }

        .highlight-box strong {
            color: #000;
        }

        /* Code blocks */
        .code-block {
            background-color: #f5f5f5;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            border-left: 4px solid #C41E3A;
            margin: 15px 0;
            font-size: 0.9em;
            line-height: 1.4;
        }

        /* Responsiveness */
        @media (max-width: 768px) {
            .header {
                padding: 40px 20px;
            }

            .header h1 {
                font-size: 1.8em;
            }

            .content {
                padding: 30px 20px;
                text-align: justify;
            }

            .section-title {
                font-size: 1.6em;
            }

            .specifications,
            .rubric-grid {
                grid-template-columns: 1fr;
            }

            .structure-item h4 {
                font-size: 1.05em;
            }

            .format-table {
                font-size: 0.9em;
            }

            .format-table th,
            .format-table td {
                padding: 10px;
            }

            p,
            li,
            td {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }
        }

        /* Animation */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .section {
            animation: fadeIn 0.6s ease-out;
        }

        .spec-card {
            animation: fadeIn 0.6s ease-out;
        }

        /* Print styles */
        @media print {
            body {
                background: white;
                padding: 2.5cm;
                margin: 0;
                font-size: 12pt;
                line-height: 1.5;
                counter-reset: page 1;
            }

            .container {
                box-shadow: none;
                border-radius: 0;
                padding: 0;
                max-width: 100%;
                margin: 0;
            }

            .header {
                page-break-after: avoid;
                padding: 30px 0;
            }

            .content {
                padding: 0;
                text-align: justify;
            }

            p,
            li,
            td,
            th {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }

            .section {
                page-break-inside: avoid;
            }

            @page {
                margin: 2.5cm;

                @bottom-center {
                    content: counter(page);
                    font-size: 12pt;
                    font-family: Arial, sans-serif;
                }
            }
        }

        /* Code styles */
        code {
            background: #f0f0f0;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d63384;
        }

        /* COVER PAGE STYLES */
        .cover-page {
            display: flex;
            align-items: flex-start;
            justify-content: center;
            min-height: 100vh;
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            color: #000;
            text-align: center;
            padding: 60px 60px 80px 60px;
            page-break-after: always;
            position: relative;
        }

        .cover-page::before {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #C41E3A, rgba(196, 30, 58, 0) 50%, rgba(196, 30, 58, 0));
        }

        .cover-page::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 2px;
            background: linear-gradient(90deg, rgba(196, 30, 58, 0), #C41E3A 50%, rgba(196, 30, 58, 0));
        }

        .cover-content {
            max-width: 600px;
            animation: fadeInCover 0.8s ease;
        }

        @keyframes fadeInCover {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .cover-logos {
            display: flex;
            justify-content: space-between;
            gap: 0;
            margin-bottom: 50px;
            align-items: center;
            width: 100%;
            max-width: none;
            margin-left: 0;
            margin-right: 0;
            min-height: 120px;
        }

        .cover-logo {
            flex: 0 0 auto;
            background: rgba(139, 21, 56, 0.05);
            padding: 15px;
            border-radius: 8px;
            border: 1px solid rgba(139, 21, 56, 0.2);
            backdrop-filter: blur(10px);
        }

        .cover-logo img {
            max-width: 100px;
            height: auto;
            filter: brightness(1);
            transition: transform 0.3s ease;
        }

        .cover-logo img:hover {
            transform: scale(1.05);
        }

        .cover-institution {
            margin-bottom: 60px;
            letter-spacing: 0.5px;
        }

        .cover-institution h2 {
            font-size: 2em;
            margin-bottom: 8px;
            font-weight: 700;
            letter-spacing: 0.3px;
            line-height: 1.2;
            color: #000;
        }

        .cover-institution p {
            font-size: 1.15em;
            opacity: 1;
            font-weight: 500;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-course {
            margin-bottom: 90px;
            font-size: 1.25em;
            font-style: italic;
            opacity: 1;
            font-weight: 400;
            letter-spacing: 0.3px;
            color: #000;
        }

        .cover-main {
            margin-bottom: 100px;
        }

        .cover-main h1 {
            font-size: 3.5em;
            margin-bottom: 20px;
            font-weight: 800;
            text-shadow: none;
            line-height: 1.1;
            letter-spacing: -0.5px;
            color: #000;
        }

        .cover-subtitle {
            font-size: 1.4em;
            opacity: 1;
            font-style: italic;
            line-height: 1.5;
            font-weight: 300;
            color: #000;
        }

        .cover-author {
            margin-bottom: 70px;
            font-size: 1.1em;
        }

        .cover-author p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-author p:last-child {
            font-size: 1.4em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-date {
            font-size: 1.1em;
            margin-top: 80px;
            padding-top: 30px;
            border-top: 1px solid #C41E3A;
        }

        .cover-date p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-date p:last-child {
            font-size: 1.3em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        /* Print styles for cover */
        @media print {
            .cover-page {
                page-break-after: always;
                background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
                color: white;
            }
        }

        code-block {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            display: block;
            overflow-x: auto;
        }

        /* Footer con numeración de página */
        .page-number {
            text-align: center;
            padding: 20px 0;
            color: #999;
            font-size: 11pt;
            border-top: 1px solid #ddd;
            margin-top: 40px;
        }

        @media print {
            .page-number {
                display: none;
            }
        }

        /* Download Button */
        .download-container {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
        }

        .download-btn {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: bold;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(139, 21, 56, 0.3);
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .download-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(139, 21, 56, 0.4);
        }

        .download-btn:active {
            transform: translateY(0);
        }

        @media print {
            .download-container {
                display: none;
            }
        }

        /* Page Break Control */
        .page-section {
            page-break-after: always;
            page-break-inside: avoid;
            padding: 20px 0;
            margin-bottom: 1cm;
        }

        .page-section:last-child {
            page-break-after: avoid;
        }

        .section-page-break {
            page-break-after: always;
        }

        /* Evitar rupturas dentro de elementos */
        .page-section .section {
            page-break-inside: avoid;
        }

        .section-subtitle {
            page-break-after: avoid;
        }

        .section-title {
            page-break-after: avoid;
        }

        ul,
        ol {
            page-break-inside: avoid;
        }

        .format-table {
            page-break-inside: avoid;
        }

        .spec-card {
            page-break-inside: avoid;
        }

        .highlight-box {
            page-break-inside: avoid;
        }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script src="https://unpkg.com/docx@8.12.6/build/index.js"></script>
    <script>
        // Script para numeración de páginas
        window.addEventListener('load', function () {
            // En navegador, agregar numeración visible
            const pageNumbers = document.querySelectorAll('.page-number');
            if (pageNumbers.length > 0) {
                let pageCount = 1;
                pageNumbers.forEach((element, index) => {
                    element.textContent = 'Página ' + (index + 1);
                });
            }
        });

        // Función para descargar como Word
        function downloadAsWord() {
            try {
                const container = document.querySelector('.container');
                if (!container) {
                    alert('No se encontró el contenido para exportar');
                    return;
                }

                // Obtener el HTML completo
                const html = container.innerHTML;

                // Crear documento Word en formato OOXML
                const docContent = `<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<?mso-application progid="Word.Document"?>
<html xmlns:v="urn:schemas-microsoft-com:vml"
 xmlns:o="urn:schemas-microsoft-com:office:office"
 xmlns:w="urn:schemas-microsoft-com:office:word"
 xmlns:x="urn:schemas-microsoft-com:office:excel"
 xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
 xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 16">
<meta name=Originator content="Microsoft Word 16">
<link rel=File-List href="filelist.xml">
<title>Reporte Final - Análisis de sentimientos en versos</title>
<o:DocumentProperties>
 <o:Author>Erik I. Osornio Botello</o:Author>
 <o:LastAuthor>Erik I. Osornio Botello</o:LastAuthor>
 <o:Created>2025-10-16T00:00:00Z</o:Created>
 <o:LastSaved>2025-10-16T00:00:00Z</o:LastSaved>
 <o:Pages>1</o:Pages>
 <o:Words>1</o:Words>
 <o:Characters>1</o:Characters>
 <o:Lines>1</o:Lines>
 <o:Paragraphs>1</o:Paragraphs>
 <o:CharactersWithSpaces>1</o:CharactersWithSpaces>
 <o:Version>16.00</o:Version>
</o:DocumentProperties>
</head>
<body>
${html}
</body>
</html>`;

                // Crear Blob
                const blob = new Blob([docContent], { type: 'application/vnd.ms-word' });

                // Descargar
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;
                link.download = 'Reporte_Analisis_Sentimientos.doc';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);

                alert('✓ Descargado: Reporte_Analisis_Sentimientos.doc');
            } catch (error) {
                console.error('Error:', error);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }

        // Función alternativa: descargar como PDF
        function downloadAsPDF() {
            try {
                const element = document.querySelector('.container');
                const cloned = element.cloneNode(true);
                cloned.querySelectorAll('.download-container, .page-number, .header').forEach(el => el.remove());

                const opt = {
                    margin: 10,
                    filename: 'Reporte_Analisis_Sentimientos.pdf',
                    image: { type: 'jpeg', quality: 0.98 },
                    html2canvas: { scale: 2 },
                    jsPDF: { orientation: 'portrait', unit: 'mm', format: 'a4' }
                };

                html2pdf().set(opt).from(cloned).save();
                alert('Descargando como PDF...');
            } catch (err) {
                console.error('Error al descargar:', err);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }
    </script>
</head>

<body>
    <div class="container">
        <!-- COVER PAGE -->
        <div class="cover-page">
            <div class="cover-content">
                <div class="cover-logos">
                    <div class="cover-logo">
                        <img src="logo_cic.jpg" alt="Logo CIC - Centro de Investigación en Computación">
                    </div>
                    <div class="cover-institution" style="text-align: center; flex: 1; display: flex; flex-direction: column; align-items: center; justify-content: center;">
                        <h2 style="margin: 0; padding: 0 20px; font-size: 1.3em;">Centro de Investigación en Computación</h2>
                        <p style="margin: 10px 0 0 0; font-size: 1em;">Diplomado en Inteligencia Artificial</p>
                    </div>
                    <div class="cover-logo">
                        <img src="logo_ipn.jpg" alt="Logo IPN - Instituto Politécnico Nacional">
                    </div>
                </div>

                <div class="cover-course">
                    <p style="display: none;">Diplomado en Inteligencia Artificial</p>
                </div>

                <div class="cover-main">
                    <h1>Análisis de sentimientos en poemas</h1>
                    <p class="cover-subtitle">Implementación y Evaluación de Tres Enfoques de Clasificación</p>
                </div>

                <div class="cover-author">
                    <p><strong>Autor:</strong></p>
                    <p>Erik I. Osornio Botello</p>
                </div>

                <div class="cover-date">
                    <p><strong>Fecha de Entrega:</strong></p>
                    <p>16 de Octubre de 2025</p>
                </div>
            </div>
        </div>

        <!-- TABLE OF CONTENTS -->
        <div style="page-break-after: always; padding: 40px 0;">
            <h2 style="font-size: 1.8em; color: #000; margin-bottom: 30px; text-align: center; font-weight: bold;">
                Índice</h2>
            <ol style="font-size: 12pt; line-height: 2; margin-left: 30px; color: #333;">
                <li>Introducción</li>
                <li>Metodología</li>
                <li>Datos</li>
                <li>Preprocesamiento</li>
                <li>Representación de texto</li>
                <li>Modelos implementados
                    <ol style="margin-top: 10px; margin-left: 20px;">
                        <li>Regresión Logística</li>
                        <li>Naive Bayes Multinomial</li>
                        <li>DeBERTa‑v3‑base (fine‑tuning)</li>
                    </ol>
                </li>
                <li>Entrenamiento y validación</li>
                <li>Métricas y evaluación</li>
                <li>Resultados</li>
                <li>Discusión</li>
                <li>Conclusiones y trabajo futuro</li>
                <li>Referencias</li>
            </ol>
        </div>

        <!-- Main Content -->
        <div class="content">
            <!-- PAGE 1: Title and Author -->
            <div class="page-section">
                <div class="section" style="text-align: center; margin-bottom: 60px;">
                    <h2 style="font-size: 2.2em; color: #000; margin-bottom: 10px;">Análisis de sentimientos en versos
                    </h2>
                    <p style="font-size: 1.2em; color: #000; margin-bottom: 30px;"><strong>Autor:</strong> Erik I.
                        Osornio Botello</p>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; max-width: 800px; margin: 0 auto;">
                        <h3 style="color: #000; margin-bottom: 15px;">Resumen</h3>
                        <p style="text-align: justify; line-height: 1.8; color: #333;">
                            Este documento describe el desarrollo, implementación y evaluación de un sistema de análisis
                            de sentimientos sobre versos del dataset Poem Sentiment. Se comparan <strong>baselines
                                clásicos</strong>
                            (Regresión Logística y Naive Bayes Multinomial con CountVectorizer+SMOTE) frente a un
                            <strong>modelo preentrenado DeBERTa‑v3‑base</strong> ajustado finamente. Se detalla el flujo
                            completo: exploración y limpieza de datos, diferencias de preprocesamiento por enfoque,
                            entrenamiento, optimización de hiperparámetros, evaluación y discusión de resultados.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 2: Introduction Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📋 1. Introducción</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        El análisis de sentimientos busca asignar una polaridad (por ejemplo: positiva, negativa,
                        neutral) a textos.
                        En este proyecto se implementan tres enfoques que representan paradigmas distintos: modelos
                        lineales probabilísticos
                        (Regresión Logística), modelos de probabilidades condicionales con suposiciones de independencia
                        (Naive Bayes Multinomial)
                        y un transformador preentrenado (DeBERTa‑v3‑base). Se discute su preparación,
                        rendimiento y trade-offs.
                    </p>

                    <div class="section-subtitle">Contexto del Problema</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El análisis de sentimientos en textos poéticos presenta un desafío particular comparado con textos
                        cotidianos o técnicos. La poesía, especialmente la de épocas antiguas, emplea un lenguaje altamente
                        metafórico, ambiguo y cargado de subjetividad. Los poetas frecuentemente expresan emociones de manera
                        indirecta, mediante descripciones de la naturaleza, objetos abstractos o figuras literarias, lo que
                        dificulta la detección automática del sentimiento. Este proyecto aborda la clasificación de versos
                        de poemas ingleses antiguos en categorías de sentimiento (positivo, negativo, sin impacto),
                        utilizando un dataset curado de 1,101 ejemplos disponible en Hugging Face.
                    </p>

                    <div class="section-subtitle">Importancia Académica e Industrial</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Este proyecto es relevante en múltiples contextos:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Académico:</strong> Consolida conocimientos de aprendizaje supervisado, procesamiento de
                            lenguaje natural (NLP), y comparación de paradigmas clásicos vs. modernos (Transformers). Proporciona
                            experiencia práctica en gestión de datos desbalanceados, regularización y evaluación de modelos.</li>
                        <li><strong>Industrial/Aplicado:</strong> Las técnicas son transferibles a análisis de sentimientos en
                            reseñas de libros, críticas literarias, análisis de opiniones en redes sociales, y herramientas de
                            asistencia editorial. La metodología de comparación entre baselines y transformadores es aplicable
                            a cualquier tarea de clasificación de texto con recursos limitados.</li>
                    </ul>

                    <div class="section-subtitle">Alcance y Limitaciones</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        <strong>Alcance:</strong> Este proyecto implementa tres modelos completos (Regresión Logística, Naive Bayes
                        Multinomial, DeBERTa-v3-base), documenta el pipeline de preprocesamiento, reporta métricas de desempeño
                        (F1-macro, accuracy, precision, recall) y analiza resultados con énfasis en la clase positiva.
                    </p>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        <strong>Limitaciones:</strong>
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Tamaño del dataset:</strong> Con 1,101 ejemplos y desbalance hacia la clase "sin impacto",
                            los modelos pueden tener capacidad de generalización limitada fuera de poesía antigua en inglés.</li>
                        <li><strong>Clase "mixta" excluida:</strong> La clase "mixed" se excluyó por baja frecuencia (5.5%) y
                            ambigüedad conceptual, limitando la completitud del análisis.</li>
                        <li><strong>Dominio específico:</strong> Los modelos se entrenan en poesía inglesa de Project Gutenberg,
                            por lo que su desempeño en otros idiomas, épocas o géneros no se garantiza.</li>
                        <li><strong>Recursos computacionales:</strong> No se exploraron modelos más grandes (DeBERTa-large,
                            RoBERTa-large) ni ensembles por limitaciones de tiempo/recursos, dejando margen para mejora.</li>
                    </ul>

                    <div class="section-subtitle">Objetivos</div>
                    <ul style="line-height: 2;">
                        <li><strong>Objetivo General:</strong> Implementar y comparar tres enfoques de clasificación (dos clásicos y uno moderno basado en Transformers) para análisis de sentimientos en poesía, demostrando la viabilidad de ambos paradigmas con énfasis en técnicas de regularización para datasets pequeños.</li>
                        <li><strong>Objetivos Específicos:</strong>
                            <ul style="margin-top: 8px; margin-left: 20px; line-height: 1.8;">
                                <li>Alcanzar F1-macro ≥ 0.85 en el conjunto de prueba mediante fine-tuning de DeBERTa-v3-base con Focal Loss y class weights.</li>
                                <li>Comparar baselines clásicos (Regresión Logística, Naive Bayes Multinomial) con transformadores, evaluando trade-offs de complejidad vs. desempeño.</li>
                                <li>Documentar estrategias de preprocesamiento diferenciadas según el tipo de modelo, preservando matices poéticos en transformadores.</li>
                                
                                <li>Proporcionar recomendaciones reproducibles para análisis de sentimientos en dominios especializados (poesía, literatura, textos arcaicos).</li>
                            </ul>
                        </li>
                    </ul>

                    <div class="section-subtitle">Marco de Referencia</div>
                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <p style="margin-bottom: 12px;">
                            <strong>📋 Indicaciones del Proyecto:</strong> Este proyecto se fundamenta en las
                            indicaciones
                            especificadas en el documento <em>Indicaciones Proyecto Poemas.pdf</em>, el cual establece
                            que:
                        </p>
                        <p
                            style="margin-bottom: 12px; padding-left: 15px; border-left: 3px solid #C41E3A; margin-left: 0;">
                            <strong>"Este proyecto es un ejercicio de aprendizaje supervisado. La idea general consiste
                                en
                                implementar tres clasificadores de texto para el problema de análisis de sentimientos en
                                versos de poemas."</strong>
                        </p>
                        <p>
                            <strong>Clases del Problema:</strong> El marco original define tres categorías de
                            sentimiento (positivo, negativo
                            o neutral), aunque en la práctica el dataset utilizado incluye cuatro clases: Positivo,
                            Negativo, Mixto y No impacto.
                            La estructura de tres clasificadores y el enfoque de aprendizaje supervisado se mantienen
                            como eje central de
                            la implementación.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 1.5: Marco Teórico -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📚 1.5 Marco Teórico</div>

                    <div class="section-subtitle">Análisis de Sentimientos (Sentiment Analysis)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El análisis de sentimientos es una tarea fundamental en el procesamiento de lenguaje natural (NLP) que busca 
                        determinar la orientación emocional (positiva, negativa o neutra) de un texto. Formalmente, es un problema 
                        de clasificación multiclase donde se asigna una etiqueta de sentimiento a cada documento basándose en su 
                        contenido lingüístico.
                    </p>

                    <div class="section-subtitle">Enfoques Clásicos vs. Transformadores</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Existen dos paradigmas principales para esta tarea:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Enfoques Clásicos (Bolsa de Palabras):</strong> Modelos como Naive Bayes y Regresión Logística 
                        trabajan con representaciones de frecuencia (TF-IDF, CountVectorizer). Son rápidos, interpretables y eficientes 
                        con datos pequeños, pero no capturan relaciones contextuales o semánticas complejas.</li>
                        <li><strong>Transformadores (Contextuales):</strong> Modelos como BERT, DeBERTa utilizan mecanismos de 
                        auto-atención para capturar dependencias de largo alcance y contexto. Requieren más datos y recursos, pero 
                        son superiores en capturar matices lingüísticos, especialmente en dominios especializados como la poesía.</li>
                    </ul>

                    <div class="section-subtitle">Desafíos en Análisis de Sentimientos de Poesía</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El lenguaje poético presenta características únicas que lo hacen más desafiante:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Ambigüedad Semántica:</strong> Los poemas emplean metáforas, simbolismo y dobles sentidos que 
                        dificultan la extracción automática de sentimientos.</li>
                        <li><strong>Expresión Indirecta:</strong> Las emociones se comunican implícitamente a través de descripciones 
                        de objetos, naturaleza o estados abstractos, no mediante palabras emocionales explícitas.</li>
                        <li><strong>Escasez de Datos Etiquetados:</strong> Hay pocos datasets de sentimientos en poesía comparado con 
                        reseñas de productos o redes sociales, lo que requiere técnicas de regularización robustas.</li>
                        <li><strong>Vocabulario Arcaico:</strong> La poesía antigua contiene palabras y estructuras lingüísticas 
                        obsoletas que requieren preprocesamiento especializado.</li>
                    </ul>

                    <div class="section-subtitle">Técnicas de Regularización para Datasets Pequeños</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Con 1,101 ejemplos (pequeño para deep learning), se aplican técnicas para mejorar generalización:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>SMOTE:</strong> Sobremuestreo sintético de clases minoritarias para balanceo en modelos clásicos.</li>
                        <li><strong>Focal Loss:</strong> Función de pérdida que penaliza más ejemplos mal clasificados de clases 
                        minoritarias, evitando que el modelo ignore clases raras.</li>
                        <li><strong>Class Weights:</strong> Asignación de pesos inversamente proporcionales a la frecuencia de clase.</li>
                        <li><strong>Label Smoothing:</strong> Técnica que suaviza etiquetas one-hot (0.1 en clases incorrectas) para 
                        evitar sobrefitting.</li>
                        <li><strong>Early Stopping:</strong> Detención del entrenamiento cuando la métrica de validación no mejora, 
                        evitando sobreajuste.</li>
                    </ul>
                </div>
            </div>

            <!-- PAGE 2.1: Metodología -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">🧭 2. Metodología</div>

                    <div class="section-subtitle">Análisis de los datos y preprocesamiento</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El dataset <em>Poem Sentiment</em> presenta textos breves, con fuerte desbalance hacia la clase
                        <code>no_impact</code> y matices poéticos/arcaicos. Se implementaron dos estrategias de
                        preprocesamiento diferentes, de acuerdo con el tipo de modelo:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Baselines clásicos (MultinomialNB, Regresión Logística):</strong> preprocesamiento
                            optimizado para poesía inglesa antigua (expansión de contracciones arcaicas, normalización de
                            signos, limpieza suave). Tras tokenizar, se aplicó
                            <code>CountVectorizer(max_features=10000)</code>
                            y balanceo con <code>SMOTE</code> únicamente sobre el entrenamiento (excluyendo
                            <code>mixed</code>).
                            Esta decisión busca maximizar señal léxica útil para modelos basados en bolsa de palabras.
                        </li>
                        <li><strong>DeBERTa‑v3‑base (fine‑tuning):</strong> preprocesamiento <em>ligero y no
                                destructivo</em>
                            (normalizar comillas/guiones, eliminar duplicados, sin stemming ni stopwords), preservando los
                            matices poéticos para que el tokenizador subword capture semántica contextual. Se excluye la
                            clase
                            <code>mixed</code> en todos los splits.
                        </li>
                    </ul>
                    <div class="highlight-box">
                        <strong>Justificación de la elección:</strong> en enfoques clásicos conviene estandarizar la forma
                        superficial de las palabras para que la frecuencia sea informativa; en transformadores, el
                        tokenizador y el contexto atenúan la necesidad de limpiar agresivamente, y remover stopwords puede
                        incluso eliminar matices útiles en poesía.
                    </div>

                    <div class="section-subtitle">Modelos de IA empleados</div>
                    <ul style="line-height: 2;">
                        <li><strong>Multinomial Naive Bayes:</strong> probabilístico, rápido y efectivo con conteos de
                            tokens; se ajustó y luego se <em>tuneó</em> el hiperparámetro <code>alpha</code> vía
                            <code>GridSearchCV</code>.
                        </li>
                        <li><strong>Regresión Logística:</strong> baseline lineal con <code>class_weight='balanced'</code>
                            para mitigar desbalance sin sobremuestreo.</li>
                        <li><strong>DeBERTa‑v3‑base:</strong> transformador preentrenado ajustado finamente con técnicas de
                            regularización (Focal Loss, label smoothing, early stopping) y optimizado por F1‑macro.</li>
                    </ul>

                    <div class="section-subtitle">Herramientas y tecnologías</div>
                    <div class="specifications">
                        <div class="spec-card"><strong>Frameworks</strong> PyTorch, Hugging Face Transformers</div>
                        <div class="spec-card"><strong>ML clásico</strong> scikit‑learn, imbalanced‑learn</div>
                        <div class="spec-card"><strong>Gestión de datos</strong> pandas, numpy, datasets (HF)</div>
                        <div class="spec-card"><strong>Gráficos</strong> matplotlib, seaborn</div>
                        <div class="spec-card"><strong>NLP utilitario</strong> NLTK</div>
                        <div class="spec-card"><strong>I/O</strong> fastparquet/pyarrow (URIs hf://)</div>
                    </div>
                </div>
            </div>

            <!-- PAGE 3: Data Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📊 3. Datos</div>

                    <div class="section-subtitle">Descripción del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        <strong>Fuente:</strong> Para este proyecto se utilizó el dataset <em>Poem Sentiment</em> del
                        repositorio de Google Research,
                        disponible en Hugging Face (hf://datasets/google-research-datasets/poem_sentiment). Este
                        conjunto de datos consiste en versos
                        de poemas extraídos de Project Gutenberg, etiquetados según el sentimiento que transmiten.
                    </p>

                    <div class="spec-card">
                        <strong>📈 Características principales:</strong>
                        <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                            <li><strong>Número total de ejemplos:</strong> 1,101 versos</li>
                            <li><strong>Idioma:</strong> Textos en inglés</li>
                            <li><strong>Tamaño:</strong> Dataset pequeño, puede dificultar la generalización al entrenar
                                modelos complejos desde cero. No obstante, con transformadores preentrenados y técnicas
                                de regularización (early stopping, class weights/Focal Loss, label smoothing) es posible
                                lograr buen desempeño.</li>
                            <li><strong>Balanceo de Clases:</strong> Se aplicaron técnicas de balanceo: SMOTE en modelos
                                clásicos (Naive Bayes, Logistic Regression) y Focal Loss con class weights en DeBERTa
                                para mitigar el desbalance inherente del dataset.</li>
                        </ul>
                    </div>

                    <div class="section-subtitle">Clases de Sentimiento</div>
                    <ul style="line-height: 2;">
                        <li><strong>Positivo:</strong> Versos con emociones positivas</li>
                        <li><strong>Negativo:</strong> Versos con emociones negativas</li>
                        <li><strong>Mixto:</strong> Versos que combinan emociones positivas y negativas</li>
                        <li><strong>No impacto:</strong> Versos que no presentan un sentimiento claro</li>
                    </ul>

                    <div class="section-subtitle">Columnas del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        Este conjunto de datos consta de versos de poemas extraídos de Project Gutenberg, etiquetados
                        según el sentimiento que transmiten.
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>verse_text:</strong> Contiene el texto del verso del poema</li>
                        <li><strong>label:</strong> Indica la categoría de sentimiento del verso</li>
                    </ul>

                    <div class="section-subtitle">Exploración Inicial</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        En la fase de exploración, no se encontraron valores nulos. El histograma de las longitudes por
                        clase se encuentra representado en la Ilustración 2.
                    </p>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="verse_lengths_distribution.png"
                            alt="Gráfico de Distribución de Longitudes de Versos por Clase"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Ilustración 1. Distribución de longitudes por clase</p>
                    </div>

                    <p style="text-align: justify; line-height: 1.5; margin-top: 20px;">
                        La figura muestra la distribución de la longitud de los versos según su sentimiento. Se observa
                        que la mayoría de los versos tienen entre 30 y 50 palabras,
                        con predominancia de la clase no impact. Las clases minoritarias (mixed, positivo, negativo)
                        están menos representadas, lo que refuerza el desbalance del dataset.
                        Esta distribución sugiere que los modelos podrían aprender primero la clase mayoritaria y que
                        los ejemplos muy largos son poco frecuentes y podrían considerarse outliers.
                    </p>

                    <div class="section-subtitle">División de Datos</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Conjunto</th>
                                <th>Número de Ejemplos</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Entrenamiento</strong></td>
                                <td>892 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Validación</strong></td>
                                <td>105 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Test</strong></td>
                                <td>104 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Total</strong></td>
                                <td>1,101 ejemplos</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="section-subtitle">Distribución de Clases (Entrenamiento Original)</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                                <th>Porcentaje</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>555</td>
                                <td>62.2%</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>155</td>
                                <td>17.4%</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>133</td>
                                <td>14.9%</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>49</td>
                                <td>5.5%</td>
                            </tr>
                        </tbody>
                    </table>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="sentiment_distribution.png"
                            alt="Gráfico de Distribución de Clases en Datos de Entrenamiento"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Figura 1: Distribución de Sentimientos en los Datos de Entrenamiento Original</p>
                    </div>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <strong>⚠️ Problema de Desbalance:</strong> La mayoría de los versos pertenecen a la clase "No
                        impacto",
                        mientras que la clase "Mixto" tiene muy pocos ejemplos. Este desbalance puede generar:
                        <ul style="margin-left: 20px; margin-top: 10px; margin-bottom: 10px; line-height: 1.8;">
                            <li><strong>Bias hacia la clase mayoritaria:</strong> Los modelos tienden a predecir con
                                mayor frecuencia la clase predominante (No impacto), lo que puede inflar el accuracy
                                aparente, pero reducir la capacidad de identificar correctamente las clases
                                minoritarias.</li>
                            <li><strong>Problemas de generalización en modelos complejos:</strong> Las redes
                                neuronales pueden sobreajustar fácilmente a la clase mayoritaria, especialmente cuando
                                el dataset es pequeño. En este caso, modelos complejos pueden aprender patrones sesgados
                                en lugar de representaciones robustas de todas las clases.</li>
                            <li><strong>Métricas poco confiables para clases minoritarias:</strong> Las métricas de
                                rendimiento pueden ser engañosas si se interpretan sin considerar el desbalance.</li>
                        </ul>
                        <p style="margin-top: 12px; text-align: justify; line-height: 1.6; font-size: 11pt;">
                            Dado el tamaño reducido y el desbalance, estos conjuntos pueden no ser representativos de la
                            distribución real de clases.
                            Esto significa que las métricas de evaluación (accuracy, F1, recall, precision) pueden ser
                            ruidosas y poco confiables,
                            especialmente para las clases minoritarias como Mixto y Positivo.
                        </p>
                    </div>

                    <div class="section-subtitle">Estrategias de Mitigación</div>
                    <ul style="line-height: 2;">
                        <li><strong>SMOTE (Modelos Clásicos):</strong> Aplicada en el entrenamiento de Naive Bayes y
                            Logistic Regression para sobremuestreo sintético y balanceo de clases minoritarias</li>
                        <li><strong>Focal Loss + Class weights (DeBERTa):</strong> Pesos por clase en el transformador
                            (DeBERTa) mediante Focal Loss (γ=1.5) + class weights para penalizar predicciones
                            incorrectas de clases minoritarias y mejorar generalización</li>
                    </ul>

                    <div class="section-subtitle">Distribución de Clases (Post Balanceo con SMOTE)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        <strong>Modelos Clásicos (Naive Bayes, Logistic Regression):</strong> Se aplicó SMOTE en el
                        conjunto de entrenamiento para generar muestras sintéticas de clases minoritarias y lograr
                        balanceo perfecto entre las tres clases.
                    </p>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Técnica</th>
                                <th>Negativo</th>
                                <th>Positivo</th>
                                <th>No impacto</th>
                                <th>Total</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr style="background: #fff3cd;">
                                <td><strong>SMOTE (Entrenamiento) </strong></td>
                                <td>555</td>
                                <td>555</td>
                                <td>555</td>
                                <td>1,665</td>
                            </tr>
                        </tbody>
                    </table>
                    <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                        SMOTE generó 1,665 muestras de entrenamiento perfectamente balanceadas (555 por clase) a partir
                        de 843 originales.</p>

                    <div style="height: 20px;"></div>

                    <div class="section-subtitle">Exclusión de la clase "Mixta" (Mixed) en Evaluación</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        La clase "mixed" (label=3) fue excluida de todos los modelos tanto en entrenamiento como en
                        evaluación.
                        Esta decisión se basa en tres razones fundamentales:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Distribución minoritaria:</strong> La clase "mixed" representa solo 5.5% del set de
                            entrenamiento,
                            lo que la hace altamente minoritaria y dificulta el entrenamiento robusto.</li>
                        <li><strong>Ambigüedad conceptual:</strong> Esta clase agrupa versos con sentimientos
                            contradictorios o ambiguos,
                            donde coexisten emociones positivas y negativas simultáneamente. Para una aplicación
                            práctica de análisis
                            de sentimientos en poesía, es más útil clasificar en tres categorías bien definidas
                            (negativo, positivo, sin impacto).</li>
                        <li><strong>Mejora de robustez del modelo:</strong> Excluir la clase "mixed" permite un problema
                            de clasificación
                            más claro y robusto, centrado en sentimientos claramente expresados, lo que mejora
                            significativamente las
                            métricas de desempeño y la interpretabilidad de los resultados.</li>
                    </ul>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Por lo tanto, todos los resultados reportados (F1-macro, exactitud, matrices de confusión, etc.)
                        se calculan
                        considerando únicamente las tres clases principales: negativo, positivo y sin impacto.
                    </p>
                </div>
            </div>

            <!-- PAGE 4: Preprocesamiento -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📝 4. Preprocesamiento</div>

                    <div class="section-subtitle">Preprocesamiento para Modelos Clásicos (NB y Regresión Logística)
                    </div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El preprocesamiento aplicado ha sido cuidadosamente diseñado para optimizar la clasificación de
                        sentimientos en poesía inglesa antigua, equilibrando la limpieza textual con
                        la preservación de características semánticas relevantes. A diferencia de los enfoques estándar
                        que aplican normalización agresiva, nuestra estrategia reconoce que el lenguaje poético arcaico
                        contiene matices significativos para la detección de sentimientos.
                    </p>

                    <ul style="line-height: 2;">
                        <li><strong>Preservación del contexto poético:</strong> El enfoque mantiene palabras arcaicas y
                            poéticas (como "doth", "hath", "ne'er") que, aunque no sean comunes en el inglés moderno,
                            poseen un alto valor predictivo para la clasificación de sentimientos en textos históricos.
                            Estas palabras no se eliminan como stopwords, ya que a menudo aparecen en contextos emotivos
                            específicos que el modelo necesita capturar.</li>

                        <li><strong>Normalización de contracciones antiguas:</strong> Se expandieron contracciones
                            arcaicas ("'twas" → "it was", "o'er" → "over") a palabras completas para mejorar la
                            representación vectorial sin perder información léxica. Esta técnica aumenta la consistencia
                            del vocabulario sin introducir ambigüedad, permitiendo que el vectorizador de conteo
                            (CountVectorizer) capte patrones más robustos.</li>

                        <li><strong>Limpieza moderada de puntuación:</strong> Se normalizó la puntuación de manera
                            selectiva, removiendo caracteres especiales y de formato histórico, pero manteniendo la
                            estructura de oraciones. Esta aproximación evita la pérdida de información contextual que
                            podría ser relevante para modelos basados en bolsa de palabras, donde la proximidad léxica
                            importa.</li>

                        <li><strong>Vectorización con CountVectorizer y balanceo SMOTE:</strong> Después del
                            preprocesamiento, se utilizó CountVectorizer con un vocabulario máximo de 10,000 features
                            para capturar términos frecuentes relevantes. Aplicamos SMOTE solo en el conjunto de
                            entrenamiento para corregir el desbalance de clases de forma sintética, evitando sobreajuste
                            al no modificar conjuntos de validación y prueba.</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este diseño integrado maximiza la capacidad del modelo para distinguir entre sentimientos en
                        textos antiguos, priorizando la precisión sobre la simplicidad de preprocesamiento.
                    </p>

                    <div class="section-subtitle">Implementación: Función preprocess_poetry_text</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        La siguiente función implementa esta estrategia de preprocesamiento optimizada para poesía:
                    </p>

                    <div class="spec-card">
                        <strong>📝 Ejemplos de Preprocesamiento:</strong>
                        <div
                            style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                            <p><strong>Original (0):</strong> "with pale blue berries. in these peaceful shades--"</p>
                            <p><strong>Procesado:</strong> "with pale blue berries in these peaceful shades"</p>
                            <hr style="border: none; border-top: 1px solid #ddd; margin: 10px 0;">
                            <p><strong>Original (1):</strong> "it flows so long as falls the rain,"</p>
                            <p><strong>Procesado:</strong> "it flows so long as falls the rain"</p>
                            <hr style="border: none; border-top: 1px solid #ddd; margin: 10px 0;">
                            <p><strong>Original (2):</strong> "and that is why, the lonesome day,"</p>
                            <p><strong>Procesado:</strong> "and that is why the lonesome day"</p>
                        </div>
                    </div>

                    <div style="height: 20px; clear: both;"></div>



                    <div class="section-subtitle">Preprocesamiento en DeBERTa-v3-base</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        El preprocesamiento aplicado en DeBERTa-v3-base es <strong>ligero y no destructivo</strong>,
                        diseñado específicamente para preservar las características estilísticas y semánticas de la
                        poesía:
                    </p>

                    <ul style="line-height: 2;">
                        <li><strong>Operaciones realizadas:</strong>
                            <ul style="margin-top: 8px; margin-left: 20px;">
                                <li>Normalización de comillas y guiones: convierte variantes Unicode (", —, –) a ASCII
                                    estándar para evitar tokens raros</li>
                                <li>Colapso de espacios múltiples y recorte de espacios al inicio/final</li>
                                <li>Eliminación de versos duplicados por coincidencia exacta</li>
                            </ul>
                        </li>
                        <li><strong>Decisiones importantes:</strong>
                            <ul style="margin-top: 8px; margin-left: 20px;">
                                <li><strong>Sin stemming ni stopwords:</strong> En poesía, la morfología completa y
                                    palabras aparentemente "vacías" portan matices de sentimiento. Removerlas degrada la
                                    señal</li>
                                <li><strong>Sin lowercasing forzado:</strong> El tokenizador subword (BPE) de DeBERTa
                                    maneja mayúsculas; además, en poesía las mayúsculas pueden tener valor estilístico
                                </li>
                            </ul>
                        </li>
                    </ul>

                    <div class="section-subtitle">Técnicas de Balanceo de Clases</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Dado el desbalance del dataset,
                        se aplicaron técnicas específicas de balanceo según el tipo de modelo:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Selección de clases minoritarias:</strong> Se identifican las clases que tienen
                            pocas muestras (por ejemplo: “negative”, “positive” y “mixed”).</li>
                        <li><strong>SMOTE (Synthetic Minority Over-sampling Technique):</strong> Para los modelos
                            clásicos (Multinomial Naive Bayes y Regresión Logística), se aplicó SMOTE exclusivamente en
                            el conjunto de entrenamiento para generar sintéticamente nuevas muestras de las clases
                            minoritarias. Esto corrige el desbalance sin perder información, permitiendo que los modelos
                            aprendan a distinguir mejor entre sentimientos.</li>
                        <li><strong>Focal Loss y Class Weights:</strong> Para DeBERTa-v3-base, se utilizó Focal Loss
                            combinada con pesos de clases para manejar el desbalance. Este enfoque es más eficaz en
                            redes neuronales profundas, ya que el Focal Loss penaliza más los ejemplos mal clasificados
                            de las clases minoritarias.</li>
                        <li><strong>Preservación de sets de validación y prueba:</strong> Tanto SMOTE como los pesos de
                            clase se aplicaron únicamente al conjunto de entrenamiento. Los conjuntos de validación y
                            prueba mantuvieron su distribución original para garantizar evaluación realista de la
                            capacidad de generalización del modelo.</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este enfoque diferenciado permite optimizar cada modelo de acuerdo a sus características,
                        mejorando el desempeño sin comprometer la evaluación independiente.
                    </p>

                </div>

                <!-- PAGE 5: Text Representation -->
                <div class="page-section">


                    <!-- PAGE 5.1: Implementación -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">🛠️ Implementación</div>

                            <div class="section-subtitle">Pipeline de desarrollo</div>
                            <div class="structure-list">
                                <div class="structure-item">
                                    <h4>Baselines clásicos (NB / Reg. Logística)</h4>
                                    <div class="structure-description">
                                        <ol>
                                            <li>Exploración y división de datos (train/val/test) desde Hugging Face</li>
                                            <li>Preprocesamiento optimizado para poesía (expansión de contracciones,
                                                limpieza suave)</li>
                                            <li>Vectorización con <code>CountVectorizer(max_features=10000)</code></li>
                                            <li>Exclusión de clase <code>mixed</code> y balanceo con <code>SMOTE</code>
                                                (solo train)</li>
                                            <li>Entrenamiento de <code>MultinomialNB</code> y
                                                <code>LogisticRegression</code>
                                            </li>
                                            <li>Ajuste de <code>alpha</code> (NB) con <code>GridSearchCV</code></li>
                                            <li>Evaluación macro‑F1 (sin clase <code>mixed</code>) y matrices de
                                                confusión</li>
                                        </ol>
                                    </div>
                                </div>
                                <div class="structure-item">
                                    <h4>DeBERTa‑v3‑base (fine‑tuning)</h4>
                                    <div class="structure-description">
                                        <ol>
                                            <li>Preprocesamiento ligero (normalizar comillas/guiones, deduplicar)</li>
                                            <li>Exclusión de clase <code>mixed</code> en todos los splits</li>
                                            <li>Tokenización subword (max_len=128) y creación de datasets de HF</li>
                                            <li>Hiperparámetros: lr=2e‑5, batch=16, epochs=6, warmup=0.05</li>
                                            <li>Regularización: Focal Loss (γ=1.5) + class weights, label smoothing=0.1
                                            </li>
                                            <li>Entrenamiento con Trainer optimizando F1‑macro + early stopping</li>
                                            <li>Evaluación en validación y test; análisis por clase y matriz de
                                                confusión</li>
                                        </ol>
                                    </div>
                                </div>
                            </div>

                            <div class="section-subtitle" style="margin-top: 25px;">Optimización y ajustes
                                (hiperparámetros)</div>
                            <div class="specifications">
                                <div class="spec-card">
                                    <strong>MultinomialNB</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li><code>GridSearchCV</code> sobre
                                            <code>alpha ∈ {0.01, 0.1, 0.5, 1.0, 5.0, 10.0}</code>
                                        </li>
                                        <li><em>Scoring</em>: F1‑macro, CV=5</li>
                                    </ul>
                                </div>
                                <div class="spec-card">
                                    <strong>Regresión Logística</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li><code>class_weight='balanced'</code>, <code>max_iter=2000</code>,
                                            <code>solver='liblinear'</code>
                                        </li>
                                    </ul>
                                </div>
                                <div class="spec-card">
                                    <strong>DeBERTa‑v3‑base</strong>
                                    <ul style="margin-top: 8px; padding-left: 20px;">
                                        <li>Focal Loss (γ=1.5) + <em>class weights</em>, <em>label smoothing</em>=0.1
                                        </li>
                                        <li>lr=2e‑5, batch=16, epochs=6, warmup_ratio=0.05, early stopping (patience=3)
                                        </li>
                                        <li>Métrica objetivo: F1‑macro</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- PAGE 6: Models -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">🤖 6. Modelos Implementados</div>

                            <div class="section-subtitle">5.1 Regresión Logística</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                La regresión logística fue seleccionada por su capacidad para manejar eficazmente
                                representaciones vectorizadas
                                del texto. Este modelo aprende a estimar la probabilidad de pertenencia a cada clase
                                mediante una combinación
                                lineal de características, lo cual resulta apropiado en problemas de análisis de texto
                                donde la presencia
                                o frecuencia de ciertas palabras suele correlacionarse directamente con el sentimiento.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Permite incorporar pesos para clases minoritarias (class weights)</li>
                                    <li>Naturaleza probabilística facilita interpretar confianza</li>
                                    <li>Bajo costo computacional y estable</li>
                                    <li>Excelente baseline para comparar con modelos más complejos</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>
                            <div class="section-subtitle" style="border-left: none; padding-left: 0;">Configuración:
                                LogisticRegression</div>
                            <pre class="code-block"><code>lr_model = LogisticRegression(
    random_state=SEED,
    max_iter=2000,
    class_weight='balanced',
    C=1.0,
    solver='liblinear'
)</code></pre>

                            <div class="section-subtitle">5.2 Naive Bayes Multinomial</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                El modelo Multinomial Naive Bayes se utiliza, en este caso, con ajuste de
                                hiperparámetros mediante
                                búsqueda en cuadrícula (GridSearchCV) para optimizar el parámetro de suavizado alpha.
                                Este enfoque probabilístico calcula probabilidades condicionales de palabras para cada
                                clase, permitiendo una clasificación eficiente incluso con vocabularios grandes. La
                                búsqueda exhaustiva de alpha mediante validación cruzada de 5 folds maximiza el F1-score
                                macro, encontrando el balance óptimo entre sesgo y varianza del modelo.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Entrenamiento rápido y eficiente incluso con vocabularios grandes</li>
                                    <li>Optimización automática de hiperparámetros mediante GridSearchCV</li>
                                    <li>Probabilidades interpretables a nivel palabra-clase</li>
                                    <li>Rendimiento equilibrado en todas las clases con datos balanceados</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>
                            <div class="section-subtitle" style="border-left: none; padding-left: 0;">Configuración:
                                GridSearchCV</div>
                            <pre class="code-block"><code>grid_search = GridSearchCV(
    estimator=MultinomialNB(),
    param_grid=param_grid,
    scoring='f1_macro',
    cv=5,
    n_jobs=-1,
    verbose=1
)</code></pre>

                            <div class="section-subtitle">5.3 DeBERTa‑v3‑base (fine‑tuning)</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                Los transformadores preentrenados como <strong>DeBERTa‑v3‑base</strong> capturan
                                relaciones contextuales y semántica a nivel sub‑palabra mediante auto‑atención.
                                En este trabajo se realizó <em>fine‑tuning</em> para el dataset Poem
                                Sentiment (excluyendo la clase <code>mixed</code>), optimizando la métrica
                                <strong>F1‑macro</strong> y usando técnicas de regularización para manejar el
                                desbalance y evitar sobreajuste.
                            </p>
                            <div class="spec-card">
                                <strong>Técnicas aplicadas</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Tokenización subword (max_len=128)</li>
                                    <li>Focal Loss (γ = 1.5) + <em>class weights</em></li>
                                    <li><em>Label smoothing</em> = 0.1</li>
                                    <li><em>Early stopping</em> (patience = 3)</li>
                                    <li>Optimización con Hugging Face Trainer por F1‑macro</li>
                                </ul>
                            </div>

                            <div class="spec-card" style="margin-top: 15px;">
                                <strong>Ventajas</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Captura dependencias largas y matices poéticos</li>
                                    <li>Robusto ante variaciones léxicas y de estilo</li>
                                    <li>Rendimiento superior en dominios de texto fino</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>
                            <div class="section-subtitle" style="border-left: none; padding-left: 0;">Configuración: TrainingArguments</div>
                            <pre class="code-block"><code>
TrainingArguments(
    output_dir=f"{config.OUTPUT_DIR}/fold_{fold}",
    logging_dir=f"{config.LOGGING_DIR}/fold_{fold}",
    num_train_epochs=config.NUM_EPOCHS,
    per_device_train_batch_size=config.BATCH_SIZE,
    per_device_eval_batch_size=config.BATCH_SIZE * 2,
    learning_rate=config.LEARNING_RATE,
    weight_decay=config.WEIGHT_DECAY,
    warmup_ratio=config.WARMUP_RATIO,
    lr_scheduler_type="cosine",
    save_strategy="epoch",
    evaluation_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="f1_macro",
    greater_is_better=True,
    save_total_limit=2,
    logging_steps=50,
    report_to="none"
)</code></pre>
                            <p style="text-align: justify; line-height: 1.8; margin-top: 15px;">
                                Los argumentos de entrenamiento configuran el proceso de fine-tuning de DeBERTa. Se utiliza un scheduler coseno con warmup del 5%, early stopping basado en F1-macro, y se guardan solo los 2 mejores checkpoints para optimizar memoria.
                            </p>

                            

                        </div>

                        <!-- PAGE 7: Metrics and Training -->
                        <div class="page-section">
                            <div class="section">
                                <div class="section-title">📊 7. Validación y Métricas</div>
                                <div class="section-subtitle">Carga del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    El dataset se obtuvo desde el repositorio de Hugging Face utilizando pandas. Los
                                    archivos están disponibles en formato Parquet
                                    y se pueden cargar directamente usando la siguiente configuración:
                                </p>

                                <div
                                    style="background: #f8f9fa; padding: 20px; border-radius: 4px; margin: 20px 0; overflow-x: auto;">
                                    <code
                                        style="background: #f0f0f0; padding: 15px; border-radius: 4px; font-family: 'Courier New', monospace; display: block;">
                                        import pandas as pd<br>
                                        <br>
                                        splits = {<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'train': 'data/train-00000-of-00001.parquet',<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'validation': 'data/validation-00000-of-00001.parquet',<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;'test': 'data/test-00000-of-00001.parquet'<br>
                                        }<br>
                                        <br>
                                        df = pd.read_parquet(<br>
                                        &nbsp;&nbsp;&nbsp;&nbsp;"hf://datasets/google-research-datasets/poem_sentiment/" + splits["train"]<br>
                                        )
                                    </code>
                                </div>

                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    <strong>URL del Dataset:</strong> <a
                                        href="https://huggingface.co/datasets/google-research-datasets/poem_sentiment/viewer"
                                        target="_blank"
                                        style="color: #C41E3A; text-decoration: none;">https://huggingface.co/datasets/google-research-datasets/poem_sentiment/viewer</a>
                                </p>

                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Este método permite cargar directamente los splits de entrenamiento, validación y
                                    prueba en DataFrames de pandas,
                                    facilitando el preprocesamiento y manipulación de los datos para el análisis
                                    posterior.
                                </p>
                                <div class="section-subtitle">División del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utilizó la división estándar del dataset proporcionada por Hugging Face para
                                    garantizar coherencia
                                    y reproducibilidad de los resultados.
                                </p>

                                <div class="section-subtitle">Métricas de Evaluación</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utilizaron las siguientes métricas para evaluar el desempeño de los modelos:
                                </p>
                                <ul style="line-height: 2;">
                                    <li><strong>Accuracy:</strong> Proporción de predicciones correctas</li>
                                    <li><strong>Precision (macro avg):</strong> Promedio de precisión por clase</li>
                                    <li><strong>Recall (macro avg):</strong> Promedio de recall por clase</li>
                                    <li><strong>F1 (macro avg):</strong> Media armónica de precision y recall</li>
                                </ul>
                               

                            </div>

                            <!-- PAGE 8: Results -->
                            <div class="page-section">
                                <div class="section">
                                    <div class="section-title">📈 8. Resultados</div>

                                    <div class="section-subtitle">Resultados de Baselines Clásicos</div>

                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt;">
                                        <strong>Regresión Logística</strong> con class_weight='balanced'
                                    </p>
                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt;">
                                        Validación: F1‑macro = 0.4310
                                    </p>
                                    
                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="margin-bottom: 10px;"><strong>Validación - Classification Report:</strong></div>
                                        <div style="white-space: pre; text-align: left;">              precision    recall  f1-score   support

    negativo       0.50      0.21      0.30        19
    positivo       0.50      0.12      0.19        17
 sin_impacto       0.69      0.93      0.79        69

    accuracy                           0.67       105
   macro avg       0.56      0.42      0.43       105
weighted avg       0.62      0.67      0.60       105</div>
                                        
                                        <div style="margin-top: 15px; margin-bottom: 10px;"><strong>Test - Classification Report:</strong></div>
                                        <div style="white-space: pre; text-align: left;">              precision    recall  f1-score   support

    negative       0.44      0.21      0.29        19
    positive       0.75      0.19      0.30        16
   no_impact       0.71      0.94      0.81        69

    accuracy                           0.69       104
   macro avg       0.64      0.45      0.47       104
weighted avg       0.67      0.69      0.64       104</div>
                                    </div>
                                    <div style="height: 20px; clear: both;"></div>
                                    <div style="text-align: center; margin: 30px 0;">
                                        <img src="mc_rl.png" alt="Matriz de Confusión - Regresión Logística"
                                            style="max-width: 55%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                        <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                            Ilustración. Matriz de Confusión - Regresión Logística</p>
                                    </div>
                                    <div style="height: 20px; clear: both;"></div>

                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt; margin-top: 30px;">
                                        <strong>Multinomial Naive Bayes</strong> optimizado con GridSearchCV
                                    </p>
                                    
                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt;">
                                        Test: F1‑macro = 0.5625
                                    </p>
                                    
                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="margin-bottom: 10px;"><strong>Test - Classification Report (Ajustado):</strong></div>
                                        <div style="white-space: pre; text-align: left;">              precision    recall  f1-score   support

    negativo       0.46      0.58      0.51        19
    positivo       0.50      0.31      0.38        16
 sin_impacto       0.79      0.80      0.79        69

    accuracy                           0.68       104
   macro avg       0.58      0.56      0.56       104
weighted avg       0.68      0.68      0.68       104</div>
                                    </div>

                                    <div style="text-align: center; margin: 30px 0;">
                                        <img src="nb_m.png" alt="Matriz de Confusión - Multinomial Naive Bayes Optimizado"
                                            style="max-width: 55%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                        <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                            Ilustración. Matriz de Confusión - Multinomial Naive Bayes Optimizado</p>
                                    </div>

                                    

                                    <div class="section-subtitle">Resultados principales (DeBERTa‑v3‑base)</div>

                                    <table class="format-table">
                                        <thead>
                                            <tr>
                                                <th>Conjunto</th>
                                                <th>Accuracy</th>
                                                <th>F1‑Macro</th>
                                                <th>F1‑Weighted</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <td><strong>Validación</strong></td>
                                                <td>0.9143</td>
                                                <td><strong>0.8903</strong></td>
                                                <td>0.9132</td>
                                            </tr>
                                            <tr>
                                                <td><strong>Test</strong></td>
                                                <td>0.9135</td>
                                                <td><strong>0.8909</strong></td>
                                                <td>0.9136</td>
                                            </tr>
                                        </tbody>
                                    </table>



                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px; font-size: 11pt; margin-top: 20px; color: #444;">
                                        <strong>ANALIZANDO DESBALANCE Y CALCULANDO CLASS WEIGHTS...</strong>
                                    </p>
                                    
                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">Class weights (for Trainer): [1.8129033 2.112782  0.5063063]
  • Negative (0): 1.813
  • Positive (1): 2.113
  • No_impact (2): 0.506</div>
                                    </div>

                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px; font-size: 11pt; margin-top: 25px; color: #444;">
                                        <strong>Progresión de entrenamiento (6 épocas):</strong>
                                    </p>

                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 9pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">[318/318 06:05, Epoch 6/6]

Epoch	Training Loss	Validation Loss	Accuracy	F1 Macro	F1 Weighted
1	0.687600	0.627334	0.219048	0.219373	0.112739
2	0.415900	0.277040	0.695238	0.677715	0.704948
3	0.168000	0.238712	0.904762	0.879654	0.905809
4	0.057400	0.295952	0.885714	0.855089	0.889655
5	0.033500	0.272913	0.904762	0.878603	0.903656
6	0.014500	0.268912	0.914286	0.890276	0.913175</div>
                                    </div>

                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 25px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">RESULTADOS FINALES EN VALIDATION SET:
  Accuracy:    0.9143
  F1-Macro:    0.8903
  F1-Weighted: 0.9132

RESULTADOS FINALES EN TEST SET:
  Accuracy:    0.9135
  F1-Macro:    0.8909
  F1-Weighted: 0.9136</div>
                                    </div>


                                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px; font-size: 11pt; margin-top: 25px; color: #444;">
                                        <strong>Reporte detallado de clasificación (Test Set):</strong>
                                    </p>

                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0; font-size: 10pt; line-height: 1.6; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">CLASSIFICATION REPORT (Test Set):
              precision    recall  f1-score   support

    negative       0.86      1.00      0.93        19
    positive       0.81      0.81      0.81        16
   no_impact       0.95      0.91      0.93        69

    accuracy                           0.91       104
   macro avg       0.88      0.91      0.89       104
weighted avg       0.92      0.91      0.91       104</div>
                                    </div>

                                    <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 25px 0; font-size: 10pt; line-height: 1.8; font-family: 'Courier New', monospace; overflow-x: auto;">
                                        <div style="white-space: pre; text-align: left;">FINE-TUNING DEBERTA-V3-BASE COMPLETADO:

 TÉCNICAS APLICADAS:
   • Modelo: DeBERTa-v3-base (Fine-tuned)
   • Preprocesamiento: Eliminación duplicados, normalización comillas/guiones, 
     exclusión clase 'mixed'
   • Tokenización: max_len=128
   • Pérdida: Focal Loss (γ=1.5) con class weights
   • Regularización: Label smoothing 0.1
   • Entrenamiento: Hugging Face Trainer, optimizado por F1-macro
   • Validación: Early stopping (patience=3)</div>
                                    </div>

                                    <div style="text-align: center; margin: 30px 0;">
                                        <img src="deberta.png" alt="Matriz de Confusión - DeBERTa-v3-base"
                                            style="max-width: 60%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                        <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                            Ilustración. Matriz de Confusión - DeBERTa-v3-base (Conjunto de Test)</p>
                                    </div>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #e8f5e9 0%, #ffffff 100%); border-left-color: #2e7d32; margin-top: 30px;">
                                        <strong>Objetivo cumplido (ALCANZADO):</strong> Se alcanzó <strong>F1‑macro = 0.8909</strong> en el conjunto de Test, 
                                        superando la meta de <strong>F1‑macro ≥ 0.85</strong>. DeBERTa‑v3‑base demostró ser significativamente superior 
                                        a los baselines clásicos (Regresión Logística: 0.4661 | Multinomial NB optimizado: 0.5625), justificando 
                                        el uso de transformadores para la tarea de análisis de sentimiento en poesía.
                                    </div>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; margin-top: 30px;">
                                        <strong>Comparativa con baselines clásicos:</strong> Los enfoques con
                                        CountVectorizer (MultinomialNB / Regresión Logística)
                                        se usaron como líneas base sólidas, pero <em>no alcanzaron</em> el desempeño del
                                        transformador en F1‑macro. La elección de
                                        DeBERTa se justifica por su capacidad para capturar matices semánticos y de
                                        estilo propios de la poesía.
                                    </div>
                                </div>

                                <!-- PAGE 9: Discussion -->
                                <div class="page-section">
                                    <div class="section">
                                        <div class="section-title">💡 9. Discusión</div>

                                        <div class="section-subtitle">¿Qué se observa en los resultados?</div>
                                        <ul style="line-height: 2;">
                                            <li><strong>DeBERTa‑v3‑base</strong> alcanza F1‑macro ≈ 0.891 en Test,
                                                superando ampliamente a los baselines clásicos.</li>
                                            <li>Por clase (Test): <em>negative</em> logra <strong>recall ≈ 1.00</strong>
                                                (marcadores explícitos); <em>positive</em> es desafiante (F1 ≈ 0.81) porque el 
                                                sentimiento positivo en poesía es sutil y metafórico, frecuentemente confundido con 
                                                <code>no_impact</code> cuando el poeta describe la belleza sin expresar explícitamente 
                                                alegría. Ejemplo: un verso como <em>"The golden light upon the hills"</em> expresa belleza 
                                                (sentimiento positivo), pero el modelo puede clasificarlo como neutro por la ausencia de 
                                                palabras emocionales directas; <em>no_impact</em> es fácil de detectar (precisión ≈ 0.95, recall ≈ 0.91).
                                            </li>
                                            <li>La combinación de <em>class weights</em> + Focal Loss + label smoothing
                                                favorece el balance entre clases bajo desbalance.</li>
                                        </ul>

                                        <div class="section-subtitle">¿Fue exitoso el entrenamiento?</div>
                                        <p style="text-align: justify; line-height: 1.8;">
                                            Sí. La métrica objetivo (<strong>F1‑macro ≥ 0.85</strong>) se cumplió con
                                            margen. Las curvas por época
                                            (con early stopping) y el uso de regularización indican un proceso estable y
                                            reproducible.
                                        </p>

                                        <div class="section-subtitle">Escenarios de uso</div>
                                        <ul style="line-height: 2;">
                                            <li>Analítica de colecciones poéticas (tendencias afectivas por
                                                autor/época).</li>
                                            <li>Herramientas de apoyo editorial, talleres de escritura y análisis
                                                literario asistido.</li>
                                            
                                        </ul>

                                        <div class="section-subtitle">Limitaciones y mejoras</div>
                                        <ul style="line-height: 2;">
                                            <li><strong>Clase positive:</strong> aún mejorable con
                                                <em>augmentations</em> suaves o calibración de umbrales.
                                            </li>
                                            <li><strong>Generalización:</strong> ampliar datos o realizar
                                                <em>fine‑tuning</em> por dominio/autor:
                                                <ul style="margin-top: 10px; margin-left: 20px; line-height: 1.8;">
                                                    <li><strong>Por dominio:</strong> Poesía medieval vs. moderna vs. romántica (cada estilo tiene características diferentes). Un modelo entrenado específicamente en poesía romántica (con énfasis en descripciones líricas de la naturaleza y emociones) podría capturar mejor los matices del sentimiento positivo en ese contexto, comparado con un modelo general entrenado en múltiples épocas simultáneamente.</li>
                                                    <li><strong>Por autor:</strong> Ajustar el modelo específicamente para William Shakespeare, Emily Dickinson, etc. (cada poeta tiene su propio estilo y forma de expresar sentimientos). Shakespeare tiende a usar lenguaje elaborado y formal; Dickinson emplea puntuación experimental y abstracciones. Un modelo fine-tuned por autor sería más preciso en detectar sentimientos bajo el estilo específico de ese poeta.</li>
                                                </ul>
                                            </li>
                                            <li><strong>Clase mixta (<code>mixed</code>):</strong> reincorporarla demandará
                                                rediseñar pérdidas/umbral o recolectar más muestras.</li>
                                            <li><strong>Recursos:</strong> modelos mayores (DeBERTa‑large,
                                                RoBERTa‑large) y <em>ensembles</em> podrían subir el techo de desempeño
                                                con mayor costo computacional.</li>
                                        </ul>
                                    </div>

                                    <!-- PAGE 10: Conclusions -->
                                    <div class="page-section">
                                        <div class="section">
                                            <div class="section-title">🎯 10. Conclusiones y Trabajo Futuro</div>

                                            <div class="section-subtitle">Conclusiones</div>
                                            <ul style="line-height: 2;">
                                                <li><strong>Objetivo cumplido:</strong> se alcanzó F1‑macro ≥ 0.85 con
                                                    DeBERTa‑v3‑base (F1‑macro Test ≈ 0.8909).</li>
                                                <li>La <strong>elección de preprocesamiento</strong> diferenciado fue
                                                    clave: limpieza ligera para el transformador y normalización léxica
                                                    + CountVectorizer para baselines.</li>
                                                <li>Los <strong>baselines clásicos</strong> sirvieron como referencia y
                                                    análisis de sensibilidad, pero el transformador entendió mejor los
                                                    detalles y sutilezas del lenguaje poético.</li>
                                                <li><strong>Impacto profesional:</strong> este proyecto consolida el
                                                    manejo de pipelines de NLP modernos (Transformers) y comparativos
                                                    clásicos, útil para prototipado rápido y despliegue en analítica
                                                    textual.</li>
                                            </ul>

                                            <div class="section-subtitle">Trabajo futuro</div>
                                            <ul style="line-height: 2;">
                                                <li>Explorar modelos mayores
                                                    (DeBERTa‑large, RoBERTa).</li>
                                                <li>Mejorar la clase <em>positive</em> con <em>augmentations</em> suaves
                                                    y calibración de umbrales.</li>
                                                <li>Reincorporar la clase <code>mixed</code> con estrategias de pérdida
                                                    (p. ej., <em>asymmetric loss</em>) o más datos.</li>
                                                <li>Preparar un demo de inferencia (FastAPI) en
                                                    producción.</li>
                                            </ul>
                                        </div>

                                        <!-- PAGE 11: References & Footer -->
                                        <div class="page-section">
                                            <div class="section">
                                                <div class="section-title">📚 11. Referencias Bibliográficas</div>

                                                <div
                                                    style="background: #f8f9fa; padding: 25px; border-radius: 8px; line-height: 2;">
                                                    <p>Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011).
                                                        <em>Scikit-learn: Machine Learning in Python</em>.
                                                        Journal of Machine Learning Research, 12, 2825-2830.
                                                    </p>



                                                    <p>Google Research. (s.f.). <em>Poem sentiment</em> [Conjunto de
                                                        datos]. Hugging Face.
                                                        Disponible en:
                                                        https://huggingface.co/datasets/google-research-datasets/poem_sentiment
                                                    </p>

                                                    <p>Goodfellow, I., Bengio, Y., & Courville, A. (2016). <em>Deep
                                                            Learning</em>.
                                                        MIT Press. [Referencia para arquitecturas de redes neuronales]
                                                    </p>

                                                    <p>Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT:
                                                        Pre-training of Deep Bidirectional Transformers
                                                        for Language Understanding. arXiv preprint arXiv:1810.04805.</p>
                                                </div>
                                            </div>

                                            

                                            <div class="page-number"></div>
                                        </div>
                                    </div>
                                </div>
</body>

</html>