<!DOCTYPE html>
<html lang="es">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reporte Final - Curso de Inteligencia Artificial</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        p {
            text-align: justify;
            line-height: 1.5;
            font-size: 12pt;
        }

        body {
            font-family: Arial, sans-serif;
            font-size: 12pt;
            line-height: 1.5;
            color: #333;
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
            overflow: hidden;
            padding: 2.5cm;
        }

        /* Header */
        .header {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        .header p {
            font-size: 1.1em;
            opacity: 0.95;
        }

        .header-logo {
            margin-bottom: 20px;
            font-size: 3em;
        }

        /* Main Content */
        .content {
            padding: 0;
            text-align: justify;
        }

        .section {
            margin-bottom: 50px;
            page-break-inside: avoid;
            page-break-after: auto;
        }

        .section-title {
            font-size: 14pt;
            color: #000;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #C41E3A;
            font-weight: bold;
            page-break-after: avoid;
        }

        .section-subtitle {
            font-size: 12pt;
            color: #000;
            margin-top: 30px;
            margin-bottom: 15px;
            font-weight: bold;
            font-style: italic;
            padding-left: 20px;
            border-left: 4px solid #C41E3A;
        }

        .intro-text {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 8px;
            border-left: 5px solid #C41E3A;
            margin-bottom: 30px;
            line-height: 1.5;
            font-size: 12pt;
            text-align: justify;
        }

        /* Specifications */
        .specifications {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .spec-card {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #C41E3A;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .spec-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(196, 30, 58, 0.2);
        }

        .spec-card strong {
            color: #000;
            display: block;
            margin-bottom: 8px;
        }

        /* Lists */
        ul,
        ol {
            margin-left: 30px;
            margin-bottom: 20px;
        }

        li {
            margin-bottom: 12px;
            line-height: 1.5;
            text-align: justify;
        }

        li strong {
            color: #4A4A4A;
        }

        /* Structure sections */
        .structure-list {
            background: #f8f9fa;
            padding: 30px;
            border-radius: 8px;
            margin: 20px 0;
        }

        .structure-item {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 1px solid #e0e0e0;
        }

        .structure-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }

        .structure-item h4 {
            color: #000;
            font-size: 1.15em;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
        }

        .structure-item h4:before {
            content: "▸";
            margin-right: 10px;
            font-size: 1.3em;
            color: #4A4A4A;
        }

        .structure-description {
            margin-left: 20px;
            color: #666;
            line-height: 1.8;
        }

        /* Rubric */
        .rubric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .rubric-item {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 25px;
            border-radius: 8px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(139, 21, 56, 0.2);
        }

        .rubric-percentage {
            font-size: 2.2em;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .rubric-description {
            font-size: 0.95em;
            opacity: 0.95;
        }

        /* Deliverables */
        .deliverables {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            padding: 30px;
            border-radius: 8px;
            border: 2px solid #C41E3A;
        }

        .deliverable-item {
            display: flex;
            align-items: center;
            margin-bottom: 15px;
            font-size: 1.05em;
        }

        .deliverable-item:last-child {
            margin-bottom: 0;
        }

        .deliverable-icon {
            width: 30px;
            height: 30px;
            background: #C41E3A;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-right: 15px;
            font-weight: bold;
            flex-shrink: 0;
        }

        /* Format Table */
        .format-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
            border-radius: 8px;
            overflow: hidden;
        }

        .format-table th {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: bold;
        }

        .format-table td {
            padding: 15px;
            border-bottom: 1px solid #e0e0e0;
        }

        .format-table tr:hover {
            background: #f8f9fa;
        }

        .format-table tr:last-child td {
            border-bottom: none;
        }

        /* Footer */
        .footer {
            background: #f8f9fa;
            padding: 30px 40px;
            text-align: center;
            color: #666;
            border-top: 1px solid #e0e0e0;
        }

        .footer p {
            margin-bottom: 10px;
        }

        .footer-highlight {
            color: #4A4A4A;
            font-weight: bold;
        }

        /* Highlight boxes */
        .highlight-box {
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            border-left: 4px solid #C41E3A;
            padding: 15px 20px;
            border-radius: 4px;
            margin: 20px 0;
            color: #000;
        }

        .highlight-box strong {
            color: #000;
        }

        /* Responsiveness */
        @media (max-width: 768px) {
            .header {
                padding: 40px 20px;
            }

            .header h1 {
                font-size: 1.8em;
            }

            .content {
                padding: 30px 20px;
                text-align: justify;
            }

            .section-title {
                font-size: 1.6em;
            }

            .specifications,
            .rubric-grid {
                grid-template-columns: 1fr;
            }

            .structure-item h4 {
                font-size: 1.05em;
            }

            .format-table {
                font-size: 0.9em;
            }

            .format-table th,
            .format-table td {
                padding: 10px;
            }

            p,
            li,
            td {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }
        }

        /* Animation */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .section {
            animation: fadeIn 0.6s ease-out;
        }

        .spec-card {
            animation: fadeIn 0.6s ease-out;
        }

        /* Print styles */
        @media print {
            body {
                background: white;
                padding: 2.5cm;
                margin: 0;
                font-size: 12pt;
                line-height: 1.5;
                counter-reset: page 1;
            }

            .container {
                box-shadow: none;
                border-radius: 0;
                padding: 0;
                max-width: 100%;
                margin: 0;
            }

            .header {
                page-break-after: avoid;
                padding: 30px 0;
            }

            .content {
                padding: 0;
                text-align: justify;
            }

            p,
            li,
            td,
            th {
                font-size: 12pt;
                line-height: 1.5;
                text-align: justify;
            }

            .section {
                page-break-inside: avoid;
            }

            @page {
                margin: 2.5cm;

                @bottom-center {
                    content: counter(page);
                    font-size: 12pt;
                    font-family: Arial, sans-serif;
                }
            }
        }

        /* Code styles */
        code {
            background: #f0f0f0;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #d63384;
        }

        /* COVER PAGE STYLES */
        .cover-page {
            display: flex;
            align-items: flex-start;
            justify-content: center;
            min-height: 100vh;
            background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%);
            color: #000;
            text-align: center;
            padding: 60px 60px 80px 60px;
            page-break-after: always;
            position: relative;
        }

        .cover-page::before {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: linear-gradient(90deg, #C41E3A, rgba(196, 30, 58, 0) 50%, rgba(196, 30, 58, 0));
        }

        .cover-page::after {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            height: 2px;
            background: linear-gradient(90deg, rgba(196, 30, 58, 0), #C41E3A 50%, rgba(196, 30, 58, 0));
        }

        .cover-content {
            max-width: 600px;
            animation: fadeInCover 0.8s ease;
        }

        @keyframes fadeInCover {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .cover-logos {
            display: flex;
            justify-content: space-between;
            gap: 0;
            margin-bottom: 50px;
            align-items: center;
            width: 100%;
            max-width: none;
            margin-left: 0;
            margin-right: 0;
        }

        .cover-logo {
            flex: 0 0 auto;
            background: rgba(139, 21, 56, 0.05);
            padding: 15px;
            border-radius: 8px;
            border: 1px solid rgba(139, 21, 56, 0.2);
            backdrop-filter: blur(10px);
        }

        .cover-logo img {
            max-width: 100px;
            height: auto;
            filter: brightness(1);
            transition: transform 0.3s ease;
        }

        .cover-logo img:hover {
            transform: scale(1.05);
        }

        .cover-institution {
            margin-bottom: 60px;
            border-bottom: 2px solid #C41E3A;
            padding-bottom: 25px;
            letter-spacing: 0.5px;
        }

        .cover-institution h2 {
            font-size: 2em;
            margin-bottom: 8px;
            font-weight: 700;
            letter-spacing: 0.3px;
            line-height: 1.2;
            color: #000;
        }

        .cover-institution p {
            font-size: 1.15em;
            opacity: 1;
            font-weight: 500;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-course {
            margin-bottom: 90px;
            font-size: 1.25em;
            font-style: italic;
            opacity: 1;
            font-weight: 400;
            letter-spacing: 0.3px;
            color: #000;
        }

        .cover-main {
            margin-bottom: 100px;
        }

        .cover-main h1 {
            font-size: 3.5em;
            margin-bottom: 20px;
            font-weight: 800;
            text-shadow: none;
            line-height: 1.1;
            letter-spacing: -0.5px;
            color: #000;
        }

        .cover-subtitle {
            font-size: 1.4em;
            opacity: 1;
            font-style: italic;
            line-height: 1.5;
            font-weight: 300;
            color: #000;
        }

        .cover-author {
            margin-bottom: 70px;
            font-size: 1.1em;
        }

        .cover-author p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-author p:last-child {
            font-size: 1.4em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        .cover-date {
            font-size: 1.1em;
            margin-top: 80px;
            padding-top: 30px;
            border-top: 1px solid #C41E3A;
        }

        .cover-date p:first-child {
            margin-bottom: 12px;
            opacity: 1;
            font-size: 1em;
            text-transform: uppercase;
            letter-spacing: 1px;
            font-weight: 600;
            color: #000;
        }

        .cover-date p:last-child {
            font-size: 1.3em;
            font-weight: 700;
            letter-spacing: 0.2px;
            color: #000;
        }

        /* Print styles for cover */
        @media print {
            .cover-page {
                page-break-after: always;
                background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
                color: white;
            }
        }

        code-block {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            display: block;
            overflow-x: auto;
        }

        /* Footer con numeración de página */
        .page-number {
            text-align: center;
            padding: 20px 0;
            color: #999;
            font-size: 11pt;
            border-top: 1px solid #ddd;
            margin-top: 40px;
        }

        @media print {
            .page-number {
                display: none;
            }
        }

        /* Download Button */
        .download-container {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
        }

        .download-btn {
            background: linear-gradient(135deg, #8B1538 0%, #C41E3A 100%);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: bold;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(139, 21, 56, 0.3);
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .download-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(139, 21, 56, 0.4);
        }

        .download-btn:active {
            transform: translateY(0);
        }

        @media print {
            .download-container {
                display: none;
            }
        }

        /* Page Break Control */
        .page-section {
            page-break-after: always;
            page-break-inside: avoid;
            padding: 20px 0;
            margin-bottom: 1cm;
        }

        .page-section:last-child {
            page-break-after: avoid;
        }

        .section-page-break {
            page-break-after: always;
        }

        /* Evitar rupturas dentro de elementos */
        .page-section .section {
            page-break-inside: avoid;
        }

        .section-subtitle {
            page-break-after: avoid;
        }

        .section-title {
            page-break-after: avoid;
        }

        ul,
        ol {
            page-break-inside: avoid;
        }

        .format-table {
            page-break-inside: avoid;
        }

        .spec-card {
            page-break-inside: avoid;
        }

        .highlight-box {
            page-break-inside: avoid;
        }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html2pdf.js/0.10.1/html2pdf.bundle.min.js"></script>
    <script src="https://unpkg.com/docx@8.12.6/build/index.js"></script>
    <script>
        // Script para numeración de páginas
        window.addEventListener('load', function () {
            // En navegador, agregar numeración visible
            const pageNumbers = document.querySelectorAll('.page-number');
            if (pageNumbers.length > 0) {
                let pageCount = 1;
                pageNumbers.forEach((element, index) => {
                    element.textContent = 'Página ' + (index + 1);
                });
            }
        });

        // Función para descargar como Word
        function downloadAsWord() {
            try {
                const container = document.querySelector('.container');
                if (!container) {
                    alert('No se encontró el contenido para exportar');
                    return;
                }

                // Obtener el HTML completo
                const html = container.innerHTML;

                // Crear documento Word en formato OOXML
                const docContent = `<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<?mso-application progid="Word.Document"?>
<html xmlns:v="urn:schemas-microsoft-com:vml"
 xmlns:o="urn:schemas-microsoft-com:office:office"
 xmlns:w="urn:schemas-microsoft-com:office:word"
 xmlns:x="urn:schemas-microsoft-com:office:excel"
 xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math"
 xmlns="http://www.w3.org/TR/REC-html40">
<head>
<meta http-equiv=Content-Type content="text/html; charset=utf-8">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 16">
<meta name=Originator content="Microsoft Word 16">
<link rel=File-List href="filelist.xml">
<title>Reporte Final - Análisis de sentimientos en versos</title>
<o:DocumentProperties>
 <o:Author>Erik I. Osornio Botello</o:Author>
 <o:LastAuthor>Erik I. Osornio Botello</o:LastAuthor>
 <o:Created>2025-10-16T00:00:00Z</o:Created>
 <o:LastSaved>2025-10-16T00:00:00Z</o:LastSaved>
 <o:Pages>1</o:Pages>
 <o:Words>1</o:Words>
 <o:Characters>1</o:Characters>
 <o:Lines>1</o:Lines>
 <o:Paragraphs>1</o:Paragraphs>
 <o:CharactersWithSpaces>1</o:CharactersWithSpaces>
 <o:Version>16.00</o:Version>
</o:DocumentProperties>
</head>
<body>
${html}
</body>
</html>`;

                // Crear Blob
                const blob = new Blob([docContent], { type: 'application/vnd.ms-word' });

                // Descargar
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;
                link.download = 'Reporte_Analisis_Sentimientos.doc';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);

                alert('✓ Descargado: Reporte_Analisis_Sentimientos.doc');
            } catch (error) {
                console.error('Error:', error);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }

        // Función alternativa: descargar como PDF
        function downloadAsPDF() {
            try {
                const element = document.querySelector('.container');
                const cloned = element.cloneNode(true);
                cloned.querySelectorAll('.download-container, .page-number, .header').forEach(el => el.remove());

                const opt = {
                    margin: 10,
                    filename: 'Reporte_Analisis_Sentimientos.pdf',
                    image: { type: 'jpeg', quality: 0.98 },
                    html2canvas: { scale: 2 },
                    jsPDF: { orientation: 'portrait', unit: 'mm', format: 'a4' }
                };

                html2pdf().set(opt).from(cloned).save();
                alert('Descargando como PDF...');
            } catch (err) {
                console.error('Error al descargar:', err);
                alert('Error al generar el archivo. Por favor intente nuevamente.');
            }
        }
    </script>
</head>

<body>
    <div class="container">
        <!-- COVER PAGE -->
        <div class="cover-page">
            <div class="cover-content">
                <div class="cover-logos">
                    <div class="cover-logo">
                        <img src="logo_cic.jpg" alt="Logo CIC - Centro de Investigación en Computación">
                    </div>
                    <div class="cover-logo">
                        <img src="logo_ipn.jpg" alt="Logo IPN - Instituto Politécnico Nacional">
                    </div>
                </div>
                <div class="cover-institution">
                    <h2>Centro de Investigación en Computación</h2>
                </div>

                <div class="cover-course">
                    <p>Diplomado en Inteligencia Artificial</p>
                </div>

                <div class="cover-main">
                    <h1>Análisis de sentimientos en versos</h1>
                    <p class="cover-subtitle">Implementación y Evaluación de Tres Enfoques de Clasificación</p>
                </div>

                <div class="cover-author">
                    <p><strong>Autor:</strong></p>
                    <p>Erik I. Osornio Botello</p>
                </div>

                <div class="cover-date">
                    <p><strong>Fecha de Entrega:</strong></p>
                    <p>16 de Octubre de 2025</p>
                </div>
            </div>
        </div>

        <!-- TABLE OF CONTENTS -->
        <div style="page-break-after: always; padding: 40px 0;">
            <h2 style="font-size: 1.8em; color: #000; margin-bottom: 30px; text-align: center; font-weight: bold;">
                Índice</h2>
            <ol style="font-size: 12pt; line-height: 2; margin-left: 30px; color: #333;">
                <li>Introducción</li>
                <li>Datos</li>
                <li>Preprocesamiento</li>
                <li>Representación de texto</li>
                <li>Modelos implementados
                    <ol style="margin-top: 10px; margin-left: 20px;">
                        <li>Regresión Logística</li>
                        <li>Naive Bayes Multinomial</li>
                        <li>LSTM</li>
                    </ol>
                </li>
                <li>Entrenamiento y validación</li>
                <li>Métricas y evaluación</li>
                <li>Resultados</li>
                <li>Discusión</li>
                <li>Conclusiones y trabajo futuro</li>
                <li>Referencias</li>
            </ol>
        </div>

        <div class="download-container">
            <button class="download-btn" onclick="downloadAsWord()">📥 Descargar Word</button>
        </div>

        <!-- Main Content -->
        <div class="content">
            <!-- PAGE 1: Title and Author -->
            <div class="page-section">
                <div class="section" style="text-align: center; margin-bottom: 60px;">
                    <h2 style="font-size: 2.2em; color: #000; margin-bottom: 10px;">Análisis de sentimientos en versos
                    </h2>
                    <p style="font-size: 1.2em; color: #000; margin-bottom: 30px;"><strong>Autor:</strong> Erik I.
                        Osornio Botello</p>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; max-width: 800px; margin: 0 auto;">
                        <h3 style="color: #000; margin-bottom: 15px;">Resumen</h3>
                        <p style="text-align: justify; line-height: 1.8; color: #333;">
                            Este documento describe el desarrollo, implementación y evaluación de un sistema de análisis
                            de sentimientos
                            sobre un corpus en español. Se comparan tres enfoques principales: <strong>Regresión
                                Logística</strong> (con CountVectorizer),
                            <strong>Naive Bayes Multinomial</strong> (con CountVectorizer) y una red neuronal
                            <strong>LSTM</strong> (trabajando sobre secuencias tokenizadas).
                            El objetivo es describir el flujo completo: exploración y limpieza de datos, extracción de
                            características, entrenamiento,
                            validación, evaluación cuantitativa y análisis crítico de resultados.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 2: Introduction Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📋 1. Introducción</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        El análisis de sentimientos busca asignar una polaridad (por ejemplo: positiva, negativa,
                        neutral) a textos.
                        En este proyecto se implementan tres enfoques que representan paradigmas distintos: modelos
                        lineales probabilísticos
                        (Regresión Logística), modelos de probabilidades condicionales con suposiciones de independencia
                        (Naive Bayes Multinomial)
                        y modelos secuenciales basados en redes neuronales (LSTM). Se discute su preparación,
                        rendimiento y trade-offs.
                    </p>

                    <div class="section-subtitle">Objetivos</div>
                    <ul style="line-height: 2;">
                        <li>Construir y comparar tres modelos de análisis de sentimientos.</li>
                        <li>Evaluar rendimiento con métricas estándar (accuracy, precision, recall, F1, AUC cuando
                            aplique).</li>
                        <li>Documentar decisiones de diseño y parámetros.</li>
                    </ul>

                    <div class="section-subtitle">Marco de Referencia</div>
                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <p style="margin-bottom: 12px;">
                            <strong>📋 Indicaciones del Proyecto:</strong> Este proyecto se fundamenta en las
                            indicaciones
                            especificadas en el documento <em>Indicaciones Proyecto Poemas.pdf</em>, el cual establece
                            que:
                        </p>
                        <p
                            style="margin-bottom: 12px; padding-left: 15px; border-left: 3px solid #C41E3A; margin-left: 0;">
                            <strong>"Este proyecto es un ejercicio de aprendizaje supervisado. La idea general consiste
                                en
                                implementar tres clasificadores de texto para el problema de análisis de sentimientos en
                                versos de poemas."</strong>
                        </p>
                        <p>
                            <strong>Clases del Problema:</strong> El marco original define tres categorías de
                            sentimiento (positivo, negativo
                            o neutral), aunque en la práctica el dataset utilizado incluye cuatro clases: Positivo,
                            Negativo, Mixto y No impacto.
                            La estructura de tres clasificadores y el enfoque de aprendizaje supervisado se mantienen
                            como eje central de
                            la implementación.
                        </p>
                    </div>
                </div>
            </div>

            <!-- PAGE 3: Data Section -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📊 2. Datos</div>

                    <div class="section-subtitle">Descripción del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 20px;">
                        <strong>Fuente:</strong> Para este proyecto se utilizó el dataset <em>Poem Sentiment</em> del
                        repositorio de Google Research,
                        disponible en Hugging Face (hf://datasets/google-research-datasets/poem_sentiment). Este
                        conjunto de datos consiste en versos
                        de poemas extraídos de Project Gutenberg, etiquetados según el sentimiento que transmiten.
                    </p>

                    <div class="spec-card">
                        <strong>📈 Características principales:</strong>
                        <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                            <li><strong>Número total de ejemplos:</strong> 1,101 versos</li>
                            <li><strong>Idioma:</strong> Textos en inglés</li>
                            <li><strong>Tamaño:</strong> Dataset pequeño, lo que puede afectar la generalización de
                                modelos complejos como LSTM</li>
                            <li><strong>Data Augmentation:</strong> Debido al desbalance inicial de clases, se aplicó
                                data augmentation únicamente en el conjunto de entrenamiento para equilibrar la
                                distribución de clases.</li>
                        </ul>
                    </div>

                    <div class="section-subtitle">Clases de Sentimiento</div>
                    <ul style="line-height: 2;">
                        <li><strong>Positivo:</strong> Versos con emociones positivas</li>
                        <li><strong>Negativo:</strong> Versos con emociones negativas</li>
                        <li><strong>Mixto:</strong> Versos que combinan emociones positivas y negativas</li>
                        <li><strong>No impacto:</strong> Versos que no presentan un sentimiento claro</li>
                    </ul>

                    <div class="section-subtitle">Columnas del Dataset</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        Este conjunto de datos consta de versos de poemas extraídos de Project Gutenberg, etiquetados
                        según el sentimiento que transmiten.
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>verse_text:</strong> Contiene el texto del verso del poema</li>
                        <li><strong>label:</strong> Indica la categoría de sentimiento del verso</li>
                    </ul>

                    <div class="section-subtitle">Exploración Inicial</div>
                    <p style="text-align: justify; line-height: 1.5; margin-bottom: 15px;">
                        En la fase de exploración, no se encontraron valores nulos. El histograma de las longitudes por
                        clase se encuentra representado en la Ilustración 2.
                    </p>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="verse_lengths_distribution.png"
                            alt="Gráfico de Distribución de Longitudes de Versos por Clase"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Ilustración 1. Distribución de longitudes por clase</p>
                    </div>

                    <p style="text-align: justify; line-height: 1.5; margin-top: 20px;">
                        La figura muestra la distribución de la longitud de los versos según su sentimiento. Se observa
                        que la mayoría de los versos tienen entre 30 y 50 palabras,
                        con predominancia de la clase no impact. Las clases minoritarias (mixed, positivo, negativo)
                        están menos representadas, lo que refuerza el desbalance del dataset.
                        Esta distribución sugiere que los modelos podrían aprender primero la clase mayoritaria y que
                        los ejemplos muy largos son poco frecuentes y podrían considerarse outliers.
                    </p>

                    <div class="section-subtitle">División de Datos</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Conjunto</th>
                                <th>Número de Ejemplos</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Entrenamiento</strong></td>
                                <td>892 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Validación</strong></td>
                                <td>105 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Test</strong></td>
                                <td>104 ejemplos</td>
                            </tr>
                            <tr>
                                <td><strong>Total</strong></td>
                                <td>1,101 ejemplos</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="section-subtitle">Distribución de Clases (Entrenamiento Original)</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                                <th>Porcentaje</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>555</td>
                                <td>62.2%</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>155</td>
                                <td>17.4%</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>133</td>
                                <td>14.9%</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>49</td>
                                <td>5.5%</td>
                            </tr>
                        </tbody>
                    </table>

                    <div style="text-align: center; margin: 30px 0;">
                        <img src="sentiment_distribution.png"
                            alt="Gráfico de Distribución de Clases en Datos de Entrenamiento"
                            style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                        <p
                            style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                            Figura 1: Distribución de Sentimientos en los Datos de Entrenamiento Original</p>
                    </div>

                    <div class="highlight-box"
                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                        <strong>⚠️ Problema de Desbalance:</strong> La mayoría de los versos pertenecen a la clase "No
                        impacto",
                        mientras que la clase "Mixto" tiene muy pocos ejemplos. Este desbalance puede generar:
                        <ul style="margin-left: 20px; margin-top: 10px; margin-bottom: 10px; line-height: 1.8;">
                            <li><strong>Bias hacia la clase mayoritaria:</strong> Los modelos tienden a predecir con
                                mayor frecuencia la clase predominante (No impacto), lo que puede inflar el accuracy
                                aparente, pero reducir la capacidad de identificar correctamente las clases
                                minoritarias.</li>
                            <li><strong>Problemas de generalización en LSTM y modelos complejos:</strong> Las redes
                                neuronales pueden sobreajustar fácilmente a la clase mayoritaria, especialmente cuando
                                el dataset es pequeño. En este caso, modelos como LSTM pueden aprender patrones sesgados
                                en lugar de representaciones robustas de todas las clases.</li>
                            <li><strong>Métricas poco confiables para clases minoritarias:</strong> Las métricas de
                                rendimiento pueden ser engañosas si se interpretan sin considerar el desbalance.</li>
                        </ul>
                        <p style="margin-top: 12px; text-align: justify; line-height: 1.6; font-size: 11pt;">
                            Dado el tamaño reducido y el desbalance, estos conjuntos pueden no ser representativos de la
                            distribución real de clases.
                            Esto significa que las métricas de evaluación (accuracy, F1, recall, precision) pueden ser
                            ruidosas y poco confiables,
                            especialmente para las clases minoritarias como Mixto y Positivo.
                        </p>
                    </div>

                    <div class="section-subtitle">Estrategias de Mitigación</div>
                    <ul style="line-height: 2;">
                        <li><strong>Data Augmentation:</strong> Aplicada solo en el entrenamiento para balancear las
                            clases</li>
                        <li><strong>Class weights:</strong> Pesos por clase en LSTM para penalizar predicciones
                            incorrectas de clases minoritarias</li>
                    </ul>

                    <div class="section-subtitle">Distribución de Clases (Post Data Augmentation)</div>
                    <table class="format-table">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>2,775</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>2,325</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>1,995</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>735</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <!-- PAGE 4: Preprocesamiento -->
            <div class="page-section">
                <div class="section">
                    <div class="section-title">📝 3. Preprocesamiento</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        El texto se sometió a un pipeline de preprocesamiento con dos funciones principales:
                        <code>clean_text</code> y <code>preprocess_text</code>.
                    </p>

                    <div class="section-subtitle">Limpieza de Texto (clean_text)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Esta función realiza operaciones de limpieza básica para normalizar los datos textuales:
                    </p>
                    <ul style="line-height: 2;">
                        <li>Conversión a minúsculas para uniformidad</li>
                        <li>Eliminación de URLs y etiquetas HTML</li>
                        <li>Remoción de menciones de usuarios (@usuario) y símbolos de hashtags (#)</li>
                        <li>Eliminación de puntuación y números</li>
                        <li>Reducción de espacios en blanco redundantes</li>
                    </ul>

                    <div class="section-subtitle">Preprocesamiento Completo (preprocess_text)</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        A continuación, el texto limpio se somete a un procesamiento adicional para preparar los datos
                        para modelos de NLP:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Tokenización:</strong> El texto se divide en palabras individuales</li>
                        <li><strong>Eliminación de stopwords:</strong> Se eliminan palabras comunes sin contenido
                            semántico relevante (como “the”, “and”, “is”) utilizando la lista de NLTK</li>
                        <li><strong>Lematización:</strong> Cada palabra se reduce a su forma base (por ejemplo,
                            “running” → “run”, “cars” → “car”) usando WordNetLemmatizer.</li>
                        <li><strong>Reconstrucción del texto:</strong> Los tokens resultantes se unen nuevamente en un
                            string, listo para su análisis o entrada a un modelo</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este pipeline permite obtener un texto limpio, normalizado y representativo, adecuado para
                        técnicas de NLP como modelos de LSTM,
                        Naive Bayes o TF-IDF, mejorando la calidad de las predicciones y reduciendo el ruido en los
                        datos.
                    </p>

                    <div class="spec-card">
                        <strong>📝 Ejemplos de Preprocesamiento:</strong>
                        <div
                            style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                            <p><strong>Original:</strong> "with pale blue berries. in these peaceful shades"</p>
                            <p><strong>Procesado:</strong> "pale blue berry peaceful shade"</p>
                            <hr style="border: none; border-top: 1px solid #ddd; margin: 10px 0;">
                            <p><strong>Original:</strong> "it flows so long as falls the rain,"</p>
                            <p><strong>Procesado:</strong> "flow long fall rain"</p>
                        </div>
                    </div>

                    <div style="height: 20px; clear: both;"></div>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Se puede observar que, tras aplicar procesamiento, se reduce la longitud de la oración original,
                        se removió puntuación y stopwords.
                    </p>

                    <div class="section-subtitle">Data Augmentation</div>
                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                        Se implementó un pipeline de aumento de datos utilizando la librería <code>nlpaug</code> para
                        balancear
                        las clases minoritarias. El objetivo principal es balancear las clases minoritarias en el
                        dataset y mejorar la capacidad del modelo para generalizar.
                        El proceso incluye:
                    </p>
                    <ul style="line-height: 2;">
                        <li><strong>Selección de clases minoritarias:</strong> Se identifican las clases que tienen
                            pocas muestras (por ejemplo: “negative”, “positive” y “mixed”)
                            y se les aplica un mayor número de "augmentations" para equilibrar la distribución de
                            clases.</li>
                        <li><strong>Generación de nuevas muestras:</strong> Para cada texto en el dataset se generan
                            varias versiones alternativas reemplazando palabras por sinónimos usando WordNet.</li>
                        <li><strong>Proporción de aumentos:</strong> Las clases minoritarias reciben más aumentos que
                            las clases mayoritarias, logrando un balance más uniforme.</li>
                        <li><strong>Creación de dataset final:</strong> Los textos originales y los aumentados se
                            combinan en un nuevo DataFrame.</li>
                    </ul>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Esto produce un dataset más grande y balanceado, que reduce el sesgo hacia clases mayoritarias y
                        ayuda a mejorar el entrenamiento de modelos de NLP.
                    </p>

                    <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                        Este procedimiento es especialmente útil en problemas de clasificación de texto donde algunas
                        categorías tienen muy pocas muestras, ya que incrementa la diversidad de los datos
                        sin necesidad de recolectar más ejemplos reales.

                    </p>

                    <div class="spec-card">
                        <strong>📝 Ejemplos de Data Augmentation:</strong>
                        <div
                            style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                            <p><strong>Original:</strong> "right wrong john"</p>
                            <p><strong>Aumento 1:</strong> "right unseasonable john"</p>
                            <p><strong>Aumento 2:</strong> "right ill timed john"</p>
                            <p><strong>Aumento 3:</strong> "right wrong king john"</p>
                            <p><strong>Aumento 4:</strong> "mightily wrong john"</p>
                        </div>
                    </div>

                    <p style="text-align: justify; line-height: 1.8; margin-top: 20px;">
                        Tras aplicar aumentos, se puede observar que en cada aumento se cambia la palabra <em>wrong</em>
                        (malo) por un sinónimo diferente:
                        <em>unseasonable</em>, <em>ill timed</em>, <em>mightily wrong john</em>, haciendo el dataset más
                        diverso. A la clase mayoritaria se le
                        aplicaron 5 aumentos y a las minoritarias 14 por cada muestra. De esta manera, se genera una
                        representación más rica de cada clase
                        sin necesidad de recolectar datos nuevos.
                    </p>

                    <p style="text-align: justify; line-height: 1.8; margin-top: 20px;">
                        La distribución resultante se puede observar en la Tabla 2:
                    </p>

                    <table class="format-table" style="margin-top: 15px;">
                        <thead>
                            <tr>
                                <th>Sentimiento</th>
                                <th>Total</th>
                                <th>Porcentaje</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>No impacto (No impact)</strong></td>
                                <td>2,775</td>
                                <td>35.45%</td>
                            </tr>
                            <tr>
                                <td><strong>Negativo (Negative)</strong></td>
                                <td>2,325</td>
                                <td>29.69%</td>
                            </tr>
                            <tr>
                                <td><strong>Positivo (Positive)</strong></td>
                                <td>1,995</td>
                                <td>25.48%</td>
                            </tr>
                            <tr>
                                <td><strong>Mixto (Mixed)</strong></td>
                                <td>735</td>
                                <td>9.39%</td>
                            </tr>
                            <tr style="background: #f0f0f0; font-weight: bold;">
                                <td><strong>Total</strong></td>
                                <td>7,830</td>
                                <td>100%</td>
                            </tr>
                        </tbody>
                    </table>
                    <p style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                        Tabla 2. Distribución de clases después de aplicar aumentos</p>

                </div>

                <!-- PAGE 5: Text Representation -->
                <div class="page-section">
                    <div class="section">
                        <div class="section-title">🔢 4. Representación de Texto</div>

                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                            Se utilizó CountVectorizer para los modelos clásicos y embeddings + secuencias para la LSTM.
                        </p>

                        <div class="section-subtitle">Count Vectorizer</div>
                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            El CountVectorizer se utiliza para convertir texto en una representación numérica que pueda
                            ser procesada
                            por modelos de machine learning. Transforma un conjunto de documentos en una matriz de
                            conteo de palabras,
                            donde cada fila representa un documento, cada columna representa una palabra del
                            vocabulario, y el valor
                            indica cuántas veces aparece esa palabra en el documento.
                        </p>

                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                            En <strong>scikit-learn</strong>, CountVectorizer se configura como un objeto que luego se
                            ajusta (fit) y transforma (transform) sobre los textos. La Ilustración 4 muestra como
                            ajustar sus parámetros.
                        </p>

                        <div style="text-align: center; margin: 30px 0;">
                            <img src="count_vectorizer.png" alt="Configuración de CountVectorizer"
                                style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                            <p
                                style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                Ilustración 4. Ejemplo de configuración de CountVectorizer</p>
                        </div>

                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            <strong>Configuración:</strong> max_features=10000, unigramas y bigramas
                        </p>
                        <p style="text-align: justify; line-height: 1.8;">
                            <strong>Matrices resultantes:</strong>
                        </p>
                        <ul style="line-height: 2;">
                            <li>X_train: (7830, 10000)</li>
                            <li>X_val: (105, 10000)</li>
                            <li>X_test: (104, 10000)</li>
                        </ul>

                        <div class="section-subtitle">Tokenización para LSTM</div>
                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            Para entrenar una LSTM, cada documento se convirtió en una secuencia numérica de longitud
                            fija mediante
                            la librería Keras Tokenizer:
                        </p>
                        <ul style="line-height: 2;">
                            <li><strong>Tokenización:</strong> Asignación de identificador único a cada palabra del
                                vocabulario</li>
                            <li><strong>Padding:</strong> Relleno con ceros para garantizar longitud fija</li>
                            <li><strong>Entrada al modelo:</strong> El conjunto completo se representa como una matriz
                                de dimensión <code>(n_samples, max_sequence_length)</code>, donde <code>n_samples</code>
                                es el número de documentos y <code>max_sequence_length</code> es la longitud máxima de
                                las secuencias después del padding</li>
                            <li><strong>Embedding:</strong> Transformación de enteros en vectores densos de tamaño fijo
                                (embedding_dim), resultando en una entrada final con forma: <code>(batch_size,
                                sequence_length, embedding_dim)</code></li>

                        </ul>
                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                            <strong>Configuración de ejemplo:</strong> num_words=10000, oov_token="&lt;OOV&gt;"
                        </p>

                        <div class="spec-card">
                            <strong>📝 Ejemplo de Tokenización:</strong>
                            <div
                                style="margin-top: 15px; font-family: 'Courier New', monospace; background: #f8f9fa; padding: 15px; border-radius: 4px;">
                                <p><strong>Texto:</strong> "i love nlp"</p>
                                <p><strong>Tokenizado:</strong> [2, 3, 1]</p>
                                <p><strong>Con Padding (longitud=5):</strong> [2, 3, 1, 0, 0]</p>
                            </div>
                        </div>

                        <div style="text-align: center; margin: 30px 0;">
                            <img src="tokenizacion_keras.png" alt="Tokenización en Keras"
                                style="max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                            <p
                                style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                Ilustración 5. Tokenización en Keras</p>
                        </div>



                    </div>

                    <!-- PAGE 6: Models -->
                    <div class="page-section">
                        <div class="section">
                            <div class="section-title">🤖 5. Modelos Implementados</div>

                            <div class="section-subtitle">5.1 Regresión Logística</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                La regresión logística fue seleccionada por su capacidad para manejar eficazmente
                                representaciones vectorizadas
                                del texto. Este modelo aprende a estimar la probabilidad de pertenencia a cada clase
                                mediante una combinación
                                lineal de características, lo cual resulta apropiado en problemas de análisis de texto
                                donde la presencia
                                o frecuencia de ciertas palabras suele correlacionarse directamente con el sentimiento.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Permite incorporar pesos para clases minoritarias (class weights)</li>
                                    <li>Naturaleza probabilística facilita interpretar confianza</li>
                                    <li>Bajo costo computacional y estable</li>
                                    <li>Excelente baseline para comparar con modelos más complejos</li>
                                </ul>
                            </div>
                            <div style="height: 20px; clear: both;"></div>
                            <p style="margin-top: 15px;"><strong>Librería:</strong>
                                sklearn.linear_model.LogisticRegression</p>
                            <p style="margin-top: 15px;"><strong>Parámetros:</strong> max_iter=1000</p>

                            <div style="text-align: center; margin: 30px 0;">
                                <img src="logistic_regression.png" alt="Parámetros utilizados para regresión logística"
                                    style="max-width: 70%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                <p
                                    style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                    Ilustración 6. Parámetros utilizados para regresión logística</p>
                            </div>

                            <div class="section-subtitle">5.2 Naive Bayes Multinomial</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                El modelo Naive Bayes Multinomial está especialmente diseñado para trabajar con datos
                                representados como
                                frecuencias de palabras, como los obtenidos mediante técnicas de Bag-of-Words o TF-IDF.
                                Asume independencia entre las características (palabras), lo
                                que simplifica el
                                cálculo de probabilidades y permite un entrenamiento muy rápido incluso con grandes
                                volúmenes de texto.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Rendimiento competitivo en clasificación de textos</li>
                                    <li>Especialmente efectivo cuando hay palabras claramente asociadas a cada
                                        sentimiento</li>
                                    <li>Entrenamimiento rápido y eficiente</li>
                                    <li>Opción sólida como modelo base</li>
                                </ul>
                            </div>
                            <p style="margin-top: 15px;"><strong>Implementación:</strong> MultinomialNB de scikit-learn
                            </p>
                            <div style="text-align: center; margin: 30px 0;">
                                <img src="multinomial_nb.png" alt="Parámetros utilizados para Naive Bayes Multinomial"
                                    style="max-width: 40%; height: auto; border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                                <p
                                    style="text-align: center; color: #666; font-size: 11pt; margin-top: 10px; font-style: italic;">
                                    Ilustración 7. Configuración de parámetros de Naive Bayes Multinomial</p>
                            </div>
                            <div class="section-subtitle">5.3 LSTM (Long Short-Term Memory)</div>
                            <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                Las redes LSTM (Long Short-Term Memory) se utilizan en la clasificación de sentimientos
                                porque están diseñadas para procesar secuencias de texto teniendo en cuenta el contexto
                                y el orden de las palabras, algo que los modelos tradicionales como Bag-of-Words no
                                pueden capturar. A diferencia de los modelos basados en frecuencias, que tratan cada
                                palabra de forma independiente, una LSTM puede recordar información relevante de
                                palabras anteriores y utilizarla para interpretar correctamente el sentimiento de una
                                frase completa. Esto es especialmente útil en casos donde el significado depende de la
                                estructura, como en negaciones (“no fue tan bueno”) o expresiones compuestas. Gracias a
                                esta capacidad para modelar dependencias a largo plazo, las LSTM logran una
                                representación más semántica del texto, mejorando el desempeño en tareas de análisis de
                                sentimientos. Para su implementación se utilizó la librería de keras y los parámetros se
                                definen de acuerdo a la Ilustración 8 donde: input_dim es el tamaño de vocabulario;
                                output_dim, la dimensión del vector de embedding; input_length, la longitud máxima de
                                las secuencias; LSTM (), el número de unidades de memoria en una LSTM; Dense es el
                                número de clases de salida y activation es la función de activación para clasificación
                                multiclase.
                            </p>
                            <div class="spec-card">
                                <strong>Ventajas:</strong>
                                <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                    <li>Modela dependencias a largo plazo</li>
                                    <li>Útil para negaciones y expresiones compuestas</li>
                                    <li>Representación más semántica del texto</li>
                                    <li>Mejor desempeño en tareas complejas de análisis de sentimientos</li>
                                </ul>
                            </div>
                            <p style="margin-top: 15px;"><strong>Framework:</strong> TensorFlow / Keras</p>
                            <p style="margin-top: 10px;"><strong>Arquitectura:</strong> Embedding (10000) → LSTM (168) →
                                Dropout (0.5) → Dense (168) → Dropout (0.5) → Dense(4) → Softmax</p>
                            <p style="margin-top: 10px;"><strong>Regularización:</strong> Dropout, recurrent_dropout, L2
                            </p>
                            <p style="margin-top: 10px;"><strong>Optimizer:</strong> Adam</p>
                        </div>

                        <!-- PAGE 7: Metrics and Training -->
                        <div class="page-section">
                            <div class="section">
                                <div class="section-title">📊 6. Entrenamiento, Validación y Métricas</div>

                                <div class="section-subtitle">División del Dataset</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utilizó la división estándar del dataset proporcionada por Hugging Face para
                                    garantizar coherencia
                                    y reproducibilidad de los resultados.
                                </p>

                                <div class="section-subtitle">Métricas de Evaluación</div>
                                <p style="text-align: justify; line-height: 1.8; margin-bottom: 15px;">
                                    Se utilizaron las siguientes métricas para evaluar el desempeño de los modelos:
                                </p>
                                <ul style="line-height: 2;">
                                    <li><strong>Accuracy:</strong> Proporción de predicciones correctas</li>
                                    <li><strong>Precision (macro avg):</strong> Promedio de precisión por clase</li>
                                    <li><strong>Recall (macro avg):</strong> Promedio de recall por clase</li>
                                    <li><strong>F1 (macro avg):</strong> Media armónica de precision y recall</li>
                                </ul>
                                <p style="text-align: justify; line-height: 1.8; margin-top: 15px;">
                                    <strong>Librerías utilizadas:</strong> sklearn.metrics.classification_report,
                                    confusion_matrix
                                </p>
                            </div>

                            <!-- PAGE 8: Results -->
                            <div class="page-section">
                                <div class="section">
                                    <div class="section-title">📈 7. Resultados</div>

                                    <div class="section-subtitle">Resumen de Métricas</div>
                                    <table class="format-table">
                                        <thead>
                                            <tr>
                                                <th>Modelo</th>
                                                <th>Accuracy (train/test)</th>
                                                <th>Precision (macro)</th>
                                                <th>Recall (macro)</th>
                                                <th>F1 (macro)</th>
                                            </tr>
                                        </thead>
                                        <tbody>
                                            <tr>
                                                <td><strong>Logistic Regression</strong></td>
                                                <td>0.99 / 0.70</td>
                                                <td>0.48</td>
                                                <td>0.36</td>
                                                <td>0.38</td>
                                            </tr>
                                            <tr>
                                                <td><strong>Multinomial NB</strong></td>
                                                <td>0.99 / 0.69</td>
                                                <td>0.48</td>
                                                <td>0.48</td>
                                                <td>0.48</td>
                                            </tr>
                                            <tr>
                                                <td><strong>LSTM</strong></td>
                                                <td>0.95 / 0.51</td>
                                                <td>0.44</td>
                                                <td>0.42</td>
                                                <td>0.41</td>
                                            </tr>
                                        </tbody>
                                    </table>

                                    <div class="highlight-box"
                                        style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A; margin-top: 30px;">
                                        <strong>⚠️ Observación Clave:</strong> Se observa un patrón consistente de
                                        sobreajuste en todos los modelos,
                                        con desempeño significativamente mejor durante el entrenamiento que en el
                                        conjunto de prueba.
                                    </div>
                                </div>

                                <!-- PAGE 9: Discussion -->
                                <div class="page-section">
                                    <div class="section">
                                        <div class="section-title">💡 8. Discusión</div>

                                        <p style="text-align: justify; line-height: 1.8; margin-bottom: 20px;">
                                            A pesar de la aplicación de técnicas de aumento de datos en el conjunto de
                                            entrenamiento, los modelos
                                            evaluados presentan indicios claros de sobreajuste. Esto se evidencia en las
                                            altas precisiones obtenidas
                                            durante el entrenamiento (≈0.95–0.99) y la notable disminución del
                                            rendimiento en el conjunto de prueba.
                                        </p>

                                        <div class="spec-card">
                                            <strong>Análisis del Sobreajuste:</strong>
                                            <ul style="margin-top: 10px; margin-left: 0; padding-left: 20px;">
                                                <li>Las estrategias de aumento incrementaron la cantidad de ejemplos
                                                    pero no aportaron suficiente variabilidad semántica</li>
                                                <li>El modelo LSTM evidencia el mayor grado de sobreajuste, posiblemente
                                                    debido a su alta capacidad de representación</li>
                                                <li>Naive Bayes Multinomial muestra mejor generalización con valores más
                                                    equilibrados entre entrenamiento y prueba</li>
                                            </ul>
                                        </div>

                                        <div class="highlight-box"
                                            style="background: linear-gradient(135deg, #f5f5f5 0%, #ffffff 100%); border-left-color: #C41E3A;">
                                            <strong>✓ Conclusión Parcial:</strong> El modelo Multinomial Naive Bayes
                                            demuestra la mejor capacidad de
                                            generalización, manteniendo un F1-score consistente de 0.48 tanto en
                                            métricas generales como en recall,
                                            indicando un equilibrio adecuado entre precisión y cobertura.
                                        </div>
                                    </div>

                                    <!-- PAGE 10: Conclusions -->
                                    <div class="page-section">
                                        <div class="section">
                                            <div class="section-title">🎯 9. Conclusiones y Trabajo Futuro</div>

                                            <div class="section-subtitle">Conclusiones Principales</div>
                                            <ul style="line-height: 2;">
                                                <li>Se implementaron exitosamente tres modelos de análisis de
                                                    sentimientos con diferentes paradigmas</li>
                                                <li>La técnica de data augmentation mejoró el balance de clases pero no
                                                    resolvió completamente el sobreajuste</li>
                                                <li>Naive Bayes Multinomial mostró la mejor generalización relativa bajo
                                                    las condiciones actuales</li>
                                                <li>El dataset pequeño y desbalanceado limita el desempeño,
                                                    especialmente de modelos complejos como LSTM</li>
                                            </ul>

                                            <div class="section-subtitle">Recomendaciones para Trabajo Futuro</div>
                                            <ul style="line-height: 2;">
                                                <li>Optimizar la regularización de los modelos neuronales</li>
                                                <li>Explorar el uso de embeddings preentrenados (Word2Vec, GloVe,
                                                    FastText)</li>
                                                <li>Emplear técnicas avanzadas de balanceo de clases (SMOTE,
                                                    estratificación)</li>
                                                <li>Aumentar el volumen de datos o utilizar transfer learning</li>
                                                <li>Implementar validación cruzada estratificada para evaluaciones más
                                                    robustas</li>
                                            </ul>
                                        </div>

                                        <!-- PAGE 11: References & Footer -->
                                        <div class="page-section">
                                            <div class="section">
                                                <div class="section-title">📚 10. Referencias Bibliográficas</div>

                                                <div
                                                    style="background: #f8f9fa; padding: 25px; border-radius: 8px; line-height: 2;">
                                                    <p>Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011).
                                                        <em>Scikit-learn: Machine Learning in Python</em>.
                                                        Journal of Machine Learning Research, 12, 2825-2830.
                                                    </p>

                                                    <p>Chollet, F. (2021). <em>Deep Learning with Python</em> (2nd ed.).
                                                        Manning Publications. [Keras framework documentation]</p>

                                                    <p>Google Research. (s.f.). <em>Poem sentiment</em> [Conjunto de
                                                        datos]. Hugging Face.
                                                        Disponible en:
                                                        https://huggingface.co/datasets/google-research-datasets/poem_sentiment
                                                    </p>

                                                    <p>Goodfellow, I., Bengio, Y., & Courville, A. (2016). <em>Deep
                                                            Learning</em>.
                                                        MIT Press. [Referencia para arquitecturas de redes neuronales]
                                                    </p>

                                                    <p>Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT:
                                                        Pre-training of Deep Bidirectional Transformers
                                                        for Language Understanding. arXiv preprint arXiv:1810.04805.</p>
                                                </div>
                                            </div>

                                            <!-- Footer -->
                                            <div class="footer">
                                                <p>📊 <span class="footer-highlight">Reporte Final: Análisis de
                                                        sentimientos en versos - Diplomado en Inteligencia
                                                        Artificial</span></p>
                                                <p style="font-size: 0.9em; color: #999;">Autor: Erik I. Osornio Botello
                                                </p>
                                                <p style="margin-top: 15px; color: #999; font-size: 0.85em;">
                                                    Este reporte presenta el desarrollo, implementación y evaluación de
                                                    un sistema completo de análisis de sentimientos
                                                    utilizando tres enfoques distintos.
                                                </p>
                                            </div>

                                            <div class="page-number"></div>
                                        </div>
                                    </div>
                                </div>
</body>

</html>